{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini neural net training\n",
    "Authors: Alfredo Canziani, Philipp Schmitt  \n",
    "Date: Tue 24 Feb 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from IPython import display\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from matplotlib.pyplot import imshow, axis, figure, subplot, pause\n",
    "import numpy\n",
    "import random\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11b002110>"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# static random seed\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input definition\n",
    "class input_settings:\n",
    "    batch_size = 1\n",
    "    channels = 1\n",
    "    height = 8\n",
    "    width = 8\n",
    "\n",
    "dummy_X = torch.randn(  # batch of inputs x\n",
    "    input_settings.batch_size,\n",
    "    input_settings.channels,\n",
    "    input_settings.height,\n",
    "    input_settings.width,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network architecture\n",
    "class model_settings:\n",
    "    conv_channels = 4\n",
    "    kernel = 3\n",
    "    pooling_kernel = 3\n",
    "    flattened = 16\n",
    "    output_size = 1\n",
    "    \n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(\n",
    "        in_channels=input_settings.channels,\n",
    "        out_channels=model_settings.conv_channels,\n",
    "        kernel_size=model_settings.kernel,\n",
    "        bias=True,\n",
    "    ),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(\n",
    "        kernel_size=model_settings.pooling_kernel,\n",
    "        stride=model_settings.pooling_kernel,\n",
    "    ),  # we have 4 x 2x2\n",
    "    nn.Flatten(),  # gives 16\n",
    "    nn.Linear(\n",
    "        in_features=model_settings.flattened,\n",
    "        out_features=model_settings.output_size,\n",
    "        bias=True,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "with torch.no_grad():\n",
    "    print(model(dummy_X).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Flatten()\n",
      "  (4): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weights and biases\n",
    "def get_weights():\n",
    "    print(\n",
    "        model[0],\n",
    "        model[0].weight,\n",
    "        model[0].bias,\n",
    "        sep='\\n',\n",
    "    )\n",
    "    print(\n",
    "        model[4],\n",
    "        model[4].weight,\n",
    "        model[4].bias,\n",
    "        sep='\\n',\n",
    "    )\n",
    "    # Maybe add some saving routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = ImageFont.truetype('Verdana', 8)  # let's keep it to Verdana 8pt\n",
    "data_set_settings = dict(\n",
    "    D=dict(\n",
    "        x_min = -1,\n",
    "        x_max = 2,\n",
    "        y_min = -3,\n",
    "        y_max = -1,\n",
    "    ),\n",
    "    C=dict(\n",
    "        x_min = 0,\n",
    "        x_max = 3,\n",
    "        y_min = -4,\n",
    "        y_max = -2,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(visualise=False, target=None):\n",
    "    image = Image.new('L', (input_settings.height, input_settings.width))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.fontmode = '1'\n",
    "    if not target:\n",
    "        character = random.choice(('C', 'D'))\n",
    "    else:\n",
    "        character = target\n",
    "\n",
    "    x = random.randint(\n",
    "        data_set_settings[character]['x_min'],\n",
    "        data_set_settings[character]['x_max'],\n",
    "    )\n",
    "    y = random.randint(\n",
    "        data_set_settings[character]['y_min'],\n",
    "        data_set_settings[character]['y_max'],\n",
    "    )\n",
    "\n",
    "    draw.text((x, y), character, (255,), font=font)\n",
    "    data = numpy.array(image, dtype=numpy.float32) / 255\n",
    "    \n",
    "    if visualise:\n",
    "        figure(facecolor='k')\n",
    "        imshow(data, cmap='gray')\n",
    "        axis('off');\n",
    "    \n",
    "    return torch.tensor(data).unsqueeze_(0), torch.tensor(character=='C', dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 1., 1., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 1., 1., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.]]]), tensor(1.))"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAzBJREFUeJzt3cFxQyEQBcHFpfxTxkFYAv1xdwLsZYrjWzOzB0j6uX0A8DkChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAh7HX7gCfZe98+IWGtdfuEf8MPDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmECh7DHTxednBMyucPT+MEhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAI+8g2mb0w+A5+cAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmECh7A1M/v2EX+x97nz11rH3oJ38INDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAh7HX7gCc5OZNUZgLqHD84hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYWtmDG5BlB8cwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYb9/wRP7GOaO3wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_data(visualise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letter samples\n",
    "samples = [\n",
    "    [\n",
    "        [0,1,1,1],\n",
    "        [1,0,0,0],\n",
    "        [1,0,0,0],\n",
    "        [1,0,0,0],\n",
    "        [1,0,0,0],\n",
    "        [0,1,1,1]\n",
    "    ],\n",
    "    [\n",
    "        [1,1,1],\n",
    "        [1,0,0],\n",
    "        [1,0,0],\n",
    "        [1,1,1]\n",
    "    ],\n",
    "    [\n",
    "        [1,1,1,0],\n",
    "        [1,0,0,1],\n",
    "        [1,0,0,1],\n",
    "        [1,0,0,1],\n",
    "        [1,0,0,1],\n",
    "        [1,1,1,0]\n",
    "    ],\n",
    "    [\n",
    "        [1,1,0],\n",
    "        [1,0,1],\n",
    "        [1,0,1],\n",
    "        [1,1,0]\n",
    "    ]\n",
    "]\n",
    "\n",
    "sample_meta = [\n",
    "    [6,4,'C'],\n",
    "\t[4,3,'C'],\n",
    "\t[6,4,'D'],\n",
    "\t[4,3,'D']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.]]]), tensor(1.))"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAyNJREFUeJzt3bENAyEUBUGw3H/LuIKLzhjfaqaCl6x+gsQcY6wBJL1ODwD2ETiECRzCBA5hAocwgUOYwCFM4BAmcAh7nx5w11oe4n3DnPP0BDZwwSFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BC25euiX34n5MsduOaCQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIm2OMdXrEHWs9ev7fmHOensAGLjiECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCHv91EXDNBYcwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIR9AHsbDfcdYqUzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# updated gen. function to match teensy implementation\n",
    "def generate_data(visualise=False, target=None):\n",
    "    data = numpy.zeros(shape=(8,8), dtype=numpy.float32)\n",
    "    \n",
    "    sample = random.randint(0,len(samples)-1)\n",
    "    character = sample_meta[sample][2];\n",
    "    \n",
    "    x = random.randint(\n",
    "        0,\n",
    "        input_settings.width-sample_meta[sample][1]\n",
    "    )\n",
    "    y = random.randint(\n",
    "        0,\n",
    "        input_settings.height-sample_meta[sample][0]\n",
    "    )\n",
    "    \n",
    "    data[y:y+sample_meta[sample][0],x:x+sample_meta[sample][1]] = samples[sample]\n",
    "    \n",
    "    if visualise:\n",
    "        figure(facecolor='k')\n",
    "        imshow(data, cmap='gray')\n",
    "        axis('off');\n",
    "        \n",
    "    return torch.tensor(data).unsqueeze_(0), torch.tensor(character=='C', dtype=torch.float)\n",
    "        \n",
    "generate_data(visualise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a C, D batch\n",
    "def get_batch(visualise=False):\n",
    "    Cx, Cy = generate_data(target='C', visualise=visualise)\n",
    "    Dx, Dy = generate_data(target='D', visualise=visualise)\n",
    "    x = torch.stack((Cx, Dx))\n",
    "    y = torch.stack((Cy, Dy))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEYAAABGCAIAAAD+THXTAAAATUlEQVR4nO3TMQoAIQwEQL3//zk2coiWUU6OmSpNFrbYUgAA+Juaj4iInlU3pOU9yf+3z3R/KFvpQiotxv1csiUAAAAAAAAAAAAA4JgGt1sJCjqkBk8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=70x70 at 0x127D79D30>"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from numpy import interp\n",
    "from math import cos, sin, radians, pi\n",
    "\n",
    "\n",
    "def draw_weight(value, size=20):\n",
    "    rad = interp(value,[-.75,.75],[pi,0])\n",
    "    im = Image.new('RGB', (size, size), (0, 0, 0))\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    x, y, r = (\n",
    "        size/2 + size/3 * cos(rad), \n",
    "        size/2 - size/3 * sin(rad),\n",
    "        4)\n",
    "    draw.ellipse((x-r/2, y-r/2, x+r/2, y+r/2), fill=(255, 255, 255), outline=None)\n",
    "\n",
    "    return im\n",
    "\n",
    "draw_weight(-.25, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAAeCAIAAABc99v3AAABNElEQVR4nO3aMY7DMAwEQCu4/3/ZVwVwcXYl0tLeTJWKlAVx4Sg5jjLneSquuOKKK95W/FNXHYBOAh0gxM/bCziOy9eQMcbKNXuKt3XZbtvr2jUvu9qUx8k45NUtVhvSpzf082vCuh67/Pl5tZo9xdu6bLftde2al33tVTFfUx4n45BXt1hwSG8D/a1TDv+B+aKCO3SAEO8H+vVuaNY9VEXNnuJtXbbb9rp2zcuuNuVxMg55dYsFh/T2R9ExRtsvRdV7sVfxti7bbXtdu/4cL52vKQUzDnl1i9WG9OlfLgFvK7As88V071+5ADCFQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBC/cK7SKe8H8nUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=496x30 at 0x127CC0588>"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw weights\n",
    "\n",
    "def draw_weights(layer, size=20):\n",
    "    weights = layer.weight.data.clone().numpy()\n",
    "\n",
    "    n_weights = len(weights[0])\n",
    "    im = Image.new('RGB', ((size+1)*n_weights, size), (255, 255, 255))\n",
    "\n",
    "    for i in range(n_weights):\n",
    "        weight = draw_weight(weights[0][i], size=size)\n",
    "        im.paste(weight,((size+1)*i,0))\n",
    "\n",
    "    return im\n",
    "\n",
    "draw_weights(model[4], size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAD8AAAA/CAIAAADYPYeIAAAA9UlEQVR4nO2awQoDIQxEtfT/f9keetkVNJpEx8i844KTh0QxpSkZKKVgl3/Ha+Scp6IVq2YTPoMRaWardKsUCYL94Vxt/+y58Q7WrfJNkIHfOVd3zuHQHgftcdAeB+1x0B5HbPtsfOgFBv5CFqbyPcO1ml7fbxuuR3L+VN8DnNrOFgSw79CzP3+4Fk6tvaRLQuvoy78EnkBrC+7t+/OhPQ7a46A9DtrjoD0OTuW45UteyF6TuJhT931r/lWUTOZJXMx52XsV3kbsO8ff3msSH8l5ndrO/KsubEHMqe+cVX8KWAP7HgftcdAeB+1x0B4H7XHEnsp/C5qQT/FM8BQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=63x63 at 0x129F2A2E8>"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw a filter\n",
    "def draw_filter(filter):\n",
    "    matrix = Image.new('RGB', (63, 63), (255, 255, 255))\n",
    "    data = filter.view(3, 3).numpy()\n",
    "    # go over filter\n",
    "    # rows\n",
    "    for x in range(0, data.shape[0]):\n",
    "        # cols\n",
    "        for y in range(0, data.shape[1]):\n",
    "            vis = draw_weight(data[y,x])\n",
    "            matrix.paste(vis,(x*21,y*21))\n",
    "    return matrix\n",
    "\n",
    "filters = model[0].weight.data\n",
    "draw_filter(filters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARoAAAA/CAIAAACwx5DcAAACiElEQVR4nO3czU7DMBBF4Rrx/q9cFpUQrajjes74JznfikU8jp3eQiIy5RZwv99LKROH1w+Ye24u7d3w+gFbL+275aDHDx/N1DeKraDxBly1iR+Mw6m/GsffGr5XgqPYCu0TPew4HCkOnsOAq4ZM0bfklqkP4nRuwWszdzhSfNjX1jpSl3zpOEmsgzj9/Rux/U/VvlFsBY034KpN/GC0TH38KCKehz4DNquUErmvnTscKY6fw5irFhzeveTD44/jdG7xazNxOFL8gr/885bsvZOEMU4SxjhJGOMkYYyThDFOEsY4SRjjJGGMk4QxThLGOEkY4yRhykVeGpMGCP1r7fROF/UDtm7iUT/Apb0rvnTrlbN2UJl7VnmzByt3D1/zKmeor7R277ROBxW2RUl3PxnkHPJ6FczqXZG6oviej+wts8GjiBXag6xwDldDNS2KF2m3QZykXdTidNYOKnPPKm/2YOXu4Wte5QyHKz14FLFCB5WMFiUdPTfAc8j7zM3qXZGxImTPB/eW2aP1ygrfeSucw9Xs0lzpl/dOEsY4SRjjJGGMk4QxThLGOEkY4yRhjJOEMU4SxjhJGOMkYYyThLH1ioSx9crb4i4taXj9gK2XlvKCBvWGCf6a00U6hHQsE9yZZRvLDJj09d4p3qcCbLeC1EEKsr1fUst2LBPc6tUaywR3+NNJn+Jkg5F/JW2Lu51t/A77ZE/C8HGiGnHgDT0u0iGkY5ngzizbWGbMpE+PIqg+FbMapCQVzOj9kle2rxq7LqpUsDLVvKX94Ncneyf+2o5I2hZ3O9vgHfbeScIYJwljnCSMcZIwxknCGCcJY5wkjHGSMMZJwhgnCWOcJIxxkjC2XpEwP13zN1vs/so5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=282x63 at 0x127D795F8>"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw all filters\n",
    "def draw_filters(layer):\n",
    "    matrix = Image.new('RGB', (282, 63), (255, 255, 255))\n",
    "    filters = layer.weight.data.clone()\n",
    "    for i, filter in enumerate(filters):\n",
    "        vis = draw_filter(filter)\n",
    "        matrix.paste(vis, (i*(63+10),0))\n",
    "    return matrix\n",
    "\n",
    "\n",
    "draw_filters(model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARoAAAA/CAIAAACwx5DcAAACiElEQVR4nO3czU7DMBBF4Rrx/q9cFpUQrajjes74JznfikU8jp3eQiIy5RZwv99LKROH1w+Ye24u7d3w+gFbL+275aDHDx/N1DeKraDxBly1iR+Mw6m/GsffGr5XgqPYCu0TPew4HCkOnsOAq4ZM0bfklqkP4nRuwWszdzhSfNjX1jpSl3zpOEmsgzj9/Rux/U/VvlFsBY034KpN/GC0TH38KCKehz4DNquUErmvnTscKY6fw5irFhzeveTD44/jdG7xazNxOFL8gr/885bsvZOEMU4SxjhJGOMkYYyThDFOEsY4SRjjJGGMk4QxThLGOEkY4yRhykVeGpMGCP1r7fROF/UDtm7iUT/Apb0rvnTrlbN2UJl7VnmzByt3D1/zKmeor7R277ROBxW2RUl3PxnkHPJ6FczqXZG6oviej+wts8GjiBXag6xwDldDNS2KF2m3QZykXdTidNYOKnPPKm/2YOXu4Wte5QyHKz14FLFCB5WMFiUdPTfAc8j7zM3qXZGxImTPB/eW2aP1ygrfeSucw9Xs0lzpl/dOEsY4SRjjJGGMk4QxThLGOEkY4yRhjJOEMU4SxjhJGOMkYYyThLH1ioSx9crb4i4taXj9gK2XlvKCBvWGCf6a00U6hHQsE9yZZRvLDJj09d4p3qcCbLeC1EEKsr1fUst2LBPc6tUaywR3+NNJn+Jkg5F/JW2Lu51t/A77ZE/C8HGiGnHgDT0u0iGkY5ngzizbWGbMpE+PIqg+FbMapCQVzOj9kle2rxq7LqpUsDLVvKX94Ncneyf+2o5I2hZ3O9vgHfbeScIYJwljnCSMcZIwxknCGCcJY5wkjHGSMMZJwhgnCWOcJIxxkjC2XpEwP13zN1vs/so5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=282x63 at 0x127D79320>"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_filters(model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model[0].weight.data.fill_(0)\n",
    "#model[4].weight.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAABkCAIAAAA+Dt3DAAAD0UlEQVR4nO3dwW7dOAwF0LxB//+XPYtgMinQpNcSZdHOOasCDWlL9rutHYR5HcfxdqHX6zVcexzH3vLvv8DSvmpuaYvKh2vH/Lr4eH/1sQWn9nGsqrYD17vgqm28Mbrdk//sPoHffA7LPDjHqmo75Ad6d8fykuaF53DBVSs5xNiSL7snc73C4tkmL//e8pLmDT8Aqz1pycICiPQKi8/PZvlz2lhVbQeud8FV23hjNLwn273gnP+0X3ncs4eYeWW1t7ykefk5XHPVJsuHl9wkIz60C4tnm7/zNpaXNO/2AbjAY5bc6zEEaEtYABFhAUSEBRARFkBEWAARYQFEhAUQERZARFgAEWEBRIQFEHndfSAHcI2rf+r0wfNRLe2r5pa2qHy4dkyvH1F/6tzdvWe17uiTnYfLe17lFVqttNE7iz5zd2sH2w5PIS45h3UzIHfNBF26ovk9v9dE4lMahUUTHa5Qh3P4aaoGec83aUtYAJFGYfHUubt7z2rd0Sc7D5f3vMordFtprxecHeburhhsOzCptfAc1t1nu2aCrlhRyZ7fcSJxrldYNNHhCnU4h5/meR/vWo0eQ4DOhAUQERZARFgAEWEBRIQFEBEWQERYABFhAUSEBRARFkBEWAARA3uBiIG9J8q//wJL+6q5pS0qH64d84QfUa+aIFA+xqLVtNV1BpZZuDNtxxHf6KChze8s5qebFg7pLelT0rB2YvDStgPLLNzqbuOIJ3e4+QjPnWHRfGt2WbQtdnu1x++w74YAkduHRdVQ0/LhqN2mrS4ysMzCnWk7jvhGB83tfMFZNd1011jdRQ1XTAxe13asW+26qlpNdq4a+TtWeIHN3w3pvDUbLdoWu73as3f49o8hwDWEBRARFkBEWAARYQFEhAUQERZARFgAEWEBRIQFEBEWQERYABEDe4GI/1kAEWEBRIQFEBEWQERYABFhAUSEBRARFkBEWAARYQFEhAUQERZARFgAEWEBRIQFEBEWQERYAJFf3//1zK+QP45DuXLlNyr//gv+EhaLfJzW2bUNF5aUVzXZtfyZVoWHnrfl5Dde9w7lb2cfQ47/jB3so8kf/7yusKS8qsmu5c+0Kjz05z5j99KWk9943TuUvzsRFivuGH4m99IdecEJRDaExedHplOPT8OFJeVVTXYtf6ZV4aHnbTn5jde9Q/m7Ey84X6//f8lI4c16TWFJeVWTXcufaVWbEZP30paT33jdO5S/nf1uyPZ/VXgM99LteGcBRIQFEBEWQERYABFhAUSEBRARFkBEWAARYQFEhAUQERZARFgAkX8BXj0M4L2XhdsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=356x100 at 0x127C9DEB8>"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw all the weights in the net\n",
    "def draw_net():\n",
    "    im = Image.new('RGB', (356, 100), (255, 255, 255))\n",
    "    im.paste(draw_filters(model[0]), (37,0))\n",
    "    im.paste(draw_weights(model[4]), (10,80))\n",
    "\n",
    "    return im\n",
    "\n",
    "draw_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABrCAYAAABXGGiIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAArZJREFUeJzt2zFOamEUhdGDsdBGYkepWEmHzsZRUFI5DGNLwhTsnYIUxobGxAHIBO7rrPW+nGd23lo9+yd/4OM2TIZhKAByHP32GwDgZ4QbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhjjtGHx8fW/+O+f7+3jlfVVUnJyet+/f395Mxr9tut613e3SU/1t+d3c36m43m03r3T49PXXOV1XVzc1N6/56vR51t1VVDw8Prfd7enraOV9VVZ+fn637q9XqW/eb/y0F+M8IN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMcdo4fDoWP2y+XlZet+VdXZ2Vn7GWN8fHy07r+8vLTuV1UtFov2M8Z4e3tr3b+6umrdr+r/fPyN5+fn1v3pdNq6X1W1XC7bz/gOT9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEEa4AcIIN0AY4QYIc9wx+vr62jH75fz8vHW/quri4qL9jDH2+33r/jAMrftVVfP5vP2MMWazWet+9/eiqur6+rr9jLFub29b9//F/e52u/YzvsMTN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEGYyDMNvvwcAfsATN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEOYPpUVDXdix804AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize weights\n",
    "def visualize_filters(layer):\n",
    "    filters = layer.weight.data.clone()\n",
    "    # visualize\n",
    "    for i in range(0, len(filters)):\n",
    "        data = filters[i].view(3, 3)\n",
    "        subplot(1, 4, i+1)\n",
    "        imshow(data, cmap='gray', vmin=-1, vmax=1)\n",
    "        axis('off');\n",
    "        \n",
    "visualize_filters(model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up network training\n",
    "nb_epochs = 10_000\n",
    "lr = 1e-3\n",
    "optimiser = optim.SGD(params=model.parameters(), lr=lr)\n",
    "#loss = nn.BCEWithLogitsLoss()\n",
    "loss = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.001\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH]: 9900, [LOSS]: 0.204992, [ACCURACY]: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(nb_epochs):\n",
    "    # Training steps\n",
    "    X, Y = generate_data()\n",
    "    logits = model(X.unsqueeze(0))  # feed-forward\n",
    "    \n",
    "    # not sure if I'm doing this right ...\n",
    "    logits = logits.squeeze(-2)\n",
    "    Y = Y.unsqueeze(0)\n",
    "\n",
    "    J = loss(logits, Y)  # computes the loss\n",
    "    model.zero_grad()  # cleans up previous gradients\n",
    "    J.backward()\n",
    "    optimiser.step()\n",
    "    \n",
    "    # Accuracy computation and display\n",
    "    score, predicted = torch.max(logits, 0)\n",
    "    acc = (Y == (logits > 0)).sum().float() / len(Y)\n",
    "    \n",
    "    if(epoch % 100 == 0):\n",
    "        display.clear_output(wait=True)\n",
    "        print(\"[EPOCH]: %i, [LOSS]: %.6f, [ACCURACY]: %.3f\" % (epoch, J.item(), acc))\n",
    "        \n",
    "        continue\n",
    "        \n",
    "        print(model[0].weight.data)\n",
    "        \n",
    "        figure(figsize=(10, 20))\n",
    "        #visualize_filters(model[0])\n",
    "        im = draw_net()\n",
    "        imshow(numpy.asarray(im), aspect='equal', interpolation='nearest')\n",
    "        \n",
    "        # im.save('%s.png' % epoch)\n",
    "        \n",
    "        #draw_filters(model[0]).save('%i.png' % epoch)\n",
    "        axis('off');\n",
    "        pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAyVJREFUeJzt3cENAjEQBEEvuvxTNhEg8TkMTVUEI0utfXrWWnsBSY/TA4D7CBzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmECh7Dr9IBfsvc+PSFhZk5P+BsuOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMJ8XfTFql/8fPILqOobvssFhzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQdp0ewGt779MTbjEzpyf8DRccwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHsFlrNT/AAlxwKBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hD0B8jMM/n59iD4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inference: C vs. D detector\n",
    "with torch.no_grad():\n",
    "    print('C' if model(generate_data(visualise=True)[0].unsqueeze_(0)) > 0 else 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x1279ddcf8>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# register hook to get activation after conv layer out\n",
    "\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "backward = {}\n",
    "def get_backward(name):\n",
    "    def hook(model, input, output):\n",
    "        backward[name] = {}\n",
    "        backward[name]['input'] = input\n",
    "        backward[name]['output'] = output\n",
    "    return hook\n",
    "\n",
    "model[0].register_forward_hook(get_activation('act'))\n",
    "model[1].register_forward_hook(get_activation('relu'))\n",
    "model[2].register_forward_hook(get_activation('pool'))\n",
    "model[3].register_forward_hook(get_activation('flatten'))\n",
    "\n",
    "model[0].register_backward_hook(get_backward('conv'))\n",
    "model[1].register_backward_hook(get_backward('relu'))\n",
    "model[2].register_backward_hook(get_backward('pool'))\n",
    "model[3].register_backward_hook(get_backward('flatten'))\n",
    "model[4].register_backward_hook(get_backward('lin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABrCAYAAABXGGiIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAABC9JREFUeJzt3MFKVXsYxuFPs9ggBJk00AgpMimvoAuoSZfQqEk30KBRNG7Q1TSJoGGzRIJIHQnirqTSPbFSyjM5F+C7D/vEF88zfl3LvTb8XBP/UycnJwVAH9N/+hcAICPcAM0IN0Azwg3QjHADNCPcAM0IN0Azwg3QjHADNDMziYu+fPky+nfMM2fORNdfWVmJ9pubm9G+qmo0GkX7w8PDaH///v2p6Af+9ejRo+jZDofD6PpLS0vR/uzZs9G+qur69evR/ujoKNo/ePBgrGd7586d6Nmmz2pvby/az83NRfuqqsFgMNH98+fPx3q2VVUPHz6Mnu/s7Gx0/fX19Wj/9evXaF9Vtbi4GO1XV1ej/bNnz071fL1xAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAMxM5q+Tbt2/Rfn9/P9qn5ytMT+d/ny5cuBDt07NKxpV+9idPnkT79ByYL1++RPuqqo2NjWi/tbUV32Mc8/Pz0f7g4CDap8/2x48f0b6q6ubNm9E+/S7+i52dnWh/+/btaP/06dNoP85ZJdvb29H+48eP8T1Owxs3QDPCDdCMcAM0I9wAzQg3QDPCDdCMcAM0I9wAzQg3QDPCDdCMcAM0M5GzSo6Pj6P9xYsXo316XsDf5NevX9H+w4cP0f7NmzfR/m+ytrYW7R8/fhzt3717F+3HOWPn/zx7JHX+/PloPxwOo/2LFy+ifWfeuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhmZhIXvXXrVrSfmpqK9q9fv472w+Ew2ldVzc/PR/srV67E9xjH3bt3o/3MTPYVv337Ntpvb29H+6qq5eXlaH/58uX4HuNYWVmJ9p8+fYr26XcxGo2ifVXVwsLCxO8xrnPnzkX7V69eRfv0sy8uLkb7qqpr165F+58/f8b3OA1v3ADNCDdAM8IN0IxwAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAM8IN0MxEzio5OTmJ9jdu3Ij2ly5divabm5vRvio/w+Hw8DC+xzimp7O/teln//37d7RPz26oqrp69Wq0Pzo6iu8xjt3d3Wj//fv3aL+1tRXt5+bmon1V1efPn6P9YDCI7zGue/fuRfv0TJv0DKP3799H+6qqg4ODaL+6uhrf4zS8cQM0I9wAzQg3QDPCDdCMcAM0I9wAzQg3QDPCDdCMcAM0I9wAzQg3QDNT6bkiAPxZ3rgBmhFugGaEG6AZ4QZoRrgBmhFugGaEG6AZ4QZoRrgBmhFugGaEG6AZ4QZoRrgBmhFugGaEG6AZ4QZoRrgBmhFugGaEG6AZ4QZoRrgBmhFugGaEG6CZfwDfULk2eUehcgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inference: C vs. D detector\n",
    "with torch.no_grad():\n",
    "    print('C' if model(generate_data(visualise=False)[0].unsqueeze_(0)) > 0 else 'D')\n",
    "    \n",
    "    # visualize activations after convolution\n",
    "    for i, act in enumerate(activation['act'][0]):\n",
    "        data = act.view(6,6)\n",
    "        subplot(1, 4, i+1)\n",
    "        imshow(data, cmap='gray', vmin=-1, vmax=1)\n",
    "        axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# A printout of sample data, activations, outputs to troubleshoot Teensy implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONV WEIGHTS\n",
      "[[[ 0.2017441   0.00308158  0.04606714]\n",
      "  [ 0.07480983  0.11689769  0.30476084]\n",
      "  [-0.24218692 -0.14427844  0.19337441]]\n",
      "\n",
      " [[ 0.30300942  0.30281624  0.32107574]\n",
      "  [ 0.04421493 -0.2898609  -0.02634343]\n",
      "  [-0.21836622 -0.30158904  0.25087616]]\n",
      "\n",
      " [[ 0.30892864 -0.33250934  0.06331794]\n",
      "  [-0.06391373 -0.05740379 -0.15258563]\n",
      "  [ 0.10691884 -0.1978942   0.11555099]]\n",
      "\n",
      " [[ 0.18961638  0.25415832  0.14558695]\n",
      "  [-0.33572823 -0.22541218  0.14864472]\n",
      "  [ 0.05087484 -0.26549476 -0.21621124]]]\n",
      "CONV BIAS\n",
      "[ 0.28327325  0.23270558 -0.10685033 -0.07848678]\n",
      "\n",
      "LIN WEIGHTS\n",
      "[[-2.2068898e-01 -2.1241444e-04 -1.3680935e-01 -1.7643958e-01\n",
      "   1.5825884e-02  1.4667754e-01 -6.2232032e-02  1.5228274e-01\n",
      "  -1.4018767e-01  2.4638823e-01  1.6870129e-01 -2.3665445e-01\n",
      "  -1.4726459e-02  1.2934357e-01  1.0478461e-01  1.1715993e-01]]\n",
      "LIN BIAS\n",
      "[0.15213825]\n"
     ]
    }
   ],
   "source": [
    "print(\"CONV WEIGHTS\")\n",
    "print(model[0].weight.clone().detach().squeeze(1).numpy())\n",
    "print('CONV BIAS')\n",
    "print(model[0].bias.clone().detach().numpy())\n",
    "\n",
    "print('\\nLIN WEIGHTS')\n",
    "print(model[4].weight.clone().detach().numpy())\n",
    "print('LIN BIAS')\n",
    "print(model[4].bias.clone().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 1., 1., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 1., 1., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]]]), tensor(1.))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAx9JREFUeJzt3bENwzAQBEG+4f5bpmPlkiksZiq4gIsPOWutvYCkz+kBwHMEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFD2Pf0AN5h7316QsLMnJ5w4YJDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhzNdFL/bP74Te9uUO93DBIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziEzVprnx7BeXt7BneYmdMTLlxwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwvxNBmEuOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMJ+zG0N94R9oR8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dat = generate_data(visualise=True)\n",
    "print(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n",
      "tensor([[ 0.2833,  0.4766,  0.4438,  0.4627,  0.7797,  0.4750],\n",
      "        [ 0.2833,  0.7814,  0.3020,  0.1650,  0.5342,  0.4881],\n",
      "        [ 0.2833,  0.8275,  0.2590,  0.3176,  0.2833,  0.2833],\n",
      "        [ 0.2833,  0.8275,  0.2590,  0.3176,  0.2833,  0.2833],\n",
      "        [ 0.2833,  0.6341,  0.5966,  0.6089,  0.0902, -0.1032],\n",
      "        [ 0.2833,  0.3293,  0.5911,  0.9067,  0.7797,  0.4750]])\n",
      "tensor([[ 0.2327,  0.4836, -0.0952, -0.3019, -0.0393, -0.0129],\n",
      "        [ 0.2327,  0.4572, -0.0377,  0.6824,  1.1596,  0.8385],\n",
      "        [ 0.2327,  0.7783, -0.0559,  0.3616,  0.2327,  0.2327],\n",
      "        [ 0.2327,  0.7783, -0.0559,  0.3616,  0.2327,  0.2327],\n",
      "        [ 0.2327,  0.5274,  0.4965,  0.5292, -0.0364, -0.2872],\n",
      "        [ 0.2327,  0.5538,  0.5092,  0.2195, -0.0393, -0.0129]])\n",
      "tensor([[-0.1069,  0.0087, -0.4573, -0.2099, -0.3808, -0.2282],\n",
      "        [-0.1069, -0.1439, -0.2988, -0.3330, -0.0671, -0.1304],\n",
      "        [-0.1069, -0.0806, -0.6947,  0.2451, -0.1069, -0.1069],\n",
      "        [-0.1069, -0.0806, -0.6947,  0.2451, -0.1069, -0.1069],\n",
      "        [-0.1069, -0.1961, -0.3812,  0.0558, -0.0823, -0.1978],\n",
      "        [-0.1069, -0.0435, -0.5919, -0.0079, -0.3808, -0.2282]])\n",
      "tensor([[-7.8487e-02, -2.9470e-01, -1.9534e-01, -1.0438e-01, -4.9098e-01,\n",
      "         -6.3963e-01],\n",
      "        [-7.8487e-02, -1.4605e-01, -4.2381e-01,  3.6405e-02,  5.1087e-01,\n",
      "          3.6529e-01],\n",
      "        [-7.8487e-02, -4.6636e-04, -3.1524e-01, -1.7372e-01, -7.8487e-02,\n",
      "         -7.8487e-02],\n",
      "        [-7.8487e-02, -4.6636e-04, -3.1524e-01, -1.7372e-01, -7.8487e-02,\n",
      "         -7.8487e-02],\n",
      "        [-7.8487e-02,  2.1574e-01, -2.6595e-01, -7.0630e-01, -5.0932e-01,\n",
      "         -2.9311e-01],\n",
      "        [-7.8487e-02,  6.7100e-02,  3.2432e-01,  3.4362e-02, -4.9098e-01,\n",
      "         -6.3963e-01]])\n",
      "\n",
      "\n",
      "relu:\n",
      "tensor([[[[0.2833, 0.4766, 0.4438, 0.4627, 0.7797, 0.4750],\n",
      "          [0.2833, 0.7814, 0.3020, 0.1650, 0.5342, 0.4881],\n",
      "          [0.2833, 0.8275, 0.2590, 0.3176, 0.2833, 0.2833],\n",
      "          [0.2833, 0.8275, 0.2590, 0.3176, 0.2833, 0.2833],\n",
      "          [0.2833, 0.6341, 0.5966, 0.6089, 0.0902, 0.0000],\n",
      "          [0.2833, 0.3293, 0.5911, 0.9067, 0.7797, 0.4750]],\n",
      "\n",
      "         [[0.2327, 0.4836, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2327, 0.4572, 0.0000, 0.6824, 1.1596, 0.8385],\n",
      "          [0.2327, 0.7783, 0.0000, 0.3616, 0.2327, 0.2327],\n",
      "          [0.2327, 0.7783, 0.0000, 0.3616, 0.2327, 0.2327],\n",
      "          [0.2327, 0.5274, 0.4965, 0.5292, 0.0000, 0.0000],\n",
      "          [0.2327, 0.5538, 0.5092, 0.2195, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0087, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.2451, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.2451, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0558, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0364, 0.5109, 0.3653],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.2157, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0671, 0.3243, 0.0344, 0.0000, 0.0000]]]])\n",
      "\n",
      "\n",
      "pool:\n",
      "tensor([[[[0.8275, 0.7797],\n",
      "          [0.8275, 0.9067]],\n",
      "\n",
      "         [[0.7783, 1.1596],\n",
      "          [0.7783, 0.5292]],\n",
      "\n",
      "         [[0.0087, 0.2451],\n",
      "          [0.0000, 0.2451]],\n",
      "\n",
      "         [[0.0000, 0.5109],\n",
      "          [0.3243, 0.0344]]]])\n",
      "\n",
      "\n",
      "flatten:\n",
      "tensor([[0.8275, 0.7797, 0.8275, 0.9067, 0.7783, 1.1596, 0.7783, 0.5292, 0.0087,\n",
      "         0.2451, 0.0000, 0.2451, 0.0000, 0.5109, 0.3243, 0.0344]])\n",
      "\n",
      "\n",
      "0.015991762280464172\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABrCAYAAABXGGiIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAABCtJREFUeJzt3D9LlQ0cx+GfaRFEEcdwMIdEOBm9g9aGlpb2Jl9CQzSJvhGnXoK0CC5FW1JBhBHhEAcJD9lUIGXL82zPA36F7Pzguubvuf9ZH8/iPXV8fFwA9HHub18AABnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboJmZP3HQp0+fRn+OOT8/Hx3/6Ogo2k9PT0f7qqrl5eVov7u7G+3v3r07FX3gHxsbG9GzvXHjRnT8Z8+eRfvRaBTtq/JrOn/+fLRfX18/1bN99OhR9GyvXr0aHf/FixfRPn1OVVVfvnyJ9oPBINpvbGyc6tlWVT1+/Dh6vp8/f46Of/ny5Wh/6dKlaF9V9fr162g/Ho+j/Zs3b070fH3jBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZv7Iu0pSw+Ew2j9//jzaf/36NdpXVV28eDHanzs3mb8Df/78Ge3T+15dXY32Vfl7YA4ODuJznIX0uq5duxbtDw8Po31V/mx//PgRn+OspM/r48eP0f7OnTvRvqpqbW0t2qfvKjmpyawNAP9LuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZibiXSUXLlyI9kdHR9F+dnY22ldV7e3txZ+ZRLdu3Yr229vb0f79+/fRvqrq5cuX8WcSKysrf/T4/0rf67KzsxPtnzx5Eu2rqt6+fRvtJ/UdO1VVg8Eg2l+5ciXaj0ajaF9Vtbm5GX8m8eDBgxPtJvenBsB/Em6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhm5m9fQFXV/v5+tL99+3a0n5qaivZVVdvb29F+NBpF+4cPH0b709rb24v29+7di/YzM/k/oVevXkX79B5WVlai/Wl9+/Yt2i8vL0f79P9FVf7zSO/hLC0sLET7T58+Rfutra1oX1U1Pz8f7a9fvx6f4yR84wZoRrgBmhFugGaEG6AZ4QZoRrgBmhFugGaEG6AZ4QZoRrgBmhFugGYm4l0lu7u70X5xcTHa37x5M9pXVc3NzUX79B7OyvT0dLT/9etXtD/NfafnWFpais9xFmZnZ6P9zs5OtP/+/Xu0r6r68OFDtB8MBvE5zsp4PI729+/fj/bD4TDaV+XvMHr37l18jpPwjRugGeEGaEa4AZoRboBmhBugGeEGaEa4AZoRboBmhBugGeEGaEa4AZqZOj4+/tvXAEDAN26AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmjmN47srRvTL6zwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    #dat = generate_data(visualise=False)\n",
    "    x = dat[0].clone().unsqueeze_(0)\n",
    "    y = model(x)\n",
    "    print('C' if y > 0 else 'D')\n",
    "    \n",
    "    # visualize activations after convolution\n",
    "    for i, act in enumerate(activation['act'][0]):\n",
    "        print(act)\n",
    "        data = act.view(6,6)\n",
    "        subplot(1, 4, i+1)\n",
    "        imshow(data, cmap='gray', vmin=-1, vmax=1)\n",
    "        axis('off');\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"relu:\")\n",
    "    print(activation[\"relu\"])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"pool:\")\n",
    "    print(activation[\"pool\"])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"flatten:\")\n",
    "    print(activation[\"flatten\"])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(y.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out    0.015991762280464172\n",
      "target 1.0\n",
      "loss   0.6851832270622253\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "X, Y = dat\n",
    "logits = model(X.clone().unsqueeze_(0))  # feed-forward\n",
    "\n",
    "# not sure if I'm doing this right ...\n",
    "logits = logits.squeeze(-2)\n",
    "Y = Y.unsqueeze(0)\n",
    "\n",
    "J = loss(logits, Y)  # computes the loss\n",
    "\n",
    "print('out   ', logits.item())\n",
    "print('target', Y.item())\n",
    "print('loss  ', J.item())\n",
    "\n",
    "model.zero_grad()  # cleans up previous gradients\n",
    "\n",
    "J.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Framework-less backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_old = {\n",
    "    'lin': model[4].weight.clone().detach(),\n",
    "    'lin_bias': model[4].bias.clone().detach(),\n",
    "    'conv': model[0].weight.clone().detach(),\n",
    "    'conv_bias': model[0].bias.clone().detach(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    # e^x => math.e ** 2\n",
    "    return 1 / (1 + math.e ** -x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L:  0.6851832270622253\n",
      "dL: -0.4960021376609802\n",
      "\n",
      "GOAL\n",
      " 0.6851832270622253 \n",
      " -0.4960021376609802\n"
     ]
    }
   ],
   "source": [
    "# BCEwithLogits Loss, formula from\n",
    "# https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/Loss.cpp\n",
    "\n",
    "y = logits\n",
    "\n",
    "max_val = max(0, -y)\n",
    "l = (1-Y) * y + max_val + math.log((math.e ** -max_val) + math.e ** (-y-max_val))\n",
    "\n",
    "# Derivative of BCEwithLogits Loss\n",
    "# grad_input = (input.sigmoid() - target).mul_(grad);\n",
    "dl = (sigmoid(y) - Y) * 1\n",
    "\n",
    "print(\"L: \", l.item())\n",
    "print(\"dL:\", dl.item())\n",
    "print('\\nGOAL\\n', J.item(), \"\\n\", backward[\"lin\"][\"input\"][0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dW\n",
      " tensor([[-0.4104, -0.3868, -0.4104, -0.4497, -0.3860, -0.5752, -0.3860, -0.2625,\n",
      "         -0.0043, -0.1216, -0.0000, -0.1216, -0.0000, -0.2534, -0.1609, -0.0170]],\n",
      "       grad_fn=<MulBackward0>)\n",
      " GOAL\n",
      " tensor([[-0.4104, -0.3868, -0.4104, -0.4497, -0.3860, -0.5752, -0.3860, -0.2625,\n",
      "         -0.0043, -0.1216,  0.0000, -0.1216,  0.0000, -0.2534, -0.1609, -0.0170]])\n",
      " DIFF 0.0\n",
      "\n",
      "\n",
      "dX\n",
      " tensor([[ 1.0946e-01,  1.0536e-04,  6.7858e-02,  8.7514e-02, -7.8497e-03,\n",
      "         -7.2752e-02,  3.0867e-02, -7.5533e-02,  6.9533e-02, -1.2221e-01,\n",
      "         -8.3676e-02,  1.1738e-01,  7.3044e-03, -6.4155e-02, -5.1973e-02,\n",
      "         -5.8112e-02]], grad_fn=<MulBackward0>)\n",
      " GOAL\n",
      " tensor([[ 1.0946e-01,  1.0536e-04,  6.7858e-02,  8.7514e-02, -7.8497e-03,\n",
      "         -7.2752e-02,  3.0867e-02, -7.5533e-02,  6.9533e-02, -1.2221e-01,\n",
      "         -8.3676e-02,  1.1738e-01,  7.3044e-03, -6.4155e-02, -5.1973e-02,\n",
      "         -5.8112e-02]])\n",
      " DIFF 0.0\n",
      "\n",
      "\n",
      "dB\n",
      " tensor([-0.4960], grad_fn=<MulBackward0>)\n",
      " GOAL\n",
      " tensor([-0.4960])\n",
      " DIFF 0.0\n"
     ]
    }
   ],
   "source": [
    "# backward pass, linear layer\n",
    "dx = model[4].weight * dl\n",
    "dw = activation['flatten'] * dl\n",
    "db = dl\n",
    "\n",
    "print('\\ndW\\n',dw)\n",
    "print(' GOAL\\n', model[4].weight.grad)\n",
    "print(' DIFF', numpy.sum(a=(dw.detach().numpy() - model[4].weight.grad.detach().numpy())))\n",
    "\n",
    "print('\\n\\ndX\\n',dx)\n",
    "print(' GOAL\\n', backward[\"lin\"][\"input\"][1])\n",
    "print(' DIFF', numpy.sum(a=(dx.detach().numpy() - numpy.array(backward[\"lin\"][\"input\"][1]))))\n",
    "\n",
    "print('\\n\\ndB\\n',db)\n",
    "print(' GOAL\\n', model[4].bias.grad)\n",
    "print(' DIFF', numpy.sum(a=(db.detach().numpy() - model[4].bias.grad.detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0946e-01,  1.0536e-04],\n",
      "         [ 6.7858e-02,  8.7514e-02]],\n",
      "\n",
      "        [[-7.8497e-03, -7.2752e-02],\n",
      "         [ 3.0867e-02, -7.5533e-02]],\n",
      "\n",
      "        [[ 6.9533e-02, -1.2221e-01],\n",
      "         [-8.3676e-02,  1.1738e-01]],\n",
      "\n",
      "        [[ 7.3044e-03, -6.4155e-02],\n",
      "         [-5.1973e-02, -5.8112e-02]]], grad_fn=<ViewBackward>)\n",
      "\n",
      "GOAL\n",
      " (tensor([[[[ 1.0946e-01,  1.0536e-04],\n",
      "          [ 6.7858e-02,  8.7514e-02]],\n",
      "\n",
      "         [[-7.8497e-03, -7.2752e-02],\n",
      "          [ 3.0867e-02, -7.5533e-02]],\n",
      "\n",
      "         [[ 6.9533e-02, -1.2221e-01],\n",
      "          [-8.3676e-02,  1.1738e-01]],\n",
      "\n",
      "         [[ 7.3044e-03, -6.4155e-02],\n",
      "          [-5.1973e-02, -5.8112e-02]]]]),)\n"
     ]
    }
   ],
   "source": [
    "# backward pass, flatten\n",
    "out = dx.reshape((4,2,2))\n",
    "goal = backward['pool']['output']\n",
    "\n",
    "print(out)\n",
    "print('\\nGOAL\\n', goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GOAL\n",
      " (tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0536e-04,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00,  1.0946e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00,  6.7858e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  8.7514e-02,  0.0000e+00,\n",
      "            0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -7.2752e-02,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00, -7.8497e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00,  3.0867e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -7.5533e-02,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  6.9533e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2221e-01,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [-8.3676e-02,  0.0000e+00,  0.0000e+00,  1.1738e-01,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00]],\n",
      "\n",
      "         [[ 7.3044e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -6.4155e-02,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00, -5.1973e-02, -5.8112e-02,  0.0000e+00,\n",
      "            0.0000e+00]]]]),)\n"
     ]
    }
   ],
   "source": [
    "# backward pass, maxpool2d\n",
    "# not implemented here...\n",
    "# the gradient gets assigned to the item that was max() during forward pass\n",
    "\n",
    "print('\\nGOAL\\n', backward['pool']['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0536e-04,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  1.0946e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  6.7858e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  8.7514e-02,  0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -7.2752e-02,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00, -7.8497e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  3.0867e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -7.5533e-02,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  6.9533e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2221e-01,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1738e-01,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -6.4155e-02,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00, -5.1973e-02, -5.8112e-02,  0.0000e+00,\n",
      "           0.0000e+00]]])\n",
      "\n",
      "GOAL\n",
      " tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0536e-04,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  1.0946e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  6.7858e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  8.7514e-02,  0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -7.2752e-02,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00, -7.8497e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  3.0867e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -7.5533e-02,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  6.9533e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2221e-01,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1738e-01,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -6.4155e-02,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00, -5.1973e-02, -5.8112e-02,  0.0000e+00,\n",
      "           0.0000e+00]]])\n",
      "\n",
      "DIFF 0.0\n"
     ]
    }
   ],
   "source": [
    "# derivative of relu\n",
    "# see here: https://towardsdatascience.com/back-propagation-simplified-218430e21ad0\n",
    "# d = numpy.array(backward['pool']['input'][0][0][0], copy = True)\n",
    "# d[activation['relu'][0][0] < 0] = 0.\n",
    "\n",
    "relu_grad = backward['pool']['input'][0][0].clone().detach()\n",
    "\n",
    "for f in range(0,4):\n",
    "    for y in range(0,6):\n",
    "        for x in range(0,6):\n",
    "            if(activation['act'][0][f][y][x] <= 0):\n",
    "                relu_grad[f][y][x] = 0\n",
    "                \n",
    "print(relu_grad)\n",
    "print('\\nGOAL\\n', backward['relu']['input'][0][0])\n",
    "\n",
    "print('\\nDIFF', (backward['relu']['input'][0][0] - relu_grad).sum().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Do an optimiser step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_new = {\n",
    "    'lin': model[4].weight.clone().detach(),\n",
    "    'lin_bias': model[4].bias.clone().detach(),\n",
    "    'conv': model[0].weight.clone().detach(),\n",
    "    'conv_bias': model[0].bias.clone().detach(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.2065e-01, -1.7374e-04, -1.3677e-01, -1.7639e-01,  1.5864e-02,\n",
      "          1.4674e-01, -6.2193e-02,  1.5231e-01, -1.4019e-01,  2.4640e-01,\n",
      "          1.6870e-01, -2.3664e-01, -1.4726e-02,  1.2937e-01,  1.0480e-01,\n",
      "          1.1716e-01]])\n",
      "\n",
      "GOAL\n",
      " [-2.2064795e-01 -1.7373908e-04 -1.3676831e-01 -1.7639461e-01\n",
      "  1.5864490e-02  1.4673506e-01 -6.2193427e-02  1.5230900e-01\n",
      " -1.4018723e-01  2.4640039e-01  1.6870129e-01 -2.3664229e-01\n",
      " -1.4726459e-02  1.2936892e-01  1.0480069e-01  1.1716164e-01]\n",
      "\n",
      "DIFF: 0.0\n"
     ]
    }
   ],
   "source": [
    "# lin layer, weight update\n",
    "# https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n",
    "weight_update = w_old['lin'].clone()\n",
    "weight_update -= lr * dw.clone().detach()\n",
    "\n",
    "# goal\n",
    "goal = w_new['lin'][0].numpy()\n",
    "print(weight_update)\n",
    "print('\\nGOAL\\n', goal)\n",
    "print('\\nDIFF:', numpy.sum(a=(goal - weight_update[0].numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALC: 0.15218785405158997\n",
      "GOAL: 0.15218785405158997\n",
      "DIFF: 0.0\n"
     ]
    }
   ],
   "source": [
    "# lin layer, bias update\n",
    "new_bias = w_old['lin_bias'].clone() - db * lr\n",
    "\n",
    "print('CALC:', new_bias.item())\n",
    "print('GOAL:', model[4].bias.item())\n",
    "print('DIFF:', (model[4].bias.item()-new_bias).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### conv weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 8.75144079e-02  0.00000000e+00  1.77319944e-01]\n",
      "  [ 1.05358013e-04  8.76197666e-02  2.64939696e-01]\n",
      "  [ 0.00000000e+00  0.00000000e+00  1.77319944e-01]]\n",
      "\n",
      " [[-1.48284942e-01 -7.27523714e-02 -4.97348234e-02]\n",
      "  [-7.55325705e-02  0.00000000e+00  2.30175480e-02]\n",
      "  [ 0.00000000e+00 -7.55325705e-02 -5.25150225e-02]]\n",
      "\n",
      " [[-4.82797623e-03  0.00000000e+00  0.00000000e+00]\n",
      "  [-4.82797623e-03  0.00000000e+00  0.00000000e+00]\n",
      "  [-4.82797623e-03  0.00000000e+00  6.95333853e-02]]\n",
      "\n",
      " [[-1.22266263e-01 -1.16128072e-01 -6.41546845e-02]\n",
      "  [ 0.00000000e+00 -5.81115782e-02 -1.10084966e-01]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]]\n",
      "\n",
      "GOAL\n",
      " tensor([[[ 8.7514e-02,  0.0000e+00,  1.7732e-01],\n",
      "         [ 1.0536e-04,  8.7620e-02,  2.6494e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  1.7732e-01]],\n",
      "\n",
      "        [[-1.4828e-01, -7.2752e-02, -4.9735e-02],\n",
      "         [-7.5533e-02,  0.0000e+00,  2.3018e-02],\n",
      "         [ 0.0000e+00, -7.5533e-02, -5.2515e-02]],\n",
      "\n",
      "        [[-4.8280e-03,  0.0000e+00,  0.0000e+00],\n",
      "         [-4.8280e-03,  0.0000e+00,  0.0000e+00],\n",
      "         [-4.8280e-03,  0.0000e+00,  6.9533e-02]],\n",
      "\n",
      "        [[-1.2227e-01, -1.1613e-01, -6.4155e-02],\n",
      "         [ 0.0000e+00, -5.8112e-02, -1.1008e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "DIFF 0.0\n"
     ]
    }
   ],
   "source": [
    "# backward pass, conv\n",
    "\n",
    "# only doing it here, after optimiser.step() so that model[0].weight.grad has a gradient for comparison\n",
    "\n",
    "# incoming gradient\n",
    "g = backward['relu']['input'][0][0]\n",
    "\n",
    "# gradient var\n",
    "conv_grad = torch.zeros((4,3,3))\n",
    "\n",
    "# filters\n",
    "for f in range(0,4):\n",
    "    for fy in range(0,3):\n",
    "        for fx in range(0,3):\n",
    "            # slide gradient over input X to get dF\n",
    "            for y in range(0,6):\n",
    "                for x in range(0,6):\n",
    "                    conv_grad[f][fy][fx] += g[f][y][x] * dat[0][0][y+fy][x+fx]\n",
    "\n",
    "goal = model[0].weight.grad.clone().squeeze(1)\n",
    "\n",
    "print(conv_grad.numpy())\n",
    "print('\\nGOAL\\n', goal)\n",
    "print('DIFF', (conv_grad - goal).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2017,  0.0031,  0.0460],\n",
      "         [ 0.0748,  0.1169,  0.3047],\n",
      "         [-0.2422, -0.1443,  0.1934]],\n",
      "\n",
      "        [[ 0.3030,  0.3028,  0.3211],\n",
      "         [ 0.0442, -0.2899, -0.0263],\n",
      "         [-0.2184, -0.3016,  0.2509]],\n",
      "\n",
      "        [[ 0.3089, -0.3325,  0.0633],\n",
      "         [-0.0639, -0.0574, -0.1526],\n",
      "         [ 0.1069, -0.1979,  0.1155]],\n",
      "\n",
      "        [[ 0.1896,  0.2542,  0.1456],\n",
      "         [-0.3357, -0.2254,  0.1487],\n",
      "         [ 0.0509, -0.2655, -0.2162]]])\n",
      "\n",
      "GOAL: tensor([[[ 0.2017,  0.0031,  0.0460],\n",
      "         [ 0.0748,  0.1169,  0.3047],\n",
      "         [-0.2422, -0.1443,  0.1934]],\n",
      "\n",
      "        [[ 0.3030,  0.3028,  0.3211],\n",
      "         [ 0.0442, -0.2899, -0.0263],\n",
      "         [-0.2184, -0.3016,  0.2509]],\n",
      "\n",
      "        [[ 0.3089, -0.3325,  0.0633],\n",
      "         [-0.0639, -0.0574, -0.1526],\n",
      "         [ 0.1069, -0.1979,  0.1155]],\n",
      "\n",
      "        [[ 0.1896,  0.2542,  0.1456],\n",
      "         [-0.3357, -0.2254,  0.1487],\n",
      "         [ 0.0509, -0.2655, -0.2162]]])\n",
      "DIFF: 0.0\n"
     ]
    }
   ],
   "source": [
    "new_weights = w_old['conv'].clone().squeeze(1)\n",
    "new_weights -= lr * conv_grad\n",
    "goal = w_new['conv'].clone().squeeze(1)\n",
    "\n",
    "print(new_weights)\n",
    "print('\\nGOAL:', goal)\n",
    "print('DIFF:', (goal - new_weights).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2832,  0.2327, -0.1069, -0.0785])\n",
      "GOAL: tensor([ 0.2832,  0.2327, -0.1069, -0.0785])\n",
      "DIFF: 0.0\n"
     ]
    }
   ],
   "source": [
    "# conv layer, bias update\n",
    "# -> sum of filter gradient is dB\n",
    "# https://stackoverflow.com/questions/3775032/how-to-update-the-bias-in-neural-network-backpropagation\n",
    "# https://datascience.stackexchange.com/questions/25081/how-to-update-bias-in-cnn\n",
    "\n",
    "# biases before weight update\n",
    "biases = w_old['conv_bias'].clone()\n",
    "\n",
    "for i in range(len(biases)):\n",
    "    biases[i] -= g[i].sum() * lr\n",
    "\n",
    "goal = model[0].bias.clone().detach()\n",
    "\n",
    "print(biases)\n",
    "print('GOAL:', goal)\n",
    "print('DIFF:', (goal - biases).sum().item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
