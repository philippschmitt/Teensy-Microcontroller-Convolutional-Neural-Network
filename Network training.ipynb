{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini neural net training\n",
    "Authors: Alfredo Canziani, Philipp Schmitt  \n",
    "Date: Tue 24 Feb 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from IPython import display\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from matplotlib.pyplot import imshow, axis, figure, subplot, pause\n",
    "import numpy\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1091f9270>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# static random seed\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input definition\n",
    "class input_settings:\n",
    "    batch_size = 1\n",
    "    channels = 1\n",
    "    height = 8\n",
    "    width = 8\n",
    "\n",
    "dummy_X = torch.randn(  # batch of inputs x\n",
    "    input_settings.batch_size,\n",
    "    input_settings.channels,\n",
    "    input_settings.height,\n",
    "    input_settings.width,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network architecture\n",
    "class model_settings:\n",
    "    conv_channels = 4\n",
    "    kernel = 3\n",
    "    pooling_kernel = 3\n",
    "    flattened = 16\n",
    "    output_size = 1\n",
    "    \n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(\n",
    "        in_channels=input_settings.channels,\n",
    "        out_channels=model_settings.conv_channels,\n",
    "        kernel_size=model_settings.kernel,\n",
    "        bias=True,\n",
    "    ),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(\n",
    "        kernel_size=model_settings.pooling_kernel,\n",
    "        stride=model_settings.pooling_kernel,\n",
    "    ),  # we have 4 x 2x2\n",
    "    nn.Flatten(),  # gives 16\n",
    "    nn.Linear(\n",
    "        in_features=model_settings.flattened,\n",
    "        out_features=model_settings.output_size,\n",
    "        bias=True,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "with torch.no_grad():\n",
    "    print(model(dummy_X).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Flatten()\n",
      "  (4): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weights and biases\n",
    "def get_weights():\n",
    "    print(\n",
    "        model[0],\n",
    "        model[0].weight,\n",
    "        model[0].bias,\n",
    "        sep='\\n',\n",
    "    )\n",
    "    print(\n",
    "        model[4],\n",
    "        model[4].weight,\n",
    "        model[4].bias,\n",
    "        sep='\\n',\n",
    "    )\n",
    "    # Maybe add some saving routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = ImageFont.truetype('Verdana', 8)  # let's keep it to Verdana 8pt\n",
    "data_set_settings = dict(\n",
    "    D=dict(\n",
    "        x_min = -1,\n",
    "        x_max = 2,\n",
    "        y_min = -3,\n",
    "        y_max = -1,\n",
    "    ),\n",
    "    C=dict(\n",
    "        x_min = 0,\n",
    "        x_max = 3,\n",
    "        y_min = -4,\n",
    "        y_max = -2,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(visualise=False, target=None):\n",
    "    image = Image.new('L', (input_settings.height, input_settings.width))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.fontmode = '1'\n",
    "    if not target:\n",
    "        character = random.choice(('C', 'D'))\n",
    "    else:\n",
    "        character = target\n",
    "\n",
    "    x = random.randint(\n",
    "        data_set_settings[character]['x_min'],\n",
    "        data_set_settings[character]['x_max'],\n",
    "    )\n",
    "    y = random.randint(\n",
    "        data_set_settings[character]['y_min'],\n",
    "        data_set_settings[character]['y_max'],\n",
    "    )\n",
    "\n",
    "    draw.text((x, y), character, (255,), font=font)\n",
    "    data = numpy.array(image, dtype=numpy.float32) / 255\n",
    "    \n",
    "    if visualise:\n",
    "        figure(facecolor='k')\n",
    "        imshow(data, cmap='gray')\n",
    "        axis('off');\n",
    "    \n",
    "    return torch.tensor(data).unsqueeze_(0), torch.tensor(character=='C', dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 1., 1., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 1., 1., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.]]]), tensor(1.))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAzBJREFUeJzt3cFxQyEQBcHFpfxTxkFYAv1xdwLsZYrjWzOzB0j6uX0A8DkChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAh7HX7gCfZe98+IWGtdfuEf8MPDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmECh7DHTxednBMyucPT+MEhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAI+8g2mb0w+A5+cAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmECh7A1M/v2EX+x97nz11rH3oJ38INDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAh7HX7gCc5OZNUZgLqHD84hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYWtmDG5BlB8cwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYb9/wRP7GOaO3wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_data(visualise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letter samples\n",
    "samples = [\n",
    "    [\n",
    "        [0,1,1,1],\n",
    "        [1,0,0,0],\n",
    "        [1,0,0,0],\n",
    "        [1,0,0,0],\n",
    "        [1,0,0,0],\n",
    "        [0,1,1,1]\n",
    "    ],\n",
    "    [\n",
    "        [1,1,1],\n",
    "        [1,0,0],\n",
    "        [1,0,0],\n",
    "        [1,1,1]\n",
    "    ],\n",
    "    [\n",
    "        [1,1,1,0],\n",
    "        [1,0,0,1],\n",
    "        [1,0,0,1],\n",
    "        [1,0,0,1],\n",
    "        [1,0,0,1],\n",
    "        [1,1,1,0]\n",
    "    ],\n",
    "    [\n",
    "        [1,1,0],\n",
    "        [1,0,1],\n",
    "        [1,0,1],\n",
    "        [1,1,0]\n",
    "    ]\n",
    "]\n",
    "\n",
    "sample_meta = [\n",
    "    [6,4,'C'],\n",
    "\t[4,3,'C'],\n",
    "\t[6,4,'D'],\n",
    "\t[4,3,'D']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0., 1., 1., 1., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 1., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.]]]), tensor(1.))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAyBJREFUeJzt3bENwzAMAEExyP4rK7V7OzIedxOw0IONAM5aay8g6XN6AOA5AocwgUOYwCFM4BAmcAgTOIQJHMIEDmHf0wPwDnv70HiHmTk9woUNDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCni17sn+eE3nZyh3vY4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwmattU8PwXl7ewZ3mJnTI1zY4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAhzugjCbHAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUPYD/JnDfdngNlNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# updated gen. function to match teensy implementation\n",
    "def generate_data(visualise=False, target=None):\n",
    "    data = numpy.zeros(shape=(8,8), dtype=numpy.float32)\n",
    "    \n",
    "    sample = random.randint(0,len(samples)-1)\n",
    "    character = sample_meta[sample][2];\n",
    "    \n",
    "    x = random.randint(\n",
    "        0,\n",
    "        input_settings.width-sample_meta[sample][1]\n",
    "    )\n",
    "    y = random.randint(\n",
    "        0,\n",
    "        input_settings.height-sample_meta[sample][0]\n",
    "    )\n",
    "    \n",
    "    data[y:y+sample_meta[sample][0],x:x+sample_meta[sample][1]] = samples[sample]\n",
    "    \n",
    "    if visualise:\n",
    "        figure(facecolor='k')\n",
    "        imshow(data, cmap='gray')\n",
    "        axis('off');\n",
    "        \n",
    "    return torch.tensor(data).unsqueeze_(0), torch.tensor(character=='C', dtype=torch.float)\n",
    "        \n",
    "generate_data(visualise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a C, D batch\n",
    "def get_batch(visualise=False):\n",
    "    Cx, Cy = generate_data(target='C', visualise=visualise)\n",
    "    Dx, Dy = generate_data(target='D', visualise=visualise)\n",
    "    x = torch.stack((Cx, Dx))\n",
    "    y = torch.stack((Cy, Dy))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEYAAABGCAIAAAD+THXTAAAATUlEQVR4nO3TMQoAIQwEQL3//zk2coiWUU6OmSpNFrbYUgAA+Juaj4iInlU3pOU9yf+3z3R/KFvpQiotxv1csiUAAAAAAAAAAAAA4JgGt1sJCjqkBk8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=70x70 at 0x1216749E8>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from numpy import interp\n",
    "from math import cos, sin, radians, pi\n",
    "\n",
    "\n",
    "def draw_weight(value, size=20):\n",
    "    rad = interp(value,[-.75,.75],[pi,0])\n",
    "    im = Image.new('RGB', (size, size), (0, 0, 0))\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    x, y, r = (\n",
    "        size/2 + size/3 * cos(rad), \n",
    "        size/2 - size/3 * sin(rad),\n",
    "        4)\n",
    "    draw.ellipse((x-r/2, y-r/2, x+r/2, y+r/2), fill=(255, 255, 255), outline=None)\n",
    "\n",
    "    return im\n",
    "\n",
    "draw_weight(-.25, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAAeCAIAAABc99v3AAABOElEQVR4nO3aQU7DUAwE0H7E/a8cNoAqQbLBcf2H9w4wdis8lJTH4zbHcQgXLly48Lbwt/vSAeik0AFCvL96gU/ff4mstWYGtoU3TykftOPabTs32Ou1BJzSqPCrT+jHl4K9Lj2PKBlXHtgW3jylfNCOa7ft/HNu+X3Vvi13n3/AKU0LPy30V/2Uw38w/L6Gr8cZz9ABQowo9OfHQyXPocoD28Kbp5QP2nHttp0b7PVaAk5pWvjpl6Jrrc5vV259L8r1nErbQdYO2nHt/u67776qPhL1nH/AKY0Kv/ovl/m/4WFfw+9r+Hr8asQjFwD+TqEDhFDoACEUOkAIhQ4QQqEDhFDoACEUOkAIhQ4QQqEDhFDoACEUOkAIhQ4QQqEDhFDoACEUOkAIhQ4QQqEDhFDoACEUOkCID0yt2x3j4/1FAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=496x30 at 0x11E8C2390>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw weights\n",
    "\n",
    "def draw_weights(layer, size=20):\n",
    "    weights = layer.weight.data.clone().numpy()\n",
    "\n",
    "    n_weights = len(weights[0])\n",
    "    im = Image.new('RGB', ((size+1)*n_weights, size), (255, 255, 255))\n",
    "\n",
    "    for i in range(n_weights):\n",
    "        weight = draw_weight(weights[0][i], size=size)\n",
    "        im.paste(weight,((size+1)*i,0))\n",
    "\n",
    "    return im\n",
    "\n",
    "draw_weights(model[4], size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAD8AAAA/CAIAAADYPYeIAAAA+klEQVR4nO2awQ4CIQxEqfH/fxkPXnQNBdritJt5V0P7XAthNrbmoPeOXf5c7yEiW6UNq3YrPBZLtJ1HZVtlqDCxT86t7T9nbn2CbatiK8yBnzm3npzk0B4H7XHQHgftcdAeR217cV70CgO/IWup3J+so4qMGM69P1kHFnnz+1H2Xat//+z2OkP7kFx8Olxruzakn7OIiCj7fv4mEI79TWByaI+D9jhoj4P2OGiPo7Y9Uzlu+ZEbcmAS10td516JwLv9WuiPM0/lgY3/Q+0zJ94+MIlPS33tWj0C27o60Utdz5xTfwo4A+ceB+1x0B4H7XHQHgftcdRO5S9Bf5BPu6a2EgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=63x63 at 0x120AC2080>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw a filter\n",
    "def draw_filter(filter):\n",
    "    matrix = Image.new('RGB', (63, 63), (255, 255, 255))\n",
    "    data = filter.view(3, 3).numpy()\n",
    "    # go over filter\n",
    "    # rows\n",
    "    for x in range(0, data.shape[0]):\n",
    "        # cols\n",
    "        for y in range(0, data.shape[1]):\n",
    "            vis = draw_weight(data[y,x])\n",
    "            matrix.paste(vis,(x*21,y*21))\n",
    "    return matrix\n",
    "\n",
    "filters = model[0].weight.data\n",
    "draw_filter(filters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARoAAAA/CAIAAACwx5DcAAACiElEQVR4nO3cy3akMAxF0dCr//+XqweZdB4YyjqSBZw9ygAL29QlgZXS9hHwer22bVs4fHzA2rm5tL3h4wMuvbS/Zw76/OGtM82NYiuoXsFVW/jBODz1n5PjP07cV4Kj2ArnT/RpyXCkQrAyOIGCq4acYm7JZ059EKd7C16bzneNk5XLblt9pC750XGSWAdx+v9vxPN/qs6NYiuoXsFVW/jBOHPq41cR8TzMKdisbdsiz7XB4UiFYGV8AjVXLTh8esmHxx/H6d7i12btBOKVH/jLP2/JPjtJGOMkYYyThDFOEsY4SRjjJGGMk4QxThLGOEkY4yRhjJOEMU4SZnvIl8akAqF/rV3e6WJ8wKWbeIwPcGl7xfu2XkG+CdOzg8raWeWdPVJ51dhs7NzG1XafnageF0gRtjnJdD8ZZBrL+0O0GntYOd7Z5tefk6p1fxXRpDdIk2k8yhX3vHucpAvZjRPS46JnB5W1s8o7e6TyqrHZ2LkdVhu9iujQiyOpOcnEJwacxvL+EK3GDmoie553z/rpAq1XmtzwmkzjUS635z47SRjjJGGMk4QxThLGOEkY4yRhjJOEMU4SxjhJGOMkYYyThDFOEsbWKxLG1iu7xV1a0vDxAZdeWsoXNMCvBlX2zbiNiWW2vWSVxeNn/P7s1KrZRXHfjPFYtv1LXtmJZba9ZPHiwR1+94xf4nTFZhcFkrbF3c5Wv8O+2ZMwfJzAZhfFfTPuYWKZbS9ZZXHkjF9eRTRsdlHZN2MwKqn9S9KD9US1tpcsUhzZ4bcGfn+zd+PbdkTStrjb2Yp32GcnCWOcJIxxkjDGScIYJwljnCSMcZIwxknCGCcJY5wkjHGSMMZJwth6RcL8A5OILmfCsf6AAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=282x63 at 0x121488CF8>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw all filters\n",
    "def draw_filters(layer):\n",
    "    matrix = Image.new('RGB', (282, 63), (255, 255, 255))\n",
    "    filters = layer.weight.data.clone()\n",
    "    for i, filter in enumerate(filters):\n",
    "        vis = draw_filter(filter)\n",
    "        matrix.paste(vis, (i*(63+10),0))\n",
    "    return matrix\n",
    "\n",
    "\n",
    "draw_filters(model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARoAAAA/CAIAAACwx5DcAAACiElEQVR4nO3cy3akMAxF0dCr//+XqweZdB4YyjqSBZw9ygAL29QlgZXS9hHwer22bVs4fHzA2rm5tL3h4wMuvbS/Zw76/OGtM82NYiuoXsFVW/jBODz1n5PjP07cV4Kj2ArnT/RpyXCkQrAyOIGCq4acYm7JZ059EKd7C16bzneNk5XLblt9pC750XGSWAdx+v9vxPN/qs6NYiuoXsFVW/jBOHPq41cR8TzMKdisbdsiz7XB4UiFYGV8AjVXLTh8esmHxx/H6d7i12btBOKVH/jLP2/JPjtJGOMkYYyThDFOEsY4SRjjJGGMk4QxThLGOEkY4yRhjJOEMU4SZnvIl8akAqF/rV3e6WJ8wKWbeIwPcGl7xfu2XkG+CdOzg8raWeWdPVJ51dhs7NzG1XafnageF0gRtjnJdD8ZZBrL+0O0GntYOd7Z5tefk6p1fxXRpDdIk2k8yhX3vHucpAvZjRPS46JnB5W1s8o7e6TyqrHZ2LkdVhu9iujQiyOpOcnEJwacxvL+EK3GDmoie553z/rpAq1XmtzwmkzjUS635z47SRjjJGGMk4QxThLGOEkY4yRhjJOEMU4SxjhJGOMkYYyThDFOEsbWKxLG1iu7xV1a0vDxAZdeWsoXNMCvBlX2zbiNiWW2vWSVxeNn/P7s1KrZRXHfjPFYtv1LXtmJZba9ZPHiwR1+94xf4nTFZhcFkrbF3c5Wv8O+2ZMwfJzAZhfFfTPuYWKZbS9ZZXHkjF9eRTRsdlHZN2MwKqn9S9KD9US1tpcsUhzZ4bcGfn+zd+PbdkTStrjb2Yp32GcnCWOcJIxxkjDGScIYJwljnCSMcZIwxknCGCcJY5wkjHGSMMZJwth6RcL8A5OILmfCsf6AAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=282x63 at 0x120AC2C88>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_filters(model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model[0].weight.data.fill_(0)\n",
    "#model[4].weight.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAABkCAIAAAA+Dt3DAAAD1klEQVR4nO3d0W7bOBAF0HrR//9l7UOx3rRonCtyKI6Vc54C1DMiKeaiUhDmcRzHjws9Ho/h2uM49pa//oCpfdbc1BaVD9eO+Xnx9b70XIJT6zhWVduB611w1zZujG578p/dA/jNx7DMg3OsqrZDfqFftpSXdJjsXDiAC+5aySXGpnzZnsz1Cot7m7z9nTMx7NzwG2C1O01ZWACRXmHx8dksf04bq6rtwPUuuGsbN0bDPdnuBef8d/uV1z17iZlXVpPlJR0mO5cP4Jq7Nlk+POUmGfHULizubX7n7R3AfOdu3wAXuM2Uez2GAG0JCyAiLICIsAAiwgKICAsgIiyAiLAAIsICiAgLICIsgIiwACKPdz+QA7jG1b91euPzUU3ts+amtqh8uHZMo19RLznpoNsZp7/sHdW6q8903lW7Wu3YWs20yzuLqpNRS5rUHmk7fApxyTC2n7vZqvbLzvPnIf/16w7d5nUJiyaa3J4mw/hWrPmXhAUQ6RIWJceTNjzj9MfuUa27+kznXbWr1Y6t20wbveDscILroiNtB74fCoex/dzNVrUvepas+bpE3q5RWDTR5PY0Gca3Ys1f6/IYAjQnLICIsAAiwgKICAsgIiyAiLAAIsICiAgLICIsgIiwACLCAog4sBeIOLD3RPnrD5jaZ81NbVH5cO2YO/yKeuHRDzc+bXWdgWm2vWVXNm9yxdzmdxatjkjtc9pq+aHB69oOTLPtLZtvPrnCzc8B3RkWzZdml0XLYrVXu/0K+2kIEHn7sCg81PTep60uMjDNtrfsyuZNrnjKzhecDY9I7XDa6rpDgxe9PBvo1vaWzTQvWeGGGfG0+achnZdmo0XLYrVXu/cKv/1jCHANYQFEhAUQERZARFgAEWEBRIQFEBEWQERYABFhAUSEBRARFkDEgb1AxP8sgIiwACLCAogICyAiLICIsAAiwgKICAsgIiyAiLAAIsICiAgLICIsgIiwACLCAogICyAiLIDIz9f/PPMn5I/jUK5c+RuVv/7AF2GxznNkp6Y3VlVVXthkrM8NLj1vy0g2rnzVGOancO4x5PjP2MU+9vnr1yuqqsoLm4z1ucGl/+g5sJfGBj+5aTeufNUYSqZwIixW7Bi+p8v2kk1byAtOILInLD4+NeVPUGNVVeWFTcb63ODS87aMZOPKV42hZAonXnA+Hv//kZH5+zTWYfK6Jdurao9O3vI3vfSz2/BeOvX5qk27ceWrxjA/hXM/Ddn+Jpzb2PL/AmZ4ZwFEhAUQERZARFgAEWEBRIQFEBEWQERYABFhAUSEBRARFkBEWACRfwH0aAzg8redOAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=356x100 at 0x1214CAEB8>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw all the weights in the net\n",
    "def draw_net():\n",
    "    im = Image.new('RGB', (356, 100), (255, 255, 255))\n",
    "    im.paste(draw_filters(model[0]), (37,0))\n",
    "    im.paste(draw_weights(model[4]), (10,80))\n",
    "\n",
    "    return im\n",
    "\n",
    "draw_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABrCAYAAABXGGiIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAs5JREFUeJzt2zFKa2EUhdHjI43RFE7ATmwEC8ksMgX7TMCp2OoE0gmKk7AXbMQmYqGp0kjsBLt4eQfZsFZ/93/5CR+3yc5msykAcvz76xcA4HeEGyCMcAOEEW6AMMINEEa4AcIIN0AY4QYII9wAYUYdo9fX161/x3x7e+ucr6qq/f391v35fL4z5Lm7u7vWux2NWn4SP6zX69b92Ww26G5vb29b7/bq6qpzvqqqptNp6/7FxcWgu62qurm5ab3fz8/PzvmqqlqtVq375+fnW92vL26AMMINEEa4AcIIN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyDMqGP0/f29Y/bbcrls3a+qOjs7az9jiMVi0br/8fHRul9Vtbe317o/m80GPXd/f/+f3+Snw8PD1v2qqufn5/Yzhrq8vGzdn0wmrftVVaenp+1nbMMXN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEEa4AcKMOkYfHx87Zr+tVqvW/aqq3d3d9jOGeH19bd0fj8et+1VVx8fH7WcMcXBw0Lr/9PTUul9VdXR01H7GUCcnJ637Ly8vrftVVQ8PD+1nbMMXN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEGZns9n89TsA8Au+uAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEEa4AcIIN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDBf7OJLImoM7c8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize weights\n",
    "def visualize_filters(layer):\n",
    "    filters = layer.weight.data.clone()\n",
    "    # visualize\n",
    "    for i in range(0, len(filters)):\n",
    "        data = filters[i].view(3, 3)\n",
    "        subplot(1, 4, i+1)\n",
    "        imshow(data, cmap='gray', vmin=-1, vmax=1)\n",
    "        axis('off');\n",
    "        \n",
    "visualize_filters(model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up network training\n",
    "nb_epochs = 10_000\n",
    "optimiser = optim.SGD(params=model.parameters(), lr=1e-4)\n",
    "#loss = nn.BCEWithLogitsLoss()\n",
    "loss = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH]: 6000, [LOSS]: 0.446537, [ACCURACY]: 1.000\n",
      "tensor([[[[ 0.2568,  0.1104,  0.1673],\n",
      "          [ 0.1286, -0.1042,  0.5102],\n",
      "          [-0.1522, -0.2983,  0.5759]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4487,  0.4797,  0.4105],\n",
      "          [-0.2344, -0.3460, -0.2620],\n",
      "          [-0.3920, -0.3163,  0.0459]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4300, -0.3331,  0.0822],\n",
      "          [-0.1247, -0.1019, -0.1554],\n",
      "          [ 0.0019, -0.2639,  0.0248]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4221,  0.3933,  0.2805],\n",
      "          [-0.4267, -0.3325,  0.0364],\n",
      "          [-0.0886, -0.3105, -0.3442]]]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-197-6fc6b576bfea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Training steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# feed-forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# not sure if I'm doing this right ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(nb_epochs):\n",
    "    # Training steps\n",
    "    X, Y = generate_data()\n",
    "    logits = model(X.unsqueeze(0))  # feed-forward\n",
    "    \n",
    "    # not sure if I'm doing this right ...\n",
    "    logits = logits.squeeze(-2)\n",
    "    Y = Y.unsqueeze(0)\n",
    "\n",
    "    J = loss(logits, Y)  # computes the loss\n",
    "    model.zero_grad()  # cleans up previous gradients\n",
    "    J.backward()\n",
    "    optimiser.step()\n",
    "    \n",
    "    # Accuracy computation and display\n",
    "    score, predicted = torch.max(logits, 0)\n",
    "    acc = (Y == (logits > 0)).sum().float() / len(Y)\n",
    "\n",
    "    if(epoch % 100 == 0):\n",
    "        display.clear_output(wait=True)\n",
    "        print(\"[EPOCH]: %i, [LOSS]: %.6f, [ACCURACY]: %.3f\" % (epoch, J.item(), acc))\n",
    "        \n",
    "        print(model[0].weight.data)\n",
    "        \n",
    "        figure(figsize=(10, 20))\n",
    "        #visualize_filters(model[0])\n",
    "        im = draw_net()\n",
    "        imshow(numpy.asarray(im), aspect='equal', interpolation='nearest')\n",
    "        \n",
    "        # im.save('%s.png' % epoch)\n",
    "        \n",
    "        #draw_filters(model[0]).save('%i.png' % epoch)\n",
    "        axis('off');\n",
    "        pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAx9JREFUeJzt3bENAjAMAMEYsf/KYQIqFCKeuwEsNy+XnrXWXkDS4/YCwDkChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziEPU8M3XufGPt3Zub2Cvw4FxzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAoewI7/Jvsn/LnjPBYcwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAh73l7gU3vv2yscMzO3V+DHueAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIm7VW9/cP/DkXHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgEPYC6nEJ/hpjB4oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inference: C vs. D detector\n",
    "with torch.no_grad():\n",
    "    print('C' if model(generate_data(visualise=True)[0].unsqueeze_(0)) > 0 else 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x11d4ab9b0>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# register hook to get activation after conv layer out\n",
    "\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "model[0].register_forward_hook(get_activation('act'))\n",
    "model[1].register_forward_hook(get_activation('relu'))\n",
    "model[2].register_forward_hook(get_activation('pool'))\n",
    "model[3].register_forward_hook(get_activation('flatten'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n",
      "tensor([[[[ 2.4630e-01,  2.4630e-01,  2.4630e-01,  2.4630e-01,  2.4630e-01,\n",
      "            2.4630e-01],\n",
      "          [ 2.4630e-01,  2.4630e-01,  2.4630e-01,  2.4630e-01,  2.4630e-01,\n",
      "            2.4630e-01],\n",
      "          [ 2.4630e-01,  2.4630e-01,  8.2236e-01,  5.2409e-01, -2.0414e-01,\n",
      "            9.4129e-02],\n",
      "          [ 2.4630e-01,  2.4630e-01,  1.3327e+00,  3.5409e-01,  6.9464e-01,\n",
      "            7.6730e-02],\n",
      "          [ 2.4630e-01,  2.4630e-01,  1.5001e+00,  1.2165e-01,  1.6766e+00,\n",
      "            1.0067e-01],\n",
      "          [ 2.4630e-01,  2.4630e-01,  1.5001e+00,  5.3033e-01,  8.5915e-01,\n",
      "            1.0036e-01]],\n",
      "\n",
      "         [[ 2.4893e-01,  2.4893e-01,  2.4893e-01,  2.4893e-01,  2.4893e-01,\n",
      "            2.4893e-01],\n",
      "          [ 2.4893e-01,  2.4893e-01,  2.4893e-01,  2.4893e-01,  2.4893e-01,\n",
      "            2.4893e-01],\n",
      "          [ 2.4893e-01,  2.4893e-01,  2.9484e-01, -2.1504e-02, -4.5946e-01,\n",
      "           -1.4312e-01],\n",
      "          [ 2.4893e-01,  2.4893e-01,  3.2814e-02, -6.7547e-01, -6.7775e-01,\n",
      "           -3.0191e-01],\n",
      "          [ 2.4893e-01,  2.4893e-01,  4.4329e-01,  4.7669e-01,  3.3462e-01,\n",
      "            3.5241e-02],\n",
      "          [ 2.4893e-01,  2.4893e-01,  4.4329e-01,  1.1213e-01, -9.6823e-02,\n",
      "           -9.4869e-03]],\n",
      "\n",
      "         [[-2.4686e-02, -2.4686e-02, -2.4686e-02, -2.4686e-02, -2.4686e-02,\n",
      "           -2.4686e-02],\n",
      "          [-2.4686e-02, -2.4686e-02, -2.4686e-02, -2.4686e-02, -2.4686e-02,\n",
      "           -2.4686e-02],\n",
      "          [-2.4686e-02, -2.4686e-02,  1.0942e-04, -2.6376e-01, -2.8670e-01,\n",
      "           -2.2832e-02],\n",
      "          [-2.4686e-02, -2.4686e-02, -1.5531e-01, -5.4588e-01, -2.2463e-01,\n",
      "           -4.1324e-01],\n",
      "          [-2.4686e-02, -2.4686e-02, -7.3125e-02, -6.4136e-01, -1.8123e-01,\n",
      "            3.9537e-02],\n",
      "          [-2.4686e-02, -2.4686e-02, -7.3125e-02, -6.9875e-01, -5.4631e-02,\n",
      "           -4.5782e-01]],\n",
      "\n",
      "         [[ 2.4214e-02,  2.4214e-02,  2.4214e-02,  2.4214e-02,  2.4214e-02,\n",
      "            2.4214e-02],\n",
      "          [ 2.4214e-02,  2.4214e-02,  2.4214e-02,  2.4214e-02,  2.4214e-02,\n",
      "            2.4214e-02],\n",
      "          [ 2.4214e-02,  2.4214e-02, -3.2002e-01, -6.3048e-01, -3.7490e-01,\n",
      "           -6.4443e-02],\n",
      "          [ 2.4214e-02,  2.4214e-02, -2.8358e-01, -5.8233e-01, -1.1679e+00,\n",
      "           -7.1300e-01],\n",
      "          [ 2.4214e-02,  2.4214e-02, -3.0973e-03,  5.4979e-02,  1.6336e-02,\n",
      "           -1.9669e-01],\n",
      "          [ 2.4214e-02,  2.4214e-02, -3.0973e-03, -5.6974e-01, -6.2665e-02,\n",
      "           -3.7013e-03]]]])\n",
      "tensor([[ 0.2463,  0.2463,  0.2463,  0.2463,  0.2463,  0.2463],\n",
      "        [ 0.2463,  0.2463,  0.2463,  0.2463,  0.2463,  0.2463],\n",
      "        [ 0.2463,  0.2463,  0.8224,  0.5241, -0.2041,  0.0941],\n",
      "        [ 0.2463,  0.2463,  1.3327,  0.3541,  0.6946,  0.0767],\n",
      "        [ 0.2463,  0.2463,  1.5001,  0.1216,  1.6766,  0.1007],\n",
      "        [ 0.2463,  0.2463,  1.5001,  0.5303,  0.8592,  0.1004]])\n",
      "tensor([[ 0.2489,  0.2489,  0.2489,  0.2489,  0.2489,  0.2489],\n",
      "        [ 0.2489,  0.2489,  0.2489,  0.2489,  0.2489,  0.2489],\n",
      "        [ 0.2489,  0.2489,  0.2948, -0.0215, -0.4595, -0.1431],\n",
      "        [ 0.2489,  0.2489,  0.0328, -0.6755, -0.6777, -0.3019],\n",
      "        [ 0.2489,  0.2489,  0.4433,  0.4767,  0.3346,  0.0352],\n",
      "        [ 0.2489,  0.2489,  0.4433,  0.1121, -0.0968, -0.0095]])\n",
      "tensor([[-2.4686e-02, -2.4686e-02, -2.4686e-02, -2.4686e-02, -2.4686e-02,\n",
      "         -2.4686e-02],\n",
      "        [-2.4686e-02, -2.4686e-02, -2.4686e-02, -2.4686e-02, -2.4686e-02,\n",
      "         -2.4686e-02],\n",
      "        [-2.4686e-02, -2.4686e-02,  1.0942e-04, -2.6376e-01, -2.8670e-01,\n",
      "         -2.2832e-02],\n",
      "        [-2.4686e-02, -2.4686e-02, -1.5531e-01, -5.4588e-01, -2.2463e-01,\n",
      "         -4.1324e-01],\n",
      "        [-2.4686e-02, -2.4686e-02, -7.3125e-02, -6.4136e-01, -1.8123e-01,\n",
      "          3.9537e-02],\n",
      "        [-2.4686e-02, -2.4686e-02, -7.3125e-02, -6.9875e-01, -5.4631e-02,\n",
      "         -4.5782e-01]])\n",
      "tensor([[ 0.0242,  0.0242,  0.0242,  0.0242,  0.0242,  0.0242],\n",
      "        [ 0.0242,  0.0242,  0.0242,  0.0242,  0.0242,  0.0242],\n",
      "        [ 0.0242,  0.0242, -0.3200, -0.6305, -0.3749, -0.0644],\n",
      "        [ 0.0242,  0.0242, -0.2836, -0.5823, -1.1679, -0.7130],\n",
      "        [ 0.0242,  0.0242, -0.0031,  0.0550,  0.0163, -0.1967],\n",
      "        [ 0.0242,  0.0242, -0.0031, -0.5697, -0.0627, -0.0037]])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABrCAYAAABXGGiIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAA0RJREFUeJzt3LEupGEUx+GxhoJKIhIlkSBR0qjUCoUrmHvQCRWFyxCtZtyBQqGSSBSIKIQOhVIis+WWM2eSYf72eerz7fnyWb+8jXek0+k0AMjx56dfAIAa4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QJjmIP7R4+Njf47ZRavVGunnOd+2u36/7f7+vm/bxcHBQV/fttFoNA4PD33fLvb29nr6vk7cAGGEGyCMcAOEEW6AMMINEEa4AcIIN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAmOZPv0A/Njc3S/P39/flHScnJ6X5xcXF8o5hND4+Xpq/vb0t77i8vCzNLy0tleZbrVZp/rs0m7Vft8fHx/KOr6+v0vz8/Hx5x7C6ubkpzffzf3dubq40P6guOHEDhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINECbyrpKZmZnS/MXFRXnHzs5Oaf7s7Ky8YxhV78c4PT0d0Jv8Mz09PfAd3+H19bU0//DwUN6xvLxcmr+6uirvGFbVu2DGxsbKO9rtdml+YWGhNH90dNTTnBM3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyBM5CVTVU9PT+Vntre3S/Ojo6PlHcNobW2tNL++vl7e8fb2Vpq/u7sr7xhGExMTpfmPj4/yjurFSf38/IZV9UKnlZWV8o6tra3S/PPzc3lHL5y4AcIIN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBgjzX9xVsrq6Wn7m/f19AG/y+1xfX5efeXl5Kc1PTk6Wd/wGn5+f5WempqZK8+fn56X53d3d0vwwa7fb5Wc2NjZK87Ozs+UdvXDiBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyDMSKfT+el3AKDAiRsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEEa4AcIIN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBgjzF2g5a1SLnLjNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inference: C vs. D detector\n",
    "with torch.no_grad():\n",
    "    print('C' if model(generate_data(visualise=False)[0].unsqueeze_(0)) > 0 else 'D')\n",
    "    print(activation['act'])\n",
    "    \n",
    "    # visualize activations after convolution\n",
    "    for i, act in enumerate(activation['act'][0]):\n",
    "        print(act)\n",
    "        data = act.view(6,6)\n",
    "        subplot(1, 4, i+1)\n",
    "        imshow(data, cmap='gray', vmin=-1, vmax=1)\n",
    "        axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# A printout of sample data, activations, outputs to troubleshoot Teensy implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 1., 1., 1., 0., 0., 0.],\n",
      "          [0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 1., 1., 1., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.]]]])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAx5JREFUeJzt3dEJQyEQRUE3pP+WTRNJxPNmKrgIh/101lp7AUmv0wOA3xE4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5h79MDbrL3Pj0hYWZOT3gMFxzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5h139d9M/vhHy5w21ccAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYbPW2qdH3GJvT/UNM3N6wmO44BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIT5mwzCXHAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziEfQCI5Q33wkACzQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dat = generate_data(visualise=True, target=\"D\")\n",
    "dat = dat[0].unsqueeze_(0)\n",
    "print(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.2569,  0.1105,  0.1674],\n",
      "          [ 0.1287, -0.1043,  0.5103],\n",
      "          [-0.1522, -0.2983,  0.5761]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4487,  0.4797,  0.4105],\n",
      "          [-0.2345, -0.3460, -0.2620],\n",
      "          [-0.3920, -0.3163,  0.0459]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4300, -0.3331,  0.0822],\n",
      "          [-0.1247, -0.1019, -0.1554],\n",
      "          [ 0.0019, -0.2639,  0.0248]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4221,  0.3933,  0.2805],\n",
      "          [-0.4268, -0.3325,  0.0364],\n",
      "          [-0.0887, -0.3105, -0.3442]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2463,  0.2489, -0.0247,  0.0242], requires_grad=True)\n",
      "Linear(in_features=16, out_features=1, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.5481, -0.3763, -0.2324, -0.3884,  0.1324,  0.7295,  0.0358,  0.1847,\n",
      "         -0.1555,  0.3133,  0.0970, -0.3748,  0.1187,  0.6135,  0.2777,  0.2629]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1862], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n",
      "tensor([[ 0.4583,  0.5002,  0.7811,  0.2707,  0.3750,  0.2463],\n",
      "        [ 0.0112,  0.5007,  0.7811,  0.6137,  0.5032,  0.2463],\n",
      "        [-0.0457,  0.4797,  0.2463,  0.2463,  0.2463,  0.2463],\n",
      "        [-0.0457,  0.4797,  0.2463,  0.2463,  0.2463,  0.2463],\n",
      "        [ 0.8286,  0.9097,  0.3719, -0.2041,  0.0941,  0.2463],\n",
      "        [ 0.8671,  0.9093,  0.7811,  0.2707,  0.3750,  0.2463]])\n",
      "tensor([[-0.3294, -0.7512, -0.5936, -0.3316,  0.0144,  0.2489],\n",
      "        [-0.0030,  0.5125,  1.5878,  1.1773,  0.6976,  0.2489],\n",
      "        [ 0.0662,  0.0711,  0.2489,  0.2489,  0.2489,  0.2489],\n",
      "        [ 0.0662,  0.0711,  0.2489,  0.2489,  0.2489,  0.2489],\n",
      "        [ 0.4285,  0.1927, -0.4136, -0.4595, -0.1431,  0.2489],\n",
      "        [ 0.4666,  0.0896, -0.5936, -0.3316,  0.0144,  0.2489]])\n",
      "tensor([[-0.4440, -0.2802, -0.4067, -0.2513, -0.1494, -0.0247],\n",
      "        [-0.3083, -0.3984,  0.1544,  0.0722,  0.4053, -0.0247],\n",
      "        [-0.7235,  0.2825, -0.0247, -0.0247, -0.0247, -0.0247],\n",
      "        [-0.7235,  0.2825, -0.0247, -0.0247, -0.0247, -0.0247],\n",
      "        [-0.4349,  0.0415, -0.2619, -0.2867, -0.0228, -0.0247],\n",
      "        [-0.5132,  0.1480, -0.4067, -0.2513, -0.1494, -0.0247]])\n",
      "tensor([[-0.2498, -0.3605, -0.6986, -0.7351, -0.4025,  0.0242],\n",
      "        [-0.3383,  0.1825,  1.1200,  0.8395,  0.4463,  0.0242],\n",
      "        [-0.2255, -0.0691,  0.0242,  0.0242,  0.0242,  0.0242],\n",
      "        [-0.2255, -0.0691,  0.0242,  0.0242,  0.0242,  0.0242],\n",
      "        [-0.2593, -0.6352, -0.7191, -0.3749, -0.0644,  0.0242],\n",
      "        [ 0.4539,  0.1502, -0.6986, -0.7351, -0.4025,  0.0242]])\n",
      "\n",
      "\n",
      "relu:\n",
      "tensor([[[[0.4583, 0.5002, 0.7811, 0.2707, 0.3750, 0.2463],\n",
      "          [0.0112, 0.5007, 0.7811, 0.6137, 0.5032, 0.2463],\n",
      "          [0.0000, 0.4797, 0.2463, 0.2463, 0.2463, 0.2463],\n",
      "          [0.0000, 0.4797, 0.2463, 0.2463, 0.2463, 0.2463],\n",
      "          [0.8286, 0.9097, 0.3719, 0.0000, 0.0941, 0.2463],\n",
      "          [0.8671, 0.9093, 0.7811, 0.2707, 0.3750, 0.2463]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0144, 0.2489],\n",
      "          [0.0000, 0.5125, 1.5878, 1.1773, 0.6976, 0.2489],\n",
      "          [0.0662, 0.0711, 0.2489, 0.2489, 0.2489, 0.2489],\n",
      "          [0.0662, 0.0711, 0.2489, 0.2489, 0.2489, 0.2489],\n",
      "          [0.4285, 0.1927, 0.0000, 0.0000, 0.0000, 0.2489],\n",
      "          [0.4666, 0.0896, 0.0000, 0.0000, 0.0144, 0.2489]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.1544, 0.0722, 0.4053, 0.0000],\n",
      "          [0.0000, 0.2825, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.2825, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0415, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1480, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0242],\n",
      "          [0.0000, 0.1825, 1.1200, 0.8395, 0.4463, 0.0242],\n",
      "          [0.0000, 0.0000, 0.0242, 0.0242, 0.0242, 0.0242],\n",
      "          [0.0000, 0.0000, 0.0242, 0.0242, 0.0242, 0.0242],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0242],\n",
      "          [0.4539, 0.1502, 0.0000, 0.0000, 0.0000, 0.0242]]]])\n",
      "\n",
      "\n",
      "pool:\n",
      "tensor([[[[0.7811, 0.6137],\n",
      "          [0.9097, 0.3750]],\n",
      "\n",
      "         [[1.5878, 1.1773],\n",
      "          [0.4666, 0.2489]],\n",
      "\n",
      "         [[0.2825, 0.4053],\n",
      "          [0.2825, 0.0000]],\n",
      "\n",
      "         [[1.1200, 0.8395],\n",
      "          [0.4539, 0.0242]]]])\n",
      "\n",
      "\n",
      "flatten:\n",
      "tensor([[0.7811, 0.6137, 0.9097, 0.3750, 1.5878, 1.1773, 0.4666, 0.2489, 0.2825,\n",
      "         0.4053, 0.2825, 0.0000, 1.1200, 0.8395, 0.4539, 0.0242]])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABrCAYAAABXGGiIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAABCpJREFUeJzt3D9LlX0cx/GvNxYIaka6BhZSRDVE4Vab+AicGmx3cW8Q6hn0NKKxhoK2/kK0NOQQ0SYYopWEJedeboJ783PgFN94vebPua7jj8Oba/EaGwwGBUAf//zpLwBARrgBmhFugGaEG6AZ4QZoRrgBmhFugGaEG6AZ4QZoZnwUF338+HH075jHjx+Prn/27Nlo//Tp02hfVTU9PR3td3Z2ov3q6upY9IH/rKysRGf76tWr6Ppzc3PRfn5+PtpXVV28eDHanz59OtoPe7bLy8vR2aZnlf5GZmdno31V1dTUVLSfmZmJ9nfu3BnqbKuqbt26FZ3v7u5udP13795F+4ODg2hflf92FxcXo/3t27ePdL6euAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboJmRvKvk+fPn0f7GjRuj+Bq/pO8XqKra29uL9ul7KIZ14cKFaL+2thbtr1+/Hu2Hsbm5Ge2fPXs2om/yfydPnoz26bs0lpeXo/3+/n60r8p/Hy9fvozvMayvX79G+6WlpWj/4MGDaL+9vR3tq6revHkT7dN3BR2VJ26AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhmJO8q+f79e7Q/PDyM9k+ePIn2f5OJiYlo/+LFi2j/4cOHaP83ef36dbTf2NiI9u/fv4/2w/id7x5JnThxItp//Pgx2t+9ezfad+aJG6AZ4QZoRrgBmhFugGaEG6AZ4QZoRrgBmhFugGaEG6AZ4QZoRrgBmhFugGaEG6AZ4QZoRrgBmhFugGaEG6AZ4QZoRrgBmhFugGaEG6AZ4QZoRrgBmhFugGbGR3HR9fX1aD8xMRHt9/b2ov3Dhw+jfVXVuXPnov2pU6fiewzj8uXL0f7Tp0/R/v79+9H+4OAg2ldVnT9/PtpfuXIlvscwFhYWon16tun+8PAw2ldVnTlzJtoPBoP4HsP68eNHtH/06FG0//btW7S/dOlStK/KuzA5ORnf4yg8cQM0I9wAzQg3QDPCDdCMcAM0I9wAzQg3QDPCDdCMcAM0I9wAzQg3QDMjeVfJ+PhILvvL1atXo/2XL1/ie0xPT0f7nZ2d+B7DOHbsWLRP//atra1oPz8/H+2rqmZnZ+PP/A77+/vRfmpqKtp//vw52g9zTunvcGZmJr7HsG7evBntr127Fu3v3bsX7d++fRvtq6p+/vwZ7RcXF+N7HIUnboBmhBugGeEGaEa4AZoRboBmhBugGeEGaEa4AZoRboBmhBugGeEGaGZsMBj86e8AQMATN0Azwg3QjHADNCPcAM0IN0Azwg3QjHADNCPcAM0IN0Azwg3QjHADNCPcAM0IN0Azwg3QjHADNCPcAM0IN0Azwg3QjHADNCPcAM0IN0Azwg3QjHADNPMvFuKyMdCvq34AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    #dat = generate_data(visualise=False)\n",
    "    print('C' if model(dat) > 0 else 'D')\n",
    "    \n",
    "    # visualize activations after convolution\n",
    "    for i, act in enumerate(activation['act'][0]):\n",
    "        print(act)\n",
    "        data = act.view(6,6)\n",
    "        subplot(1, 4, i+1)\n",
    "        imshow(data, cmap='gray', vmin=-1, vmax=1)\n",
    "        axis('off');\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"relu:\")\n",
    "    print(activation[\"relu\"])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"pool:\")\n",
    "    print(activation[\"pool\"])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"flatten:\")\n",
    "    print(activation[\"flatten\"])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
