{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini neural net training\n",
    "Authors: Alfredo Canziani, Philipp Schmitt  \n",
    "Date: 15 Apr, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from IPython import display\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from matplotlib.pyplot import imshow, axis, figure, subplot, pause\n",
    "import numpy\n",
    "import random\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10de78110>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# static random seed\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input definition\n",
    "class input_settings:\n",
    "    batch_size = 1\n",
    "    channels = 1\n",
    "    height = 8\n",
    "    width = 8\n",
    "\n",
    "dummy_X = torch.randn(  # batch of inputs x\n",
    "    input_settings.batch_size,\n",
    "    input_settings.channels,\n",
    "    input_settings.height,\n",
    "    input_settings.width,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network architecture\n",
    "class model_settings:\n",
    "    conv_channels = 4\n",
    "    kernel = 3\n",
    "    pooling_kernel = 3\n",
    "    flattened = 16\n",
    "    output_size = 1\n",
    "    \n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(\n",
    "        in_channels=input_settings.channels,\n",
    "        out_channels=model_settings.conv_channels,\n",
    "        kernel_size=model_settings.kernel,\n",
    "        bias=True,\n",
    "    ),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(\n",
    "        kernel_size=model_settings.pooling_kernel,\n",
    "        stride=model_settings.pooling_kernel,\n",
    "    ),  # we have 4 x 2x2\n",
    "    nn.Flatten(),  # gives 16\n",
    "    nn.Linear(\n",
    "        in_features=model_settings.flattened,\n",
    "        out_features=model_settings.output_size,\n",
    "        bias=True,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "with torch.no_grad():\n",
    "    print(model(dummy_X).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Flatten()\n",
      "  (4): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weights and biases\n",
    "def get_weights():\n",
    "    print(\n",
    "        model[0],\n",
    "        model[0].weight,\n",
    "        model[0].bias,\n",
    "        sep='\\n',\n",
    "    )\n",
    "    print(\n",
    "        model[4],\n",
    "        model[4].weight,\n",
    "        model[4].bias,\n",
    "        sep='\\n',\n",
    "    )\n",
    "    # Maybe add some saving routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letter samples\n",
    "samples = [\n",
    "    [\n",
    "        [0,1,1,1],\n",
    "        [1,0,0,0],\n",
    "        [1,0,0,0],\n",
    "        [1,0,0,0],\n",
    "        [1,0,0,0],\n",
    "        [0,1,1,1]\n",
    "    ],\n",
    "    [\n",
    "        [1,1,1],\n",
    "        [1,0,0],\n",
    "        [1,0,0],\n",
    "        [1,1,1]\n",
    "    ],\n",
    "    [\n",
    "        [1,1,1,0],\n",
    "        [1,0,0,1],\n",
    "        [1,0,0,1],\n",
    "        [1,0,0,1],\n",
    "        [1,0,0,1],\n",
    "        [1,1,1,0]\n",
    "    ],\n",
    "    [\n",
    "        [1,1,0],\n",
    "        [1,0,1],\n",
    "        [1,0,1],\n",
    "        [1,1,0]\n",
    "    ]\n",
    "]\n",
    "\n",
    "sample_meta = [\n",
    "    [6,4,'C'],\n",
    "\t[4,3,'C'],\n",
    "\t[6,4,'D'],\n",
    "\t[4,3,'D']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 1., 1., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 1., 1., 0., 0.]]]), tensor(1.))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAyFJREFUeJzt3UEKQjEQBcGMeP8rxwvoQj4abKtO8CA0s8ystfYCkm6nBwCfI3AIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ9j99ABe23ufnvDzZub0hKNccAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHML8TfaGb/8V9u//anGdCw5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIWzWWvv0CJ7b29NcNTOnJxzlgkOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCHM10UQ5oJDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQ8voA33RCWB4gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# updated gen. function to match teensy implementation\n",
    "def generate_data(visualise=False, target=None):\n",
    "    data = numpy.zeros(shape=(8,8), dtype=numpy.float32)\n",
    "    \n",
    "    sample = random.randint(0,len(samples)-1)\n",
    "    character = sample_meta[sample][2];\n",
    "    \n",
    "    x = random.randint(\n",
    "        0,\n",
    "        input_settings.width-sample_meta[sample][1]\n",
    "    )\n",
    "    y = random.randint(\n",
    "        0,\n",
    "        input_settings.height-sample_meta[sample][0]\n",
    "    )\n",
    "    \n",
    "    data[y:y+sample_meta[sample][0],x:x+sample_meta[sample][1]] = samples[sample]\n",
    "    \n",
    "    if visualise:\n",
    "        figure(facecolor='k')\n",
    "        imshow(data, cmap='gray')\n",
    "        axis('off');\n",
    "        \n",
    "    return torch.tensor(data).unsqueeze_(0), torch.tensor(character=='C', dtype=torch.float)\n",
    "        \n",
    "generate_data(visualise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEYAAABGCAIAAAD+THXTAAAATUlEQVR4nO3TMQoAIQwEQL3//zk2coiWUU6OmSpNFrbYUgAA+Juaj4iInlU3pOU9yf+3z3R/KFvpQiotxv1csiUAAAAAAAAAAAAA4JgGt1sJCjqkBk8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=70x70 at 0x1036ED128>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from numpy import interp\n",
    "from math import cos, sin, radians, pi\n",
    "\n",
    "\n",
    "def draw_weight(value, size=20):\n",
    "    rad = interp(value,[-.75,.75],[pi,0])\n",
    "    im = Image.new('RGB', (size, size), (0, 0, 0))\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    x, y, r = (\n",
    "        size/2 + size/3 * cos(rad), \n",
    "        size/2 - size/3 * sin(rad),\n",
    "        4)\n",
    "    draw.ellipse((x-r/2, y-r/2, x+r/2, y+r/2), fill=(255, 255, 255), outline=None)\n",
    "\n",
    "    return im\n",
    "\n",
    "draw_weight(-.25, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAAeCAIAAABc99v3AAABNElEQVR4nO3aMY7DMAwEQCu4/3/ZVwVwcXYl0tLeTJWKlAVx4Sg5jjLneSquuOKKK95W/FNXHYBOAh0gxM/bCziOy9eQMcbKNXuKt3XZbtvr2jUvu9qUx8k45NUtVhvSpzf082vCuh67/Pl5tZo9xdu6bLftde2al33tVTFfUx4n45BXt1hwSG8D/a1TDv+B+aKCO3SAEO8H+vVuaNY9VEXNnuJtXbbb9rp2zcuuNuVxMg55dYsFh/T2R9ExRtsvRdV7sVfxti7bbXtdu/4cL52vKQUzDnl1i9WG9OlfLgFvK7As88V071+5ADCFQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBC/cK7SKe8H8nUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=496x30 at 0x11CC43390>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw weights\n",
    "\n",
    "def draw_weights(layer, size=20):\n",
    "    weights = layer.weight.data.clone().numpy()\n",
    "\n",
    "    n_weights = len(weights[0])\n",
    "    im = Image.new('RGB', ((size+1)*n_weights, size), (255, 255, 255))\n",
    "\n",
    "    for i in range(n_weights):\n",
    "        weight = draw_weight(weights[0][i], size=size)\n",
    "        im.paste(weight,((size+1)*i,0))\n",
    "\n",
    "    return im\n",
    "\n",
    "draw_weights(model[4], size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAD8AAAA/CAIAAADYPYeIAAAA9UlEQVR4nO2awQoDIQxEtfT/f9keetkVNJpEx8i844KTh0QxpSkZKKVgl3/Ha+Scp6IVq2YTPoMRaWardKsUCYL94Vxt/+y58Q7WrfJNkIHfOVd3zuHQHgftcdAeB+1x0B5HbPtsfOgFBv5CFqbyPcO1ml7fbxuuR3L+VN8DnNrOFgSw79CzP3+4Fk6tvaRLQuvoy78EnkBrC+7t+/OhPQ7a46A9DtrjoD0OTuW45UteyF6TuJhT931r/lWUTOZJXMx52XsV3kbsO8ff3msSH8l5ndrO/KsubEHMqe+cVX8KWAP7HgftcdAeB+1x0B4H7XHEnsp/C5qQT/FM8BQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=63x63 at 0x11BF38438>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw a filter\n",
    "def draw_filter(filter):\n",
    "    matrix = Image.new('RGB', (63, 63), (255, 255, 255))\n",
    "    data = filter.view(3, 3).numpy()\n",
    "    # go over filter\n",
    "    # rows\n",
    "    for x in range(0, data.shape[0]):\n",
    "        # cols\n",
    "        for y in range(0, data.shape[1]):\n",
    "            vis = draw_weight(data[y,x])\n",
    "            matrix.paste(vis,(x*21,y*21))\n",
    "    return matrix\n",
    "\n",
    "filters = model[0].weight.data\n",
    "draw_filter(filters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARoAAAA/CAIAAACwx5DcAAACiElEQVR4nO3czU7DMBBF4Rrx/q9cFpUQrajjes74JznfikU8jp3eQiIy5RZwv99LKROH1w+Ye24u7d3w+gFbL+275aDHDx/N1DeKraDxBly1iR+Mw6m/GsffGr5XgqPYCu0TPew4HCkOnsOAq4ZM0bfklqkP4nRuwWszdzhSfNjX1jpSl3zpOEmsgzj9/Rux/U/VvlFsBY034KpN/GC0TH38KCKehz4DNquUErmvnTscKY6fw5irFhzeveTD44/jdG7xazNxOFL8gr/885bsvZOEMU4SxjhJGOMkYYyThDFOEsY4SRjjJGGMk4QxThLGOEkY4yRhykVeGpMGCP1r7fROF/UDtm7iUT/Apb0rvnTrlbN2UJl7VnmzByt3D1/zKmeor7R277ROBxW2RUl3PxnkHPJ6FczqXZG6oviej+wts8GjiBXag6xwDldDNS2KF2m3QZykXdTidNYOKnPPKm/2YOXu4Wte5QyHKz14FLFCB5WMFiUdPTfAc8j7zM3qXZGxImTPB/eW2aP1ygrfeSucw9Xs0lzpl/dOEsY4SRjjJGGMk4QxThLGOEkY4yRhjJOEMU4SxjhJGOMkYYyThLH1ioSx9crb4i4taXj9gK2XlvKCBvWGCf6a00U6hHQsE9yZZRvLDJj09d4p3qcCbLeC1EEKsr1fUst2LBPc6tUaywR3+NNJn+Jkg5F/JW2Lu51t/A77ZE/C8HGiGnHgDT0u0iGkY5ngzizbWGbMpE+PIqg+FbMapCQVzOj9kle2rxq7LqpUsDLVvKX94Ncneyf+2o5I2hZ3O9vgHfbeScIYJwljnCSMcZIwxknCGCcJY5wkjHGSMMZJwhgnCWOcJIxxkjC2XpEwP13zN1vs/so5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=282x63 at 0x11CD94518>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw all filters\n",
    "def draw_filters(layer):\n",
    "    matrix = Image.new('RGB', (282, 63), (255, 255, 255))\n",
    "    filters = layer.weight.data.clone()\n",
    "    for i, filter in enumerate(filters):\n",
    "        vis = draw_filter(filter)\n",
    "        matrix.paste(vis, (i*(63+10),0))\n",
    "    return matrix\n",
    "\n",
    "\n",
    "draw_filters(model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAABkCAIAAAA+Dt3DAAAD0UlEQVR4nO3dwW7dOAwF0LxB//+XPYtgMinQpNcSZdHOOasCDWlL9rutHYR5HcfxdqHX6zVcexzH3vLvv8DSvmpuaYvKh2vH/Lr4eH/1sQWn9nGsqrYD17vgqm28Mbrdk//sPoHffA7LPDjHqmo75Ad6d8fykuaF53DBVSs5xNiSL7snc73C4tkmL//e8pLmDT8Aqz1pycICiPQKi8/PZvlz2lhVbQeud8FV23hjNLwn273gnP+0X3ncs4eYeWW1t7ykefk5XHPVJsuHl9wkIz60C4tnm7/zNpaXNO/2AbjAY5bc6zEEaEtYABFhAUSEBRARFkBEWAARYQFEhAUQERZARFgAEWEBRIQFEHndfSAHcI2rf+r0wfNRLe2r5pa2qHy4dkyvH1F/6tzdvWe17uiTnYfLe17lFVqttNE7iz5zd2sH2w5PIS45h3UzIHfNBF26ovk9v9dE4lMahUUTHa5Qh3P4aaoGec83aUtYAJFGYfHUubt7z2rd0Sc7D5f3vMordFtprxecHeburhhsOzCptfAc1t1nu2aCrlhRyZ7fcSJxrldYNNHhCnU4h5/meR/vWo0eQ4DOhAUQERZARFgAEWEBRIQFEBEWQERYABFhAUSEBRARFkBEWAARA3uBiIG9J8q//wJL+6q5pS0qH64d84QfUa+aIFA+xqLVtNV1BpZZuDNtxxHf6KChze8s5qebFg7pLelT0rB2YvDStgPLLNzqbuOIJ3e4+QjPnWHRfGt2WbQtdnu1x++w74YAkduHRdVQ0/LhqN2mrS4ysMzCnWk7jvhGB83tfMFZNd1011jdRQ1XTAxe13asW+26qlpNdq4a+TtWeIHN3w3pvDUbLdoWu73as3f49o8hwDWEBRARFkBEWAARYQFEhAUQERZARFgAEWEBRIQFEBEWQERYABEDe4GI/1kAEWEBRIQFEBEWQERYABFhAUSEBRARFkBEWAARYQFEhAUQERZARFgAEWEBRIQFEBEWQERYAJFf3//1zK+QP45DuXLlNyr//gv+EhaLfJzW2bUNF5aUVzXZtfyZVoWHnrfl5Dde9w7lb2cfQ47/jB3so8kf/7yusKS8qsmu5c+0Kjz05z5j99KWk9943TuUvzsRFivuGH4m99IdecEJRDaExedHplOPT8OFJeVVTXYtf6ZV4aHnbTn5jde9Q/m7Ey84X6//f8lI4c16TWFJeVWTXcufaVWbEZP30paT33jdO5S/nf1uyPZ/VXgM99LteGcBRIQFEBEWQERYABFhAUSEBRARFkBEWAARYQFEhAUQERZARFgAkX8BXj0M4L2XhdsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=356x100 at 0x11CD5A358>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw all the weights in the net\n",
    "def draw_net():\n",
    "    im = Image.new('RGB', (356, 100), (255, 255, 255))\n",
    "    im.paste(draw_filters(model[0]), (37,0))\n",
    "    im.paste(draw_weights(model[4]), (10,80))\n",
    "\n",
    "    return im\n",
    "\n",
    "draw_net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up network training\n",
    "nb_epochs = 20_000\n",
    "lr = 1e-3\n",
    "optimiser = optim.SGD(params=model.parameters(), lr=lr)\n",
    "#loss = nn.BCEWithLogitsLoss()\n",
    "loss = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH]: 19900, [LOSS]: 0.118495, [ACCURACY]: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(nb_epochs):\n",
    "    # Training steps\n",
    "    X, Y = generate_data()\n",
    "    logits = model(X.unsqueeze(0))  # feed-forward\n",
    "    \n",
    "    # not sure if I'm doing this right ...\n",
    "    logits = logits.squeeze(-2)\n",
    "    Y = Y.unsqueeze(0)\n",
    "\n",
    "    J = loss(logits, Y)  # computes the loss\n",
    "    model.zero_grad()  # cleans up previous gradients\n",
    "    J.backward()\n",
    "    optimiser.step()\n",
    "    \n",
    "    # Accuracy computation and display\n",
    "    score, predicted = torch.max(logits, 0)\n",
    "    acc = (Y == (logits > 0)).sum().float() / len(Y)\n",
    "    \n",
    "    if(epoch % 100 == 0):\n",
    "        display.clear_output(wait=True)\n",
    "        print(\"[EPOCH]: %i, [LOSS]: %.6f, [ACCURACY]: %.3f\" % (epoch, J.item(), acc))\n",
    "        \n",
    "        continue\n",
    "        \n",
    "        print(model[0].weight.data)\n",
    "        \n",
    "        figure(figsize=(10, 20))\n",
    "        #visualize_filters(model[0])\n",
    "        im = draw_net()\n",
    "        imshow(numpy.asarray(im), aspect='equal', interpolation='nearest')\n",
    "        \n",
    "        # im.save('%s.png' % epoch)\n",
    "        \n",
    "        #draw_filters(model[0]).save('%i.png' % epoch)\n",
    "        axis('off');\n",
    "        pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAxxJREFUeJzt3bENxDAMADHrkf1X9o+QNIGBC1mrUHNQqVlr7QUk/U4vALxH4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hF2nF+B79t6nV0iYmdsZFxzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hXheR9uS9T5kLDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCLtOLwBv2nufXuE1M3M744JDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhbNZa3d8u8HEuOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hP0BW/8J/oHE3lQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inference: C vs. D detector\n",
    "with torch.no_grad():\n",
    "    print('C' if model(generate_data(visualise=True)[0].unsqueeze_(0)) > 0 else 'D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Visualization & Printing of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x11bb66a20>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# register hook to get activation after conv layer out\n",
    "\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "backward = {}\n",
    "def get_backward(name):\n",
    "    def hook(model, input, output):\n",
    "        backward[name] = {}\n",
    "        backward[name]['input'] = input\n",
    "        backward[name]['output'] = output\n",
    "    return hook\n",
    "\n",
    "model[0].register_forward_hook(get_activation('act'))\n",
    "model[1].register_forward_hook(get_activation('relu'))\n",
    "model[2].register_forward_hook(get_activation('pool'))\n",
    "model[3].register_forward_hook(get_activation('flatten'))\n",
    "\n",
    "model[0].register_backward_hook(get_backward('conv'))\n",
    "model[1].register_backward_hook(get_backward('relu'))\n",
    "model[2].register_backward_hook(get_backward('pool'))\n",
    "model[3].register_backward_hook(get_backward('flatten'))\n",
    "model[4].register_backward_hook(get_backward('lin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABrCAYAAABXGGiIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAs5JREFUeJzt27FJq2EYhuE3B1OIhWDpCnYiukIGyAAu4QwWVk5g7wCSIogDWLhCIEVisFZIkdMJp9Of8yoPXFedPN+fr7j5m4x2u10BkOPPbz8AAN8j3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCLPXMfr4+Nj6d8yf+LfnfD5v3b++vh4N+d7T01Prjz84OOicr6qqt7e31v3JZDLobmezWevd3t3ddc5XVdXZ2Vnr/tXV1aC7rap6eXlpvd+Pj4/O+aqqWi6XrfvT6fRL9+uNGyCMcAOEEW6AMMINEEa4AcIIN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCLPXMbparTpmPz08PLTuV1Xd3Ny0nzHE7e1t6/52u23d/wmTyWTQ9+7v7//zk/zr+Pi4db+qarFYtJ8x1OXlZev+0dFR635V1fn5eev+dDr90ue8cQOEEW6AMMINEEa4AcIIN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyDMXsfoer3umP30+vraul9Vtb+/337GEO/v76374/G4db+q6uLiov2MIQ4PD1v3N5tN635V1cnJSfsZQ52enrbur1ar1v2qqufn5/YzvsIbN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEGa02+1++xkA+AZv3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEEa4AcIIN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QJi/OuxO/VYGeCwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize weights\n",
    "def visualize_filters(layer):\n",
    "    filters = layer.weight.data.clone()\n",
    "    # visualize\n",
    "    for i in range(0, len(filters)):\n",
    "        data = filters[i].view(3, 3)\n",
    "        subplot(1, 4, i+1)\n",
    "        imshow(data, cmap='gray', vmin=-1, vmax=1)\n",
    "        axis('off');\n",
    "        \n",
    "visualize_filters(model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABrCAYAAABXGGiIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAA2lJREFUeJzt3K9KRHkYx2HdWRHsJotgVDCJxT/BZhAs3oFGmSIYvACTBovMHZiMBqthwGLSGxC0iUUHFWbLtmVhXtlZ53t8nvy+/n4chg+neMb7/f4YADn++OkLAFAj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCPPnMP7o8fHxSP075uHhYXnn9PS0NL+/v1+ab7Va46WFv11eXo7Us727uyvvnJ2dleZfXl5K8/1+/1vP9ujoaKSe7evra3nn5uamNN/r9UrzDw8P33q2Y2NjY51OZ6Se7/X1dXmn2+2W5h8fH0vzg/52vXEDhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEGYo3yppguo3OFqt1pBuMtqWl5fLO5ubm0M/owmmpqbKO+/v76X59fX18hlNMT8/X97Z2Ngoze/s7JTPGIQ3boAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHC+FbJvzg4OPjpKzTW7e1taf7k5KQ0f3FxUZpvks/Pz5++QqOdn5+X5tvtdmm+1+sNNOeNGyCMcAOEEW6AMMINEEa4AcIIN0AY4QYII9wAYYQbIIxwA4QRboAwv+JbJU9PT+WdhYWFIdykeb6+voa+0+/3y2c0wcfHR3lnampqqPNNsrq6Wt6ZmZkpzV9dXZXPGIQ3boAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAmF/xkalOp1PeWVlZKc2vra2V5icmJkrzo2ppaam8s7W1VZpvt9vlM5pgenq6vLO4uFian5ubK5/RFJOTk+Wd3d3doc4Pyhs3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGF+xbdKvvNNgtvb26HOHx4eluZHVbfb/ekr/MP29vZPX+E/8fb2Vt6ZnZ0tzT8/P5fPaIr7+/v/Zadib29voDlv3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEGe/3+z99BwAKvHEDhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEEa4AcIIN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABh/gKO2YHZ+031twAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inference: C vs. D \n",
    "# Conv. activations visualized\n",
    "with torch.no_grad():\n",
    "    print('C' if model(generate_data(visualise=False)[0].unsqueeze_(0)) > 0 else 'D')\n",
    "    \n",
    "    # visualize activations after convolution\n",
    "    for i, act in enumerate(activation['act'][0]):\n",
    "        data = act.view(6,6)\n",
    "        subplot(1, 4, i+1)\n",
    "        imshow(data, cmap='gray', vmin=-1, vmax=1)\n",
    "        axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# A printout of sample data, activations, outputs to troubleshoot Teensy implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONV WEIGHTS\n",
      "[[[ 0.47995853  0.4736405  -0.05720931]\n",
      "  [ 0.28918833 -0.28551766  0.7975237 ]\n",
      "  [ 0.11068645 -0.45405796  0.8702007 ]]\n",
      "\n",
      " [[ 0.4995981   0.5783793   0.4361773 ]\n",
      "  [-0.37431613 -0.41237792 -0.41114756]\n",
      "  [-0.44214466 -0.4012386   0.03134381]]\n",
      "\n",
      " [[ 0.43306118 -0.32716554  0.0826793 ]\n",
      "  [-0.2293846  -0.12291433 -0.16213353]\n",
      "  [-0.11998866 -0.28797257  0.04755067]]\n",
      "\n",
      " [[ 0.6230193   0.5619987   0.33916005]\n",
      "  [-0.6327074  -0.48683587 -0.0627197 ]\n",
      "  [-0.2290302  -0.42557225 -0.47256288]]]\n",
      "\n",
      "CONV BIAS\n",
      "[ 0.05880113  0.36538437 -0.03880483  0.19600502]\n",
      "\n",
      "LIN WEIGHTS\n",
      "[[-0.8990004  -0.96621096 -0.2937874  -0.39536935  0.23426056  0.98745817\n",
      "   0.06965923  0.36579895 -0.10837258  0.38087833  0.10395952 -0.42120314\n",
      "   0.29145846  1.0594822   0.37452266  0.46097228]]\n",
      "\n",
      "LIN BIAS\n",
      "[0.28205615]\n"
     ]
    }
   ],
   "source": [
    "print(\"CONV WEIGHTS\")\n",
    "print(model[0].weight.clone().detach().squeeze(1).numpy())\n",
    "print('\\nCONV BIAS')\n",
    "print(model[0].bias.clone().detach().numpy())\n",
    "\n",
    "print('\\nLIN WEIGHTS')\n",
    "print(model[4].weight.clone().detach().numpy())\n",
    "print('\\nLIN BIAS')\n",
    "print(model[4].bias.clone().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0., 0., 0., 0., 1., 1., 1., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 1., 1., 1., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]]]), tensor(0.))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAyhJREFUeJzt3TEKwzAQAEEp+P9fVup0KWzLrGdecAiWawQ3xxhrAEmf3QMA1xE4hAkcwgQOYQKHMIFDmMAhTOAQJnAIO3YPwDOs5UPjGeacu0f4YYNDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhzOkibve08z5nuvME1D/vaINDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAg7dg/A+6y1do9wmTnn7hF+2OAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIm2OM7h0ZeDkbHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgEPYFgVMM/oo/G3QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a sample for all following data dumps\n",
    "dat = generate_data(visualise=True)\n",
    "print(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n",
      "\n",
      "\n",
      "CONV:\n",
      "tensor([[ 5.8801e-02,  5.8801e-02,  1.6693e+00, -2.6434e-01,  1.3551e+00,\n",
      "          2.6801e+00],\n",
      "        [ 5.8801e-02,  5.8801e-02,  1.6693e+00, -2.0713e-01,  9.3863e-01,\n",
      "          1.6693e+00],\n",
      "        [ 5.8801e-02,  5.8801e-02,  1.6693e+00, -2.0713e-01,  9.3863e-01,\n",
      "          1.6693e+00],\n",
      "        [ 5.8801e-02,  5.8801e-02,  1.6693e+00,  6.6307e-01,  1.3548e+00,\n",
      "          4.5574e-01],\n",
      "        [ 5.8801e-02,  5.8801e-02,  7.9912e-01,  1.0444e+00,  1.3400e+00,\n",
      "          5.2625e-03],\n",
      "        [ 5.8801e-02,  5.8801e-02,  1.5918e-03,  4.7523e-01,  9.5519e-01,\n",
      "          1.0124e+00]])\n",
      "tensor([[ 0.3654,  0.3654,  0.4218,  0.5663,  1.0631,  1.0636],\n",
      "        [ 0.3654,  0.3654,  0.4218,  0.1301,  0.0485,  0.4218],\n",
      "        [ 0.3654,  0.3654,  0.4218,  0.1301,  0.0485,  0.4218],\n",
      "        [ 0.3654,  0.3654,  0.4218,  0.1615, -0.3214, -0.4530],\n",
      "        [ 0.3654,  0.3654,  0.3904,  0.1202, -0.3329,  0.0149],\n",
      "        [ 0.3654,  0.3654,  0.8016,  1.3799,  1.8795,  1.4434]])\n",
      "tensor([[-0.0388, -0.0388, -0.0707, -0.6942, -0.1996, -0.0475],\n",
      "        [-0.0388, -0.0388, -0.0707, -0.7769,  0.0449, -0.0707],\n",
      "        [-0.0388, -0.0388, -0.0707, -0.7769,  0.0449, -0.0707],\n",
      "        [-0.0388, -0.0388, -0.0707, -0.7293, -0.1955, -0.5262],\n",
      "        [-0.0388, -0.0388, -0.1183, -0.6510, -0.1202, -0.3084],\n",
      "        [-0.0388, -0.0388,  0.0439, -0.2833,  0.1498,  0.0671]])\n",
      "tensor([[ 1.9601e-01,  1.9601e-01, -1.1751e-04,  1.8476e-01,  8.5845e-01,\n",
      "          8.4574e-01],\n",
      "        [ 1.9601e-01,  1.9601e-01, -1.1751e-04, -1.5440e-01, -4.2713e-02,\n",
      "         -1.1751e-04],\n",
      "        [ 1.9601e-01,  1.9601e-01, -1.1751e-04, -1.5440e-01, -4.2713e-02,\n",
      "         -1.1751e-04],\n",
      "        [ 1.9601e-01,  1.9601e-01, -1.1751e-04, -6.2697e-01, -9.4085e-01,\n",
      "         -1.8216e-01],\n",
      "        [ 1.9601e-01,  1.9601e-01,  4.7245e-01,  2.0845e-01, -3.6324e-01,\n",
      "         -5.8438e-01],\n",
      "        [ 1.9601e-01,  1.9601e-01,  5.3517e-01,  1.0972e+00,  1.7202e+00,\n",
      "          1.3810e+00]])\n",
      "\n",
      "\n",
      "RELU:\n",
      "tensor([[[[5.8801e-02, 5.8801e-02, 1.6693e+00, 0.0000e+00, 1.3551e+00,\n",
      "           2.6801e+00],\n",
      "          [5.8801e-02, 5.8801e-02, 1.6693e+00, 0.0000e+00, 9.3863e-01,\n",
      "           1.6693e+00],\n",
      "          [5.8801e-02, 5.8801e-02, 1.6693e+00, 0.0000e+00, 9.3863e-01,\n",
      "           1.6693e+00],\n",
      "          [5.8801e-02, 5.8801e-02, 1.6693e+00, 6.6307e-01, 1.3548e+00,\n",
      "           4.5574e-01],\n",
      "          [5.8801e-02, 5.8801e-02, 7.9912e-01, 1.0444e+00, 1.3400e+00,\n",
      "           5.2625e-03],\n",
      "          [5.8801e-02, 5.8801e-02, 1.5918e-03, 4.7523e-01, 9.5519e-01,\n",
      "           1.0124e+00]],\n",
      "\n",
      "         [[3.6538e-01, 3.6538e-01, 4.2176e-01, 5.6632e-01, 1.0631e+00,\n",
      "           1.0636e+00],\n",
      "          [3.6538e-01, 3.6538e-01, 4.2176e-01, 1.3015e-01, 4.8522e-02,\n",
      "           4.2176e-01],\n",
      "          [3.6538e-01, 3.6538e-01, 4.2176e-01, 1.3015e-01, 4.8522e-02,\n",
      "           4.2176e-01],\n",
      "          [3.6538e-01, 3.6538e-01, 4.2176e-01, 1.6149e-01, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [3.6538e-01, 3.6538e-01, 3.9041e-01, 1.2024e-01, 0.0000e+00,\n",
      "           1.4868e-02],\n",
      "          [3.6538e-01, 3.6538e-01, 8.0156e-01, 1.3799e+00, 1.8795e+00,\n",
      "           1.4434e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4883e-02,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4883e-02,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 4.3874e-02, 0.0000e+00, 1.4977e-01,\n",
      "           6.7091e-02]],\n",
      "\n",
      "         [[1.9601e-01, 1.9601e-01, 0.0000e+00, 1.8476e-01, 8.5845e-01,\n",
      "           8.4574e-01],\n",
      "          [1.9601e-01, 1.9601e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.9601e-01, 1.9601e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.9601e-01, 1.9601e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.9601e-01, 1.9601e-01, 4.7245e-01, 2.0845e-01, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.9601e-01, 1.9601e-01, 5.3517e-01, 1.0972e+00, 1.7202e+00,\n",
      "           1.3810e+00]]]])\n",
      "\n",
      "\n",
      "POOL:\n",
      "tensor([[[[1.6693, 2.6801],\n",
      "          [1.6693, 1.3548]],\n",
      "\n",
      "         [[0.4218, 1.0636],\n",
      "          [0.8016, 1.8795]],\n",
      "\n",
      "         [[0.0000, 0.0449],\n",
      "          [0.0439, 0.1498]],\n",
      "\n",
      "         [[0.1960, 0.8584],\n",
      "          [0.5352, 1.7202]]]])\n",
      "\n",
      "\n",
      "FLATTEN:\n",
      "tensor([[1.6693, 2.6801, 1.6693, 1.3548, 0.4218, 1.0636, 0.8016, 1.8795, 0.0000,\n",
      "         0.0449, 0.0439, 0.1498, 0.1960, 0.8584, 0.5352, 1.7202]])\n",
      "\n",
      "\n",
      "LINEAR:\n",
      "-1.023301362991333\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    #dat = generate_data(visualise=False)\n",
    "    x = dat[0].clone().unsqueeze_(0)\n",
    "    y = model(x)\n",
    "    print('C' if y > 0 else 'D')\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"CONV:\")\n",
    "    \n",
    "    # visualize activations after convolution\n",
    "    for i, act in enumerate(activation['act'][0]):\n",
    "        print(act)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"RELU:\")\n",
    "    print(activation[\"relu\"])\n",
    "    print(\"\\n\")\n",
    "    print(\"POOL:\")\n",
    "    print(activation[\"pool\"])\n",
    "    print(\"\\n\")\n",
    "    print(\"FLATTEN:\")\n",
    "    print(activation[\"flatten\"])\n",
    "    print(\"\\n\")\n",
    "    print(\"LINEAR:\")\n",
    "    print(y.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y      -1.023301362991333\n",
      "target 0.0\n",
      "loss   0.3070482015609741\n"
     ]
    }
   ],
   "source": [
    "# Loss\n",
    "X, Y = dat\n",
    "logits = model(X.clone().unsqueeze_(0))  # feed-forward\n",
    "\n",
    "# not sure if I'm doing this right ...\n",
    "logits = logits.squeeze(-2)\n",
    "Y = Y.unsqueeze(0)\n",
    "\n",
    "J = loss(logits, Y)  # computes the loss\n",
    "\n",
    "print('y     ', logits.item())\n",
    "print('target', Y.item())\n",
    "print('loss  ', J.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Framework-less backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()  # cleans up previous gradients\n",
    "J.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache weights + biases BEFORE optimiser step\n",
    "w_old = {\n",
    "    'lin': model[4].weight.clone().detach(),\n",
    "    'lin_bias': model[4].bias.clone().detach(),\n",
    "    'conv': model[0].weight.clone().detach(),\n",
    "    'conv_bias': model[0].bias.clone().detach(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    # e^x => math.e ** 2\n",
    "    return 1 / (1 + math.e ** -x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L:  0.30704817175865173\n",
      "dL: 0.26438483595848083\n",
      "\n",
      "GOAL\n",
      " 0.3070482015609741 \n",
      " 0.26438483595848083\n"
     ]
    }
   ],
   "source": [
    "# BCEwithLogits Loss, formula from\n",
    "# https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/Loss.cpp\n",
    "\n",
    "y = logits\n",
    "\n",
    "max_val = max(0, -y)\n",
    "l = (1-Y) * y + max_val + math.log((math.e ** -max_val) + math.e ** (-y-max_val))\n",
    "\n",
    "# Derivative of BCEwithLogits Loss\n",
    "# grad_input = (input.sigmoid() - target).mul_(grad);\n",
    "dl = (sigmoid(y) - Y) * 1\n",
    "\n",
    "print(\"L: \", l.item())\n",
    "print(\"dL:\", dl.item())\n",
    "print('\\nGOAL\\n', J.item(), \"\\n\", backward[\"lin\"][\"input\"][0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dW\n",
      " tensor([[0.4413, 0.7086, 0.4413, 0.3582, 0.1115, 0.2812, 0.2119, 0.4969, 0.0000,\n",
      "         0.0119, 0.0116, 0.0396, 0.0518, 0.2270, 0.1415, 0.4548]],\n",
      "       grad_fn=<MulBackward0>)\n",
      " GOAL\n",
      " tensor([[0.4413, 0.7086, 0.4413, 0.3582, 0.1115, 0.2812, 0.2119, 0.4969, 0.0000,\n",
      "         0.0119, 0.0116, 0.0396, 0.0518, 0.2270, 0.1415, 0.4548]])\n",
      " DIFF 0.0\n",
      "\n",
      "\n",
      "dX\n",
      " tensor([[-0.2377, -0.2555, -0.0777, -0.1045,  0.0619,  0.2611,  0.0184,  0.0967,\n",
      "         -0.0287,  0.1007,  0.0275, -0.1114,  0.0771,  0.2801,  0.0990,  0.1219]],\n",
      "       grad_fn=<MulBackward0>)\n",
      " GOAL\n",
      " tensor([[-0.2377, -0.2555, -0.0777, -0.1045,  0.0619,  0.2611,  0.0184,  0.0967,\n",
      "         -0.0287,  0.1007,  0.0275, -0.1114,  0.0771,  0.2801,  0.0990,  0.1219]])\n",
      " DIFF 0.0\n",
      "\n",
      "\n",
      "dB\n",
      " tensor([0.2644], grad_fn=<MulBackward0>)\n",
      " GOAL\n",
      " tensor([0.2644])\n",
      " DIFF 0.0\n"
     ]
    }
   ],
   "source": [
    "# backward pass, linear layer\n",
    "dx = model[4].weight * dl\n",
    "dw = activation['flatten'] * dl\n",
    "db = dl\n",
    "\n",
    "print('\\ndW\\n',dw)\n",
    "print(' GOAL\\n', model[4].weight.grad)\n",
    "print(' DIFF', numpy.sum(a=(dw.detach().numpy() - model[4].weight.grad.detach().numpy())))\n",
    "\n",
    "print('\\n\\ndX\\n',dx)\n",
    "print(' GOAL\\n', backward[\"lin\"][\"input\"][1])\n",
    "print(' DIFF', numpy.sum(a=(dx.detach().numpy() - numpy.array(backward[\"lin\"][\"input\"][1]))))\n",
    "\n",
    "print('\\n\\ndB\\n',db)\n",
    "print(' GOAL\\n', model[4].bias.grad)\n",
    "print(' DIFF', numpy.sum(a=(db.detach().numpy() - model[4].bias.grad.detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2377, -0.2555],\n",
      "         [-0.0777, -0.1045]],\n",
      "\n",
      "        [[ 0.0619,  0.2611],\n",
      "         [ 0.0184,  0.0967]],\n",
      "\n",
      "        [[-0.0287,  0.1007],\n",
      "         [ 0.0275, -0.1114]],\n",
      "\n",
      "        [[ 0.0771,  0.2801],\n",
      "         [ 0.0990,  0.1219]]], grad_fn=<ViewBackward>)\n",
      "\n",
      "GOAL\n",
      " (tensor([[[[-0.2377, -0.2555],\n",
      "          [-0.0777, -0.1045]],\n",
      "\n",
      "         [[ 0.0619,  0.2611],\n",
      "          [ 0.0184,  0.0967]],\n",
      "\n",
      "         [[-0.0287,  0.1007],\n",
      "          [ 0.0275, -0.1114]],\n",
      "\n",
      "         [[ 0.0771,  0.2801],\n",
      "          [ 0.0990,  0.1219]]]]),)\n"
     ]
    }
   ],
   "source": [
    "# backward pass, flatten\n",
    "out = dx.reshape((4,2,2))\n",
    "goal = backward['pool']['output']\n",
    "\n",
    "print(out)\n",
    "print('\\nGOAL\\n', goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GOAL\n",
      " (tensor([[[[ 0.0000,  0.0000, -0.2377,  0.0000,  0.0000, -0.2555],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0777,  0.0000, -0.1045,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0619,  0.0000,  0.0000,  0.2611],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0184,  0.0000,  0.0967,  0.0000]],\n",
      "\n",
      "         [[-0.0287,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.1007,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0275,  0.0000, -0.1114,  0.0000]],\n",
      "\n",
      "         [[ 0.0771,  0.0000,  0.0000,  0.0000,  0.2801,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0990,  0.0000,  0.1219,  0.0000]]]]),)\n"
     ]
    }
   ],
   "source": [
    "# backward pass, maxpool2d\n",
    "# not implemented here... but it's easy:\n",
    "# the gradient gets assigned to the item that was max() during forward pass\n",
    "\n",
    "print('\\nGOAL\\n', backward['pool']['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000, -0.2377,  0.0000,  0.0000, -0.2555],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0777,  0.0000, -0.1045,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0619,  0.0000,  0.0000,  0.2611],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0184,  0.0000,  0.0967,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.1007,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0275,  0.0000, -0.1114,  0.0000]],\n",
      "\n",
      "        [[ 0.0771,  0.0000,  0.0000,  0.0000,  0.2801,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0990,  0.0000,  0.1219,  0.0000]]])\n",
      "\n",
      "GOAL\n",
      " tensor([[[ 0.0000,  0.0000, -0.2377,  0.0000,  0.0000, -0.2555],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0777,  0.0000, -0.1045,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0619,  0.0000,  0.0000,  0.2611],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0184,  0.0000,  0.0967,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.1007,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0275,  0.0000, -0.1114,  0.0000]],\n",
      "\n",
      "        [[ 0.0771,  0.0000,  0.0000,  0.0000,  0.2801,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0990,  0.0000,  0.1219,  0.0000]]])\n",
      "\n",
      "DIFF 0.0\n"
     ]
    }
   ],
   "source": [
    "# derivative of relu\n",
    "# see here: https://towardsdatascience.com/back-propagation-simplified-218430e21ad0\n",
    "\n",
    "# d = numpy.array(backward['pool']['input'][0][0][0], copy = True)\n",
    "# d[activation['relu'][0][0] < 0] = 0.\n",
    "\n",
    "relu_grad = backward['pool']['input'][0][0].clone().detach()\n",
    "\n",
    "for f in range(0,4):\n",
    "    for y in range(0,6):\n",
    "        for x in range(0,6):\n",
    "            if(activation['act'][0][f][y][x] <= 0):\n",
    "                relu_grad[f][y][x] = 0\n",
    "                \n",
    "print(relu_grad)\n",
    "print('\\nGOAL\\n', backward['relu']['input'][0][0])\n",
    "\n",
    "print('\\nDIFF', (backward['relu']['input'][0][0] - relu_grad).sum().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Make an optimiser step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache weights + biases AFTER optimiser step\n",
    "w_new = {\n",
    "    'lin': model[4].weight.clone().detach(),\n",
    "    'lin_bias': model[4].bias.clone().detach(),\n",
    "    'conv': model[0].weight.clone().detach(),\n",
    "    'conv_bias': model[0].bias.clone().detach(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8994, -0.9669, -0.2942, -0.3957,  0.2341,  0.9872,  0.0694,  0.3653,\n",
      "         -0.1084,  0.3809,  0.1039, -0.4212,  0.2914,  1.0593,  0.3744,  0.4605]])\n",
      "\n",
      "GOAL\n",
      " [-0.8994417  -0.96691954 -0.29422873 -0.39572755  0.23414905  0.98717695\n",
      "  0.06944731  0.36530203 -0.10837258  0.38086647  0.10394792 -0.42124274\n",
      "  0.29140663  1.0592552   0.37438115  0.4605175 ]\n",
      "\n",
      "DIFF: 0.0\n"
     ]
    }
   ],
   "source": [
    "# lin layer, weight update\n",
    "# https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n",
    "weight_update = w_old['lin'].clone()\n",
    "weight_update -= lr * dw.clone().detach()\n",
    "\n",
    "# goal\n",
    "goal = w_new['lin'][0].numpy()\n",
    "print(weight_update)\n",
    "print('\\nGOAL\\n', goal)\n",
    "print('\\nDIFF:', numpy.sum(a=(goal - weight_update[0].numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALC: 0.2817917764186859\n",
      "GOAL: 0.2817917764186859\n",
      "DIFF: 0.0\n"
     ]
    }
   ],
   "source": [
    "# lin layer, bias update\n",
    "new_bias = w_old['lin_bias'].clone() - db * lr\n",
    "\n",
    "print('CALC:', new_bias.item())\n",
    "print('GOAL:', model[4].bias.item())\n",
    "print('DIFF:', (model[4].bias.item()-new_bias).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### conv weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.35998118 -0.25545153 -0.315355  ]\n",
      "  [-0.10452966  0.         -0.5708065 ]\n",
      "  [-0.10452966 -0.10452966 -0.6753362 ]]\n",
      "\n",
      " [[ 0.35778067  0.35778067  0.17706348]\n",
      "  [ 0.          0.          0.32300392]\n",
      "  [ 0.          0.          0.32300392]]\n",
      "\n",
      " [[-0.01066127 -0.11135972 -0.0838744 ]\n",
      "  [ 0.10069846  0.          0.        ]\n",
      "  [ 0.10069846  0.          0.        ]]\n",
      "\n",
      " [[ 0.4019851   0.4019851   0.50100327]\n",
      "  [ 0.28011104  0.          0.        ]\n",
      "  [ 0.28011104  0.          0.        ]]]\n",
      "\n",
      "GOAL\n",
      " tensor([[[-0.3600, -0.2555, -0.3154],\n",
      "         [-0.1045,  0.0000, -0.5708],\n",
      "         [-0.1045, -0.1045, -0.6753]],\n",
      "\n",
      "        [[ 0.3578,  0.3578,  0.1771],\n",
      "         [ 0.0000,  0.0000,  0.3230],\n",
      "         [ 0.0000,  0.0000,  0.3230]],\n",
      "\n",
      "        [[-0.0107, -0.1114, -0.0839],\n",
      "         [ 0.1007,  0.0000,  0.0000],\n",
      "         [ 0.1007,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.4020,  0.4020,  0.5010],\n",
      "         [ 0.2801,  0.0000,  0.0000],\n",
      "         [ 0.2801,  0.0000,  0.0000]]])\n",
      "DIFF 0.0\n"
     ]
    }
   ],
   "source": [
    "# backward pass, conv\n",
    "\n",
    "# only doing it here, after optimiser.step() so that model[0].weight.grad has a gradient for comparison\n",
    "\n",
    "# incoming gradient\n",
    "g = backward['relu']['input'][0][0]\n",
    "\n",
    "# gradient var\n",
    "conv_grad = torch.zeros((4,3,3))\n",
    "\n",
    "# filters\n",
    "for f in range(0,4):\n",
    "    for fy in range(0,3):\n",
    "        for fx in range(0,3):\n",
    "            # slide gradient over input X to get dF\n",
    "            for y in range(0,6):\n",
    "                for x in range(0,6):\n",
    "                    conv_grad[f][fy][fx] += g[f][y][x] * dat[0][0][y+fy][x+fx]\n",
    "\n",
    "goal = model[0].weight.grad.clone().squeeze(1)\n",
    "\n",
    "print(conv_grad.numpy())\n",
    "print('\\nGOAL\\n', goal)\n",
    "print('DIFF', (conv_grad - goal).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4803,  0.4739, -0.0569],\n",
      "         [ 0.2893, -0.2855,  0.7981],\n",
      "         [ 0.1108, -0.4540,  0.8709]],\n",
      "\n",
      "        [[ 0.4992,  0.5780,  0.4360],\n",
      "         [-0.3743, -0.4124, -0.4115],\n",
      "         [-0.4421, -0.4012,  0.0310]],\n",
      "\n",
      "        [[ 0.4331, -0.3271,  0.0828],\n",
      "         [-0.2295, -0.1229, -0.1621],\n",
      "         [-0.1201, -0.2880,  0.0476]],\n",
      "\n",
      "        [[ 0.6226,  0.5616,  0.3387],\n",
      "         [-0.6330, -0.4868, -0.0627],\n",
      "         [-0.2293, -0.4256, -0.4726]]])\n",
      "\n",
      "GOAL: tensor([[[ 0.4803,  0.4739, -0.0569],\n",
      "         [ 0.2893, -0.2855,  0.7981],\n",
      "         [ 0.1108, -0.4540,  0.8709]],\n",
      "\n",
      "        [[ 0.4992,  0.5780,  0.4360],\n",
      "         [-0.3743, -0.4124, -0.4115],\n",
      "         [-0.4421, -0.4012,  0.0310]],\n",
      "\n",
      "        [[ 0.4331, -0.3271,  0.0828],\n",
      "         [-0.2295, -0.1229, -0.1621],\n",
      "         [-0.1201, -0.2880,  0.0476]],\n",
      "\n",
      "        [[ 0.6226,  0.5616,  0.3387],\n",
      "         [-0.6330, -0.4868, -0.0627],\n",
      "         [-0.2293, -0.4256, -0.4726]]])\n",
      "DIFF: 0.0\n"
     ]
    }
   ],
   "source": [
    "new_weights = w_old['conv'].clone().squeeze(1)\n",
    "new_weights -= lr * conv_grad\n",
    "goal = w_new['conv'].clone().squeeze(1)\n",
    "\n",
    "print(new_weights)\n",
    "print('\\nGOAL:', goal)\n",
    "print('DIFF:', (goal - new_weights).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0595,  0.3649, -0.0388,  0.1954])\n",
      "GOAL: tensor([ 0.0595,  0.3649, -0.0388,  0.1954])\n",
      "DIFF: 0.0\n"
     ]
    }
   ],
   "source": [
    "# conv layer, bias update\n",
    "# -> sum of filter gradient is dB\n",
    "# https://stackoverflow.com/questions/3775032/how-to-update-the-bias-in-neural-network-backpropagation\n",
    "# https://datascience.stackexchange.com/questions/25081/how-to-update-bias-in-cnn\n",
    "\n",
    "# biases before weight update\n",
    "biases = w_old['conv_bias'].clone()\n",
    "\n",
    "for i in range(len(biases)):\n",
    "    biases[i] -= g[i].sum() * lr\n",
    "\n",
    "goal = model[0].bias.clone().detach()\n",
    "\n",
    "print(biases)\n",
    "print('GOAL:', goal)\n",
    "print('DIFF:', (goal - biases).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
