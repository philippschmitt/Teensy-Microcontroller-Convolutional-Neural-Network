{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini neural net training\n",
    "Authors: Alfredo Canziani, Philipp Schmitt  \n",
    "Date: 15 Apr, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from IPython import display\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from matplotlib.pyplot import imshow, axis, figure, subplot, pause\n",
    "import numpy\n",
    "import random\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10dc9b150>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# static random seed\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input definition\n",
    "class input_settings:\n",
    "    batch_size = 1\n",
    "    channels = 1\n",
    "    height = 8\n",
    "    width = 8\n",
    "\n",
    "dummy_X = torch.randn(  # batch of inputs x\n",
    "    input_settings.batch_size,\n",
    "    input_settings.channels,\n",
    "    input_settings.height,\n",
    "    input_settings.width,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network architecture\n",
    "class model_settings:\n",
    "    conv_channels = 4\n",
    "    kernel = 3\n",
    "    pooling_kernel = 3\n",
    "    flattened = 16\n",
    "    output_size = 1\n",
    "    \n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(\n",
    "        in_channels=input_settings.channels,\n",
    "        out_channels=model_settings.conv_channels,\n",
    "        kernel_size=model_settings.kernel,\n",
    "        bias=True,\n",
    "    ),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(\n",
    "        kernel_size=model_settings.pooling_kernel,\n",
    "        stride=model_settings.pooling_kernel,\n",
    "    ),  # we have 4 x 2x2\n",
    "    nn.Flatten(),  # gives 16\n",
    "    nn.Linear(\n",
    "        in_features=model_settings.flattened,\n",
    "        out_features=model_settings.output_size,\n",
    "        bias=True,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "with torch.no_grad():\n",
    "    print(model(dummy_X).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Flatten()\n",
      "  (4): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weights and biases\n",
    "def get_weights():\n",
    "    print(\n",
    "        model[0],\n",
    "        model[0].weight,\n",
    "        model[0].bias,\n",
    "        sep='\\n',\n",
    "    )\n",
    "    print(\n",
    "        model[4],\n",
    "        model[4].weight,\n",
    "        model[4].bias,\n",
    "        sep='\\n',\n",
    "    )\n",
    "    # Maybe add some saving routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letter samples\n",
    "samples = [\n",
    "    [\n",
    "        [0,1,1,1],\n",
    "        [1,0,0,0],\n",
    "        [1,0,0,0],\n",
    "        [1,0,0,0],\n",
    "        [1,0,0,0],\n",
    "        [0,1,1,1]\n",
    "    ],\n",
    "    [\n",
    "        [1,1,1],\n",
    "        [1,0,0],\n",
    "        [1,0,0],\n",
    "        [1,1,1]\n",
    "    ],\n",
    "    [\n",
    "        [1,1,1,0],\n",
    "        [1,0,0,1],\n",
    "        [1,0,0,1],\n",
    "        [1,0,0,1],\n",
    "        [1,0,0,1],\n",
    "        [1,1,1,0]\n",
    "    ],\n",
    "    [\n",
    "        [1,1,0],\n",
    "        [1,0,1],\n",
    "        [1,0,1],\n",
    "        [1,1,0]\n",
    "    ]\n",
    "]\n",
    "\n",
    "sample_meta = [\n",
    "    [6,4,'C'],\n",
    "\t[4,3,'C'],\n",
    "\t[6,4,'D'],\n",
    "\t[4,3,'D']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0., 0., 0., 1., 1., 1., 0., 0.],\n",
       "           [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 1., 1., 1., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.]]]]), tensor(1.))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAyFJREFUeJzt3cEJAzEMAEErpP+WnQZyj3Akhs1MBQKz6GPQrLX2ApIepwcAvkfgECZwCBM4hAkcwgQOYQKHMIFDmMAh7Hl6AK7t7ZPhXTNzeoSjbHAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziEOV30gV+fEvr3szvcZ4NDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAibtdY+PQTv7e1p7pqZ0yMcZYNDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhzOkiCLPBIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYS/Krw33u7HZCQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# updated gen. function to match teensy implementation\n",
    "def generate_data(visualise=False, target=None):\n",
    "    data = numpy.zeros(shape=(8,8), dtype=numpy.float32)\n",
    "    \n",
    "    sample = random.randint(0,len(samples)-1)\n",
    "    character = sample_meta[sample][2];\n",
    "    \n",
    "    x = random.randint(\n",
    "        0,\n",
    "        input_settings.width-sample_meta[sample][1]\n",
    "    )\n",
    "    y = random.randint(\n",
    "        0,\n",
    "        input_settings.height-sample_meta[sample][0]\n",
    "    )\n",
    "    \n",
    "    data[y:y+sample_meta[sample][0],x:x+sample_meta[sample][1]] = samples[sample]\n",
    "    \n",
    "    if visualise:\n",
    "        figure(facecolor='k')\n",
    "        imshow(data, cmap='gray')\n",
    "        axis('off');\n",
    "        \n",
    "    return torch.tensor(data).unsqueeze_(0).unsqueeze_(0), torch.tensor(character=='C', dtype=torch.float)\n",
    "        \n",
    "generate_data(visualise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEYAAABGCAIAAAD+THXTAAAATUlEQVR4nO3TMQoAIQwEQL3//zk2coiWUU6OmSpNFrbYUgAA+Juaj4iInlU3pOU9yf+3z3R/KFvpQiotxv1csiUAAAAAAAAAAAAA4JgGt1sJCjqkBk8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=70x70 at 0x109C77908>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from numpy import interp\n",
    "from math import cos, sin, radians, pi\n",
    "\n",
    "\n",
    "def draw_weight(value, size=20):\n",
    "    rad = interp(value,[-.75,.75],[pi,0])\n",
    "    im = Image.new('RGB', (size, size), (0, 0, 0))\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    x, y, r = (\n",
    "        size/2 + size/3 * cos(rad), \n",
    "        size/2 - size/3 * sin(rad),\n",
    "        4)\n",
    "    draw.ellipse((x-r/2, y-r/2, x+r/2, y+r/2), fill=(255, 255, 255), outline=None)\n",
    "\n",
    "    return im\n",
    "\n",
    "draw_weight(-.25, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAAeCAIAAABc99v3AAABNElEQVR4nO3aMY7DMAwEQCu4/3/ZVwVwcXYl0tLeTJWKlAVx4Sg5jjLneSquuOKKK95W/FNXHYBOAh0gxM/bCziOy9eQMcbKNXuKt3XZbtvr2jUvu9qUx8k45NUtVhvSpzf082vCuh67/Pl5tZo9xdu6bLftde2al33tVTFfUx4n45BXt1hwSG8D/a1TDv+B+aKCO3SAEO8H+vVuaNY9VEXNnuJtXbbb9rp2zcuuNuVxMg55dYsFh/T2R9ExRtsvRdV7sVfxti7bbXtdu/4cL52vKQUzDnl1i9WG9OlfLgFvK7As88V071+5ADCFQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBC/cK7SKe8H8nUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=496x30 at 0x109C869E8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw weights\n",
    "\n",
    "def draw_weights(layer, size=20):\n",
    "    weights = layer.weight.data.clone().numpy()\n",
    "\n",
    "    n_weights = len(weights[0])\n",
    "    im = Image.new('RGB', ((size+1)*n_weights, size), (255, 255, 255))\n",
    "\n",
    "    for i in range(n_weights):\n",
    "        weight = draw_weight(weights[0][i], size=size)\n",
    "        im.paste(weight,((size+1)*i,0))\n",
    "\n",
    "    return im\n",
    "\n",
    "draw_weights(model[4], size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAD8AAAA/CAIAAADYPYeIAAAA9UlEQVR4nO2awQoDIQxEtfT/f9keetkVNJpEx8i844KTh0QxpSkZKKVgl3/Ha+Scp6IVq2YTPoMRaWardKsUCYL94Vxt/+y58Q7WrfJNkIHfOVd3zuHQHgftcdAeB+1x0B5HbPtsfOgFBv5CFqbyPcO1ml7fbxuuR3L+VN8DnNrOFgSw79CzP3+4Fk6tvaRLQuvoy78EnkBrC+7t+/OhPQ7a46A9DtrjoD0OTuW45UteyF6TuJhT931r/lWUTOZJXMx52XsV3kbsO8ff3msSH8l5ndrO/KsubEHMqe+cVX8KWAP7HgftcdAeB+1x0B4H7XHEnsp/C5qQT/FM8BQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=63x63 at 0x12217B4A8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw a filter\n",
    "def draw_filter(filter):\n",
    "    matrix = Image.new('RGB', (63, 63), (255, 255, 255))\n",
    "    data = filter.view(3, 3).numpy()\n",
    "    # go over filter\n",
    "    # rows\n",
    "    for x in range(0, data.shape[0]):\n",
    "        # cols\n",
    "        for y in range(0, data.shape[1]):\n",
    "            vis = draw_weight(data[y,x])\n",
    "            matrix.paste(vis,(x*21,y*21))\n",
    "    return matrix\n",
    "\n",
    "filters = model[0].weight.data\n",
    "draw_filter(filters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARoAAAA/CAIAAACwx5DcAAACiElEQVR4nO3czU7DMBBF4Rrx/q9cFpUQrajjes74JznfikU8jp3eQiIy5RZwv99LKROH1w+Ye24u7d3w+gFbL+275aDHDx/N1DeKraDxBly1iR+Mw6m/GsffGr5XgqPYCu0TPew4HCkOnsOAq4ZM0bfklqkP4nRuwWszdzhSfNjX1jpSl3zpOEmsgzj9/Rux/U/VvlFsBY034KpN/GC0TH38KCKehz4DNquUErmvnTscKY6fw5irFhzeveTD44/jdG7xazNxOFL8gr/885bsvZOEMU4SxjhJGOMkYYyThDFOEsY4SRjjJGGMk4QxThLGOEkY4yRhykVeGpMGCP1r7fROF/UDtm7iUT/Apb0rvnTrlbN2UJl7VnmzByt3D1/zKmeor7R277ROBxW2RUl3PxnkHPJ6FczqXZG6oviej+wts8GjiBXag6xwDldDNS2KF2m3QZykXdTidNYOKnPPKm/2YOXu4Wte5QyHKz14FLFCB5WMFiUdPTfAc8j7zM3qXZGxImTPB/eW2aP1ygrfeSucw9Xs0lzpl/dOEsY4SRjjJGGMk4QxThLGOEkY4yRhjJOEMU4SxjhJGOMkYYyThLH1ioSx9crb4i4taXj9gK2XlvKCBvWGCf6a00U6hHQsE9yZZRvLDJj09d4p3qcCbLeC1EEKsr1fUst2LBPc6tUaywR3+NNJn+Jkg5F/JW2Lu51t/A77ZE/C8HGiGnHgDT0u0iGkY5ngzizbWGbMpE+PIqg+FbMapCQVzOj9kle2rxq7LqpUsDLVvKX94Ncneyf+2o5I2hZ3O9vgHfbeScIYJwljnCSMcZIwxknCGCcJY5wkjHGSMMZJwhgnCWOcJIxxkjC2XpEwP13zN1vs/so5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=282x63 at 0x109BE1940>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw all filters\n",
    "def draw_filters(layer):\n",
    "    matrix = Image.new('RGB', (282, 63), (255, 255, 255))\n",
    "    filters = layer.weight.data.clone()\n",
    "    for i, filter in enumerate(filters):\n",
    "        vis = draw_filter(filter)\n",
    "        matrix.paste(vis, (i*(63+10),0))\n",
    "    return matrix\n",
    "\n",
    "\n",
    "draw_filters(model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAABkCAIAAAA+Dt3DAAAD0UlEQVR4nO3dwW7dOAwF0LxB//+XPYtgMinQpNcSZdHOOasCDWlL9rutHYR5HcfxdqHX6zVcexzH3vLvv8DSvmpuaYvKh2vH/Lr4eH/1sQWn9nGsqrYD17vgqm28Mbrdk//sPoHffA7LPDjHqmo75Ad6d8fykuaF53DBVSs5xNiSL7snc73C4tkmL//e8pLmDT8Aqz1pycICiPQKi8/PZvlz2lhVbQeud8FV23hjNLwn273gnP+0X3ncs4eYeWW1t7ykefk5XHPVJsuHl9wkIz60C4tnm7/zNpaXNO/2AbjAY5bc6zEEaEtYABFhAUSEBRARFkBEWAARYQFEhAUQERZARFgAEWEBRIQFEHndfSAHcI2rf+r0wfNRLe2r5pa2qHy4dkyvH1F/6tzdvWe17uiTnYfLe17lFVqttNE7iz5zd2sH2w5PIS45h3UzIHfNBF26ovk9v9dE4lMahUUTHa5Qh3P4aaoGec83aUtYAJFGYfHUubt7z2rd0Sc7D5f3vMordFtprxecHeburhhsOzCptfAc1t1nu2aCrlhRyZ7fcSJxrldYNNHhCnU4h5/meR/vWo0eQ4DOhAUQERZARFgAEWEBRIQFEBEWQERYABFhAUSEBRARFkBEWAARA3uBiIG9J8q//wJL+6q5pS0qH64d84QfUa+aIFA+xqLVtNV1BpZZuDNtxxHf6KChze8s5qebFg7pLelT0rB2YvDStgPLLNzqbuOIJ3e4+QjPnWHRfGt2WbQtdnu1x++w74YAkduHRdVQ0/LhqN2mrS4ysMzCnWk7jvhGB83tfMFZNd1011jdRQ1XTAxe13asW+26qlpNdq4a+TtWeIHN3w3pvDUbLdoWu73as3f49o8hwDWEBRARFkBEWAARYQFEhAUQERZARFgAEWEBRIQFEBEWQERYABEDe4GI/1kAEWEBRIQFEBEWQERYABFhAUSEBRARFkBEWAARYQFEhAUQERZARFgAEWEBRIQFEBEWQERYAJFf3//1zK+QP45DuXLlNyr//gv+EhaLfJzW2bUNF5aUVzXZtfyZVoWHnrfl5Dde9w7lb2cfQ47/jB3so8kf/7yusKS8qsmu5c+0Kjz05z5j99KWk9943TuUvzsRFivuGH4m99IdecEJRDaExedHplOPT8OFJeVVTXYtf6ZV4aHnbTn5jde9Q/m7Ey84X6//f8lI4c16TWFJeVWTXcufaVWbEZP30paT33jdO5S/nf1uyPZ/VXgM99LteGcBRIQFEBEWQERYABFhAUSEBRARFkBEWAARYQFEhAUQERZARFgAkX8BXj0M4L2XhdsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=356x100 at 0x1220E3DD8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw all the weights in the net\n",
    "def draw_net():\n",
    "    im = Image.new('RGB', (356, 100), (255, 255, 255))\n",
    "    im.paste(draw_filters(model[0]), (37,0))\n",
    "    im.paste(draw_weights(model[4]), (10,80))\n",
    "\n",
    "    return im\n",
    "\n",
    "draw_net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up network training\n",
    "nb_epochs = 20_000\n",
    "lr = 1e-3\n",
    "optimiser = optim.SGD(params=model.parameters(), lr=lr)\n",
    "#loss = nn.BCEWithLogitsLoss()\n",
    "loss = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH]: 19900, [LOSS]: 0.091626, [ACCURACY]: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(nb_epochs):\n",
    "    # Training steps\n",
    "    X, Y = generate_data()\n",
    "    logits = model(X)  # feed-forward\n",
    "    \n",
    "    # not sure if I'm doing this right ...\n",
    "    logits = logits.squeeze(-2)\n",
    "    Y = Y.unsqueeze(0)\n",
    "\n",
    "    J = loss(logits, Y)  # computes the loss\n",
    "    model.zero_grad()  # cleans up previous gradients\n",
    "    J.backward()\n",
    "    optimiser.step()\n",
    "    \n",
    "    # Accuracy computation and display\n",
    "    score, predicted = torch.max(logits, 0)\n",
    "    acc = (Y == (logits > 0)).sum().float() / len(Y)\n",
    "    \n",
    "    if(epoch % 100 == 0):\n",
    "        display.clear_output(wait=True)\n",
    "        print(\"[EPOCH]: %i, [LOSS]: %.6f, [ACCURACY]: %.3f\" % (epoch, J.item(), acc))\n",
    "        \n",
    "        continue\n",
    "        # skip the code below, used to visualize weight movements on physical net\n",
    "        \n",
    "        print(model[0].weight.data)\n",
    "        \n",
    "        figure(figsize=(10, 20))\n",
    "        #visualize_filters(model[0])\n",
    "        im = draw_net()\n",
    "        imshow(numpy.asarray(im), aspect='equal', interpolation='nearest')\n",
    "        \n",
    "        # im.save('%s.png' % epoch)\n",
    "        \n",
    "        #draw_filters(model[0]).save('%i.png' % epoch)\n",
    "        axis('off');\n",
    "        pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAyJJREFUeJzt3cEJAkAMAMFE7L/lswJfoifLTAXhYMnnIDszZ4Ckx+0BgO8ROIQJHMIEDmEChzCBQ5jAIUzgECZwCHveHoD3zvHJ8FO7e3uEq2xwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hDldxMx0T/z8+vzTv72jDQ5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIex5ewD+wznn9ghfsbu3R7jKBocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUPYzkzzZg1gg0OZwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMJeWt8M/spHNlQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inference: C vs. D detector\n",
    "with torch.no_grad():\n",
    "    print('C' if model(generate_data(visualise=True)[0]) > 0 else 'D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Visualization & Printing of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x122212f60>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# register hook to get activation after conv layer out\n",
    "\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "backward = {}\n",
    "def get_backward(name):\n",
    "    def hook(model, input, output):\n",
    "        backward[name] = {}\n",
    "        backward[name]['input'] = input\n",
    "        backward[name]['output'] = output\n",
    "    return hook\n",
    "\n",
    "model[0].register_forward_hook(get_activation('conv'))\n",
    "model[1].register_forward_hook(get_activation('relu'))\n",
    "model[2].register_forward_hook(get_activation('pool'))\n",
    "model[3].register_forward_hook(get_activation('flatten'))\n",
    "\n",
    "model[0].register_backward_hook(get_backward('conv'))\n",
    "model[1].register_backward_hook(get_backward('relu'))\n",
    "model[2].register_backward_hook(get_backward('pool'))\n",
    "model[3].register_backward_hook(get_backward('flatten'))\n",
    "model[4].register_backward_hook(get_backward('lin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABrCAYAAABXGGiIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAstJREFUeJzt2yFOq1EUhdEDaQiYqkpmUN10CB1AHfNgCpUVDIAp1CBwgMcxAgRpUlXTkNT0uZc8B3/egexkLU33/XPFl2s4O51OBUCO89/+AAC+R7gBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBm1DH69PTU+u+Yx+Oxc76qql5eXlr3V6vV2ZDfPT8/t97t1dVV53xVVe33+9b9xWIx6G4fHx9b7/b+/r5zvqqqZrNZ6/7t7e2gu62qent7a73fw+HQOV9VVR8fH637y+XyS/frxQ0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEEa4AcIIN0AY4QYII9wAYYQbIIxwA4QZdYxut9uO2b8eHh5a96uq1ut1+xlD3N3dte4fj8fW/aqq8/Pe98JisRj0u81m85+/5F/X19et+1VV7+/v7WcMdXNz07o/mUxa96uq5vN56/5yufzS33lxA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEEa4AcIIN0AY4QYII9wAYYQbIMyoY3S323XM/th+VdXl5WX7GUN8fn627l9cXLTuV1XN5/P2M4YYj8et+9vttnW/qmo6nbafMdRsNmvd/4n7fX19bT/jK7y4AcIIN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMGen0+m3vwGAb/DiBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEEa4AcIIN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwvwBXRdPA31HbAQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize weights\n",
    "def visualize_filters(layer):\n",
    "    filters = layer.weight.data\n",
    "    # visualize\n",
    "    for i in range(0, len(filters)):\n",
    "        data = filters[i].view(3, 3)\n",
    "        subplot(1, 4, i+1)\n",
    "        imshow(data, cmap='gray', vmin=-1, vmax=1)\n",
    "        axis('off');\n",
    "        \n",
    "visualize_filters(model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABrCAYAAABXGGiIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAA4hJREFUeJzt3DEr9X0cx/Hjjs515AEYDCaTRQZSFoXVZvcIlMWgrBabyQOwnlUpEUkxMVkpw7EpKcm5l7uu4V581bmcj+v1mj8/v9N/ePdf/Ae63W4DgBz/fPcPAKBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEGawF390Z2enp/+Oubm5Wdrv7u6W79jY2CjtX19fS/tWqzVQOvCfdrvd02d7e3tb2u/t7ZXveHp6Ku1XVlZK+3a7/aVnu7W11dNn+/z8XNpfXFz06Jf8NjExUdofHBx86dk2Go3G/v5+T5/v0dFRaf+V5/v4+Fg+U9Htdj/1fL1xA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRCmJ98q6TdXV1c9v6PVavX8jj9hdna2tF9eXi7fMTMzUz7zEwwPD5f2Ly8v5TsWFxdL+5GRkfId/WpycrK0X1hYKN+xurpaPtML3rgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCPNXfKtkaGiofOb9/b20Hxz8Kx7l/1xeXpbPnJyclPZTU1Ol/dLSUmnfr77yrZLx8fHSvtPplO/4KW5vb8tnHh4eSvtms1nab29vf2rnjRsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEEa4AcIIN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhBr/7B/wJ6+vr5TODg7VHc3x8XNovLCyU9v1qaGiofObq6qq0Pz09Le2XlpZK+37VbDbLZ+7v70v7m5ub8h0/xdnZWfnM3d1dab+2tla+4zO8cQOEEW6AMMINEEa4AcIIN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QJvJbJZ1Op7Sfnp7u0S/57fz8vLTv12+VvL299XTfaDQaHx8fpf3c3Fz5jn5UfVa/fv0q31H9vsnY2Fj5jn41Pz9f2o+OjpbvODw8LO2vr6/Ld3yGN26AMMINEEa4AcIIN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgx0u93v/g0AFHjjBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEEa4AcIIN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwvwLFDyDZmOEIn0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inference: C vs. D \n",
    "# Conv. activations visualized\n",
    "with torch.no_grad():\n",
    "    print('C' if model(generate_data(visualise=False)[0]) > 0 else 'D')\n",
    "    \n",
    "    # visualize activations after convolution\n",
    "    for i, act in enumerate(activation['act'][0]):\n",
    "        data = act.view(6,6)\n",
    "        subplot(1, 4, i+1)\n",
    "        imshow(data, cmap='gray', vmin=-1, vmax=1)\n",
    "        axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# A printout of sample data, activations, outputs to troubleshoot Teensy implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONV WEIGHTS\n",
      "[[[ 0.48655856  0.43754515 -0.04270939]\n",
      "  [ 0.2965575  -0.29573244  0.812206  ]\n",
      "  [ 0.12389094 -0.47293442  0.8682822 ]]\n",
      "\n",
      " [[ 0.49971846  0.5658796   0.44064614]\n",
      "  [-0.3587915  -0.41190198 -0.3926472 ]\n",
      "  [-0.4345919  -0.38967448  0.03981554]]\n",
      "\n",
      " [[ 0.43406776 -0.33296576  0.08311657]\n",
      "  [-0.1994078  -0.11182111 -0.15975702]\n",
      "  [-0.08765889 -0.28486034  0.05038778]]\n",
      "\n",
      " [[ 0.6418607   0.5562797   0.34915066]\n",
      "  [-0.6512311  -0.49493206 -0.06805275]\n",
      "  [-0.24198909 -0.4337809  -0.47631782]]]\n",
      "\n",
      "CONV BIAS\n",
      "[ 0.05719715  0.3607946  -0.03847682  0.20167698]\n",
      "\n",
      "LIN WEIGHTS\n",
      "[[-0.88604647 -0.9647142  -0.30584323 -0.44464505  0.24024756  0.96177334\n",
      "   0.06257226  0.3562044  -0.10670137  0.36404055  0.10728421 -0.41222888\n",
      "   0.33352402  1.0776179   0.37871382  0.46879   ]]\n",
      "\n",
      "LIN BIAS\n",
      "[0.2838484]\n"
     ]
    }
   ],
   "source": [
    "print(\"CONV WEIGHTS\")\n",
    "print(model[0].weight.clone().detach().squeeze(1).numpy())\n",
    "print('\\nCONV BIAS')\n",
    "print(model[0].bias.clone().detach().numpy())\n",
    "\n",
    "print('\\nLIN WEIGHTS')\n",
    "print(model[4].weight.clone().detach().numpy())\n",
    "print('\\nLIN BIAS')\n",
    "print(model[4].bias.clone().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 1., 1., 1., 0., 0., 0.],\n",
      "          [0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 1., 1., 1., 0., 0., 0.]]]]), tensor(1.))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAx5JREFUeJzt3dEJQyEQRUE3pP+WTRNJxPNmKrgIh/101lp7AUmv0wOA3xE4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCHsfXrATfbepyckzMzpCY/hgkOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BB2/d9k//wvzJ9a3MYFhzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQNmutfXrELfb2VN8wM6cnPIYLDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzBfF0GYCw5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziEfQAT0A33vfl7UgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a sample for all following data dumps\n",
    "dat = generate_data(visualise=True)\n",
    "print(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n",
      "\n",
      "\n",
      "CONV:\n",
      "tensor([[ 0.9255,  0.4525,  0.5764, -0.2918,  0.1811,  0.0572],\n",
      "        [ 0.3965,  0.6976,  0.8702,  0.0580,  0.3538,  0.0572],\n",
      "        [-0.7542,  0.8725,  0.9386,  0.9813,  0.5438,  0.0572],\n",
      "        [-0.2739,  0.9642,  0.0572,  0.0572,  0.0572,  0.0572],\n",
      "        [-0.2739,  0.9642,  0.0572,  0.0572,  0.0572,  0.0572],\n",
      "        [ 1.0673,  1.2357,  0.5764, -0.2918,  0.1811,  0.0572]])\n",
      "tensor([[ 4.0061e-01,  1.0936e-02, -4.2366e-01, -4.6347e-01, -7.3797e-02,\n",
      "          3.6079e-01],\n",
      "        [-4.2153e-01, -8.7835e-01, -8.0255e-01, -4.0990e-01,  2.0031e-03,\n",
      "          3.6079e-01],\n",
      "        [-1.3575e-04,  5.7394e-01,  1.8670e+00,  1.4264e+00,  8.6051e-01,\n",
      "          3.6079e-01],\n",
      "        [ 1.2510e-01,  6.7130e-02,  3.6079e-01,  3.6079e-01,  3.6079e-01,\n",
      "          3.6079e-01],\n",
      "        [ 1.2510e-01,  6.7130e-02,  3.6079e-01,  3.6079e-01,  3.6079e-01,\n",
      "          3.6079e-01],\n",
      "        [ 5.5459e-01,  1.5186e-01, -4.2366e-01, -4.6347e-01, -7.3797e-02,\n",
      "          3.6079e-01]])\n",
      "tensor([[ 0.0119, -0.2729, -0.3606, -0.4110, -0.1261, -0.0385],\n",
      "        [-0.4831, -0.3977, -0.5095, -0.3497, -0.2379, -0.0385],\n",
      "        [-0.3520, -0.5754,  0.1457,  0.0626,  0.3956, -0.0385],\n",
      "        [-0.7681,  0.1085, -0.0385, -0.0385, -0.0385, -0.0385],\n",
      "        [-0.7681,  0.1085, -0.0385, -0.0385, -0.0385, -0.0385],\n",
      "        [-0.4329, -0.0383, -0.3606, -0.4110, -0.1261, -0.0385]])\n",
      "tensor([[-0.2746, -0.7084, -0.9504, -0.4741, -0.0403,  0.2017],\n",
      "        [-0.3002, -0.6033, -1.0125, -0.9445, -0.4496,  0.2017],\n",
      "        [-0.3779,  0.2139,  1.7490,  1.3998,  0.8435,  0.2017],\n",
      "        [-0.1708, -0.0497,  0.2017,  0.2017,  0.2017,  0.2017],\n",
      "        [-0.1708, -0.0497,  0.2017,  0.2017,  0.2017,  0.2017],\n",
      "        [-0.2133, -0.7178, -0.9504, -0.4741, -0.0403,  0.2017]])\n",
      "\n",
      "\n",
      "RELU:\n",
      "tensor([[[[0.9255, 0.4525, 0.5764, 0.0000, 0.1811, 0.0572],\n",
      "          [0.3965, 0.6976, 0.8702, 0.0580, 0.3538, 0.0572],\n",
      "          [0.0000, 0.8725, 0.9386, 0.9813, 0.5438, 0.0572],\n",
      "          [0.0000, 0.9642, 0.0572, 0.0572, 0.0572, 0.0572],\n",
      "          [0.0000, 0.9642, 0.0572, 0.0572, 0.0572, 0.0572],\n",
      "          [1.0673, 1.2357, 0.5764, 0.0000, 0.1811, 0.0572]],\n",
      "\n",
      "         [[0.4006, 0.0109, 0.0000, 0.0000, 0.0000, 0.3608],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0020, 0.3608],\n",
      "          [0.0000, 0.5739, 1.8670, 1.4264, 0.8605, 0.3608],\n",
      "          [0.1251, 0.0671, 0.3608, 0.3608, 0.3608, 0.3608],\n",
      "          [0.1251, 0.0671, 0.3608, 0.3608, 0.3608, 0.3608],\n",
      "          [0.5546, 0.1519, 0.0000, 0.0000, 0.0000, 0.3608]],\n",
      "\n",
      "         [[0.0119, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.1457, 0.0626, 0.3956, 0.0000],\n",
      "          [0.0000, 0.1085, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1085, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2017],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2017],\n",
      "          [0.0000, 0.2139, 1.7490, 1.3998, 0.8435, 0.2017],\n",
      "          [0.0000, 0.0000, 0.2017, 0.2017, 0.2017, 0.2017],\n",
      "          [0.0000, 0.0000, 0.2017, 0.2017, 0.2017, 0.2017],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2017]]]])\n",
      "\n",
      "\n",
      "POOL:\n",
      "tensor([[[[0.9386, 0.9813],\n",
      "          [1.2357, 0.1811]],\n",
      "\n",
      "         [[1.8670, 1.4264],\n",
      "          [0.5546, 0.3608]],\n",
      "\n",
      "         [[0.1457, 0.3956],\n",
      "          [0.1085, 0.0000]],\n",
      "\n",
      "         [[1.7490, 1.3998],\n",
      "          [0.2017, 0.2017]]]])\n",
      "\n",
      "\n",
      "FLATTEN:\n",
      "tensor([[0.9386, 0.9813, 1.2357, 0.1811, 1.8670, 1.4264, 0.5546, 0.3608, 0.1457,\n",
      "         0.3956, 0.1085, 0.0000, 1.7490, 1.3998, 0.2017, 0.2017]])\n",
      "\n",
      "\n",
      "LINEAR:\n",
      "2.4335522651672363\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    #dat = generate_data(visualise=False)\n",
    "    x = dat[0]\n",
    "    y = model(x)\n",
    "    print('C' if y > 0 else 'D')\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"CONV:\")\n",
    "    \n",
    "    # visualize activations after convolution\n",
    "    for i, act in enumerate(activation['conv'][0]):\n",
    "        print(act)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"RELU:\")\n",
    "    print(activation[\"relu\"])\n",
    "    print(\"\\n\")\n",
    "    print(\"POOL:\")\n",
    "    print(activation[\"pool\"])\n",
    "    print(\"\\n\")\n",
    "    print(\"FLATTEN:\")\n",
    "    print(activation[\"flatten\"])\n",
    "    print(\"\\n\")\n",
    "    print(\"LINEAR:\")\n",
    "    print(y.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y      2.4335522651672363\n",
      "target 1.0\n",
      "loss   0.08408807218074799\n"
     ]
    }
   ],
   "source": [
    "# Loss\n",
    "X, Y = dat\n",
    "logits = model(X)  # feed-forward\n",
    "\n",
    "# not sure if I'm doing this right ...\n",
    "logits = logits.squeeze(-2)\n",
    "Y = Y.unsqueeze(0)\n",
    "\n",
    "J = loss(logits, Y)  # computes the loss\n",
    "\n",
    "print('y     ', logits.item())\n",
    "print('target', Y.item())\n",
    "print('loss  ', J.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Framework-less backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()  # cleans up previous gradients\n",
    "J.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache weights + biases BEFORE optimiser step\n",
    "w_old = {\n",
    "    'lin': model[4].weight.clone().detach(),\n",
    "    'lin_bias': model[4].bias.clone().detach(),\n",
    "    'conv': model[0].weight.clone().detach(),\n",
    "    'conv_bias': model[0].bias.clone().detach(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    # e^x => math.e ** 2\n",
    "    return 1 / (1 + math.e ** -x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L:  0.08408807218074799\n",
      "dL: -0.080649733543396\n",
      "\n",
      "GOAL\n",
      " 0.08408807218074799 \n",
      " -0.080649733543396\n"
     ]
    }
   ],
   "source": [
    "# BCEwithLogits Loss, formula from\n",
    "# https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/Loss.cpp\n",
    "\n",
    "y = logits\n",
    "\n",
    "max_val = max(0, -y)\n",
    "l = (1-Y) * y + max_val + math.log((math.e ** -max_val) + math.e ** (-y-max_val))\n",
    "\n",
    "# Derivative of BCEwithLogits Loss\n",
    "# grad_input = (input.sigmoid() - target).mul_(grad);\n",
    "dl = (sigmoid(y) - Y) * 1\n",
    "\n",
    "print(\"L: \", l.item())\n",
    "print(\"dL:\", dl.item())\n",
    "print('\\nGOAL\\n', J.item(), \"\\n\", backward[\"lin\"][\"input\"][0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dW\n",
      " tensor([[-0.0757, -0.0791, -0.0997, -0.0146, -0.1506, -0.1150, -0.0447, -0.0291,\n",
      "         -0.0118, -0.0319, -0.0088, -0.0000, -0.1411, -0.1129, -0.0163, -0.0163]],\n",
      "       grad_fn=<MulBackward0>)\n",
      " GOAL\n",
      " tensor([[-0.0757, -0.0791, -0.0997, -0.0146, -0.1506, -0.1150, -0.0447, -0.0291,\n",
      "         -0.0118, -0.0319, -0.0088,  0.0000, -0.1411, -0.1129, -0.0163, -0.0163]])\n",
      " DIFF 0.0\n",
      "\n",
      "\n",
      "dX\n",
      " tensor([[ 0.0715,  0.0778,  0.0247,  0.0359, -0.0194, -0.0776, -0.0050, -0.0287,\n",
      "          0.0086, -0.0294, -0.0087,  0.0332, -0.0269, -0.0869, -0.0305, -0.0378]],\n",
      "       grad_fn=<MulBackward0>)\n",
      " GOAL\n",
      " tensor([[ 0.0715,  0.0778,  0.0247,  0.0359, -0.0194, -0.0776, -0.0050, -0.0287,\n",
      "          0.0086, -0.0294, -0.0087,  0.0332, -0.0269, -0.0869, -0.0305, -0.0378]])\n",
      " DIFF 0.0\n",
      "\n",
      "\n",
      "dB\n",
      " tensor([-0.0806], grad_fn=<MulBackward0>)\n",
      " GOAL\n",
      " tensor([-0.0806])\n",
      " DIFF 0.0\n"
     ]
    }
   ],
   "source": [
    "# backward pass, linear layer\n",
    "dx = model[4].weight * dl\n",
    "dw = activation['flatten'] * dl\n",
    "db = dl\n",
    "\n",
    "print('\\ndW\\n',dw)\n",
    "print(' GOAL\\n', model[4].weight.grad)\n",
    "print(' DIFF', numpy.sum(a=(dw.detach().numpy() - model[4].weight.grad.detach().numpy())))\n",
    "\n",
    "print('\\n\\ndX\\n',dx)\n",
    "print(' GOAL\\n', backward[\"lin\"][\"input\"][1])\n",
    "print(' DIFF', numpy.sum(a=(dx.detach().numpy() - numpy.array(backward[\"lin\"][\"input\"][1]))))\n",
    "\n",
    "print('\\n\\ndB\\n',db)\n",
    "print(' GOAL\\n', model[4].bias.grad)\n",
    "print(' DIFF', numpy.sum(a=(db.detach().numpy() - model[4].bias.grad.detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0715,  0.0778],\n",
      "         [ 0.0247,  0.0359]],\n",
      "\n",
      "        [[-0.0194, -0.0776],\n",
      "         [-0.0050, -0.0287]],\n",
      "\n",
      "        [[ 0.0086, -0.0294],\n",
      "         [-0.0087,  0.0332]],\n",
      "\n",
      "        [[-0.0269, -0.0869],\n",
      "         [-0.0305, -0.0378]]], grad_fn=<ViewBackward>)\n",
      "\n",
      "GOAL\n",
      " (tensor([[[[ 0.0715,  0.0778],\n",
      "          [ 0.0247,  0.0359]],\n",
      "\n",
      "         [[-0.0194, -0.0776],\n",
      "          [-0.0050, -0.0287]],\n",
      "\n",
      "         [[ 0.0086, -0.0294],\n",
      "          [-0.0087,  0.0332]],\n",
      "\n",
      "         [[-0.0269, -0.0869],\n",
      "          [-0.0305, -0.0378]]]]),)\n"
     ]
    }
   ],
   "source": [
    "# backward pass, flatten\n",
    "out = dx.reshape((4,2,2))\n",
    "goal = backward['pool']['output']\n",
    "\n",
    "print(out)\n",
    "print('\\nGOAL\\n', goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GOAL\n",
      " (tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0715,  0.0778,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0247,  0.0000,  0.0000,  0.0359,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0194, -0.0776,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000, -0.0287,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.0050,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0086,  0.0000, -0.0294,  0.0000],\n",
      "          [ 0.0000, -0.0087,  0.0000,  0.0332,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0269, -0.0869,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0305, -0.0378,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]]),)\n"
     ]
    }
   ],
   "source": [
    "# backward pass, maxpool2d\n",
    "# not implemented here... but it's easy:\n",
    "# the gradient gets assigned to the item that was max() during forward pass\n",
    "\n",
    "print('\\nGOAL\\n', backward['pool']['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0715,  0.0778,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0247,  0.0000,  0.0000,  0.0359,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0194, -0.0776,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000, -0.0287,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0050,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0086,  0.0000, -0.0294,  0.0000],\n",
      "         [ 0.0000, -0.0087,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0269, -0.0869,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0305, -0.0378,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]])\n",
      "\n",
      "GOAL\n",
      " tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0715,  0.0778,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0247,  0.0000,  0.0000,  0.0359,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0194, -0.0776,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000, -0.0287,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0050,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0086,  0.0000, -0.0294,  0.0000],\n",
      "         [ 0.0000, -0.0087,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0269, -0.0869,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0305, -0.0378,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]])\n",
      "\n",
      "DIFF 0.0\n"
     ]
    }
   ],
   "source": [
    "# derivative of relu\n",
    "# see here: https://towardsdatascience.com/back-propagation-simplified-218430e21ad0\n",
    "\n",
    "# d = numpy.array(backward['pool']['input'][0][0][0], copy = True)\n",
    "# d[activation['relu'][0][0] < 0] = 0.\n",
    "\n",
    "relu_grad = backward['pool']['input'][0][0].clone().detach()\n",
    "\n",
    "for f in range(0,4):\n",
    "    for y in range(0,6):\n",
    "        for x in range(0,6):\n",
    "            if(activation['act'][0][f][y][x] <= 0):\n",
    "                relu_grad[f][y][x] = 0\n",
    "                \n",
    "print(relu_grad)\n",
    "print('\\nGOAL\\n', backward['relu']['input'][0][0])\n",
    "\n",
    "print('\\nDIFF', (backward['relu']['input'][0][0] - relu_grad).sum().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Make an optimiser step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache weights + biases AFTER optimiser step\n",
    "w_new = {\n",
    "    'lin': model[4].weight.clone().detach(),\n",
    "    'lin_bias': model[4].bias.clone().detach(),\n",
    "    'conv': model[0].weight.clone().detach(),\n",
    "    'conv_bias': model[0].bias.clone().detach(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8860, -0.9646, -0.3057, -0.4446,  0.2404,  0.9619,  0.0626,  0.3562,\n",
      "         -0.1067,  0.3641,  0.1073, -0.4122,  0.3337,  1.0777,  0.3787,  0.4688]])\n",
      "\n",
      "GOAL\n",
      " [-0.8859708  -0.9646351  -0.30574358 -0.44463044  0.24039814  0.9618884\n",
      "  0.06261699  0.35623348 -0.10668962  0.36407247  0.10729297 -0.41222888\n",
      "  0.33366507  1.0777308   0.3787301   0.46880627]\n",
      "\n",
      "DIFF: 0.0\n"
     ]
    }
   ],
   "source": [
    "# lin layer, weight update\n",
    "# https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n",
    "weight_update = w_old['lin'].clone()\n",
    "weight_update -= lr * dw.clone().detach()\n",
    "\n",
    "# goal\n",
    "goal = w_new['lin'][0].numpy()\n",
    "print(weight_update)\n",
    "print('\\nGOAL\\n', goal)\n",
    "print('\\nDIFF:', numpy.sum(a=(goal - weight_update[0].numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALC: 0.2839290499687195\n",
      "GOAL: 0.2839290499687195\n",
      "DIFF: 0.0\n"
     ]
    }
   ],
   "source": [
    "# lin layer, bias update\n",
    "new_bias = w_old['lin_bias'].clone() - db * lr\n",
    "\n",
    "print('CALC:', new_bias.item())\n",
    "print('GOAL:', model[4].bias.item())\n",
    "print('DIFF:', (model[4].bias.item()-new_bias).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### conv weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.17392953  0.14926335  0.07145941]\n",
      "  [ 0.02466618  0.          0.        ]\n",
      "  [ 0.0358605   0.02466618  0.02466618]]\n",
      "\n",
      " [[-0.09694266 -0.1019891  -0.0193759 ]\n",
      "  [ 0.         -0.00504644  0.        ]\n",
      "  [ 0.          0.         -0.00504644]]\n",
      "\n",
      " [[-0.02940678  0.00860544  0.00860544]\n",
      "  [-0.00865244  0.          0.        ]\n",
      "  [-0.00865244  0.          0.        ]]\n",
      "\n",
      " [[-0.11380821 -0.11380821 -0.02689862]\n",
      "  [ 0.          0.          0.        ]\n",
      "  [ 0.          0.          0.        ]]]\n",
      "\n",
      "GOAL\n",
      " tensor([[[ 0.1739,  0.1493,  0.0715],\n",
      "         [ 0.0247,  0.0000,  0.0000],\n",
      "         [ 0.0359,  0.0247,  0.0247]],\n",
      "\n",
      "        [[-0.0969, -0.1020, -0.0194],\n",
      "         [ 0.0000, -0.0050,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0050]],\n",
      "\n",
      "        [[-0.0294,  0.0086,  0.0086],\n",
      "         [-0.0087,  0.0000,  0.0000],\n",
      "         [-0.0087,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.1138, -0.1138, -0.0269],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]]])\n",
      "DIFF 0.0\n"
     ]
    }
   ],
   "source": [
    "# backward pass, conv\n",
    "\n",
    "# only doing it here, after optimiser.step() so that model[0].weight.grad has a gradient for comparison\n",
    "\n",
    "# incoming gradient\n",
    "g = backward['relu']['input'][0][0]\n",
    "\n",
    "# gradient var\n",
    "conv_grad = torch.zeros((4,3,3))\n",
    "\n",
    "# filters\n",
    "for f in range(0,4):\n",
    "    for fy in range(0,3):\n",
    "        for fx in range(0,3):\n",
    "            # slide gradient over input X to get dF\n",
    "            for y in range(0,6):\n",
    "                for x in range(0,6):\n",
    "                    conv_grad[f][fy][fx] += g[f][y][x] * dat[0][0][0][y+fy][x+fx]\n",
    "\n",
    "goal = model[0].weight.grad.clone().squeeze(1)\n",
    "\n",
    "print(conv_grad.numpy())\n",
    "print('\\nGOAL\\n', goal)\n",
    "print('DIFF', (conv_grad - goal).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4864,  0.4374, -0.0428],\n",
      "         [ 0.2965, -0.2957,  0.8122],\n",
      "         [ 0.1239, -0.4730,  0.8683]],\n",
      "\n",
      "        [[ 0.4998,  0.5660,  0.4407],\n",
      "         [-0.3588, -0.4119, -0.3926],\n",
      "         [-0.4346, -0.3897,  0.0398]],\n",
      "\n",
      "        [[ 0.4341, -0.3330,  0.0831],\n",
      "         [-0.1994, -0.1118, -0.1598],\n",
      "         [-0.0877, -0.2849,  0.0504]],\n",
      "\n",
      "        [[ 0.6420,  0.5564,  0.3492],\n",
      "         [-0.6512, -0.4949, -0.0681],\n",
      "         [-0.2420, -0.4338, -0.4763]]])\n",
      "\n",
      "GOAL: tensor([[[ 0.4864,  0.4374, -0.0428],\n",
      "         [ 0.2965, -0.2957,  0.8122],\n",
      "         [ 0.1239, -0.4730,  0.8683]],\n",
      "\n",
      "        [[ 0.4998,  0.5660,  0.4407],\n",
      "         [-0.3588, -0.4119, -0.3926],\n",
      "         [-0.4346, -0.3897,  0.0398]],\n",
      "\n",
      "        [[ 0.4341, -0.3330,  0.0831],\n",
      "         [-0.1994, -0.1118, -0.1598],\n",
      "         [-0.0877, -0.2849,  0.0504]],\n",
      "\n",
      "        [[ 0.6420,  0.5564,  0.3492],\n",
      "         [-0.6512, -0.4949, -0.0681],\n",
      "         [-0.2420, -0.4338, -0.4763]]])\n",
      "DIFF: 0.0\n"
     ]
    }
   ],
   "source": [
    "new_weights = w_old['conv'].clone().squeeze(1)\n",
    "new_weights -= lr * conv_grad\n",
    "goal = w_new['conv'].clone().squeeze(1)\n",
    "\n",
    "print(new_weights)\n",
    "print('\\nGOAL:', goal)\n",
    "print('DIFF:', (goal - new_weights).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0570,  0.3609, -0.0384,  0.2019])\n",
      "GOAL: tensor([ 0.0570,  0.3609, -0.0384,  0.2019])\n",
      "DIFF: 0.0\n"
     ]
    }
   ],
   "source": [
    "# conv layer, bias update\n",
    "# -> sum of filter gradient is dB\n",
    "# https://stackoverflow.com/questions/3775032/how-to-update-the-bias-in-neural-network-backpropagation\n",
    "# https://datascience.stackexchange.com/questions/25081/how-to-update-bias-in-cnn\n",
    "\n",
    "# biases before weight update\n",
    "biases = w_old['conv_bias'].clone()\n",
    "\n",
    "for i in range(len(biases)):\n",
    "    biases[i] -= g[i].sum() * lr\n",
    "\n",
    "goal = model[0].bias.clone().detach()\n",
    "\n",
    "print(biases)\n",
    "print('GOAL:', goal)\n",
    "print('DIFF:', (goal - biases).sum().item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
