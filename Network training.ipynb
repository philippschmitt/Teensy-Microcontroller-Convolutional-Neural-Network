{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini neural net training\n",
    "Authors: Alfredo Canziani, Philipp Schmitt  \n",
    "Date: Fri 14 Feb 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from IPython import display\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from matplotlib.pyplot import imshow, axis, figure, subplot, pause\n",
    "import numpy\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x111316290>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# static random seed\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input definition\n",
    "class input_settings:\n",
    "    batch_size = 1\n",
    "    channels = 1\n",
    "    height = 8\n",
    "    width = 8\n",
    "\n",
    "dummy_X = torch.randn(  # batch of inputs x\n",
    "    input_settings.batch_size,\n",
    "    input_settings.channels,\n",
    "    input_settings.height,\n",
    "    input_settings.width,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network architecture\n",
    "class model_settings:\n",
    "    conv_channels = 4\n",
    "    kernel = 3\n",
    "    pooling_kernel = 3\n",
    "    flattened = 16\n",
    "    output_size = 1\n",
    "    \n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(\n",
    "        in_channels=input_settings.channels,\n",
    "        out_channels=model_settings.conv_channels,\n",
    "        kernel_size=model_settings.kernel,\n",
    "        bias=True,\n",
    "    ),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(\n",
    "        kernel_size=model_settings.pooling_kernel,\n",
    "        stride=model_settings.pooling_kernel,\n",
    "    ),  # we have 4 x 2x2\n",
    "    nn.Flatten(),  # gives 16\n",
    "    nn.Linear(\n",
    "        in_features=model_settings.flattened,\n",
    "        out_features=model_settings.output_size,\n",
    "        bias=True,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "with torch.no_grad():\n",
    "    print(model(dummy_X).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Flatten()\n",
      "  (4): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weights and biases\n",
    "def get_weights():\n",
    "    print(\n",
    "        model[0],\n",
    "        model[0].weight,\n",
    "        model[0].bias,\n",
    "        sep='\\n',\n",
    "    )\n",
    "    print(\n",
    "        model[4],\n",
    "        model[4].weight,\n",
    "        model[4].bias,\n",
    "        sep='\\n',\n",
    "    )\n",
    "    # Maybe add some saving routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = ImageFont.truetype('Verdana', 8)  # let's keep it to Verdana 8pt\n",
    "data_set_settings = dict(\n",
    "    D=dict(\n",
    "        x_min = -1,\n",
    "        x_max = 2,\n",
    "        y_min = -3,\n",
    "        y_max = -1,\n",
    "    ),\n",
    "    C=dict(\n",
    "        x_min = 0,\n",
    "        x_max = 3,\n",
    "        y_min = -4,\n",
    "        y_max = -2,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(visualise=False, target=None):\n",
    "    image = Image.new('L', (input_settings.height, input_settings.width))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.fontmode = '1'\n",
    "    if not target:\n",
    "        character = random.choice(('C', 'D'))\n",
    "    else:\n",
    "        character = target\n",
    "\n",
    "    x = random.randint(\n",
    "        data_set_settings[character]['x_min'],\n",
    "        data_set_settings[character]['x_max'],\n",
    "    )\n",
    "    y = random.randint(\n",
    "        data_set_settings[character]['y_min'],\n",
    "        data_set_settings[character]['y_max'],\n",
    "    )\n",
    "\n",
    "    draw.text((x, y), character, (255,), font=font)\n",
    "    data = numpy.array(image, dtype=numpy.float32) / 255\n",
    "    \n",
    "    if visualise:\n",
    "        figure(facecolor='k')\n",
    "        imshow(data, cmap='gray')\n",
    "        axis('off');\n",
    "    \n",
    "    return torch.tensor(data).unsqueeze_(0), torch.tensor(character=='C', dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.]]]), tensor(1.))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAzRJREFUeJzt3UFuwzAMAEEqyP+/rD4hBtJaxXrmbMA8aMEj18zsAZJepwcA/o7AIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIe58egOfZe58eIWGt9fEbGxzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hThcxM/eeE7pycoffYYNDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQ5jbZP+ZeGN+ywSFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMLWzOzTQ3De3vc9g7XWbf96OhscwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYe/TA/A8d55JKrtyAsoGhzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIWzNjENREGWDQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIewHRqQT+5eAyc8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_data(visualise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a C, D batch\n",
    "def get_batch(visualise=False):\n",
    "    Cx, Cy = generate_data(target='C', visualise=visualise)\n",
    "    Dx, Dy = generate_data(target='D', visualise=visualise)\n",
    "    x = torch.stack((Cx, Dx))\n",
    "    y = torch.stack((Cy, Dy))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up network training\n",
    "nb_epochs = 10_000\n",
    "optimiser = optim.SGD(params=model.parameters(), lr=1e-3)\n",
    "loss = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAzlJREFUeJzt3UFqBDEQBMGW2f9/WT4bfDG7loYk4gPTMCQ61pqZPUDS1+0DgP8jcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFD2Ov2ATzD3vv2CQlrrdsn/OAFhzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIcw22YOd3At72qYWn+EFhzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jpoj84OSU0Y06I93nBIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwtbM7NtH8Lu9z/2atdaxb3GOFxzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAoew1+0DeIaTO2hlT9t484JDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhbM2MzRqI8oJDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYd/ZsBP7aY0SUgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inference: C vs. D detector\n",
    "with torch.no_grad():\n",
    "    print('C' if model(generate_data(visualise=True)[0].unsqueeze_(0)) > 0 else 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEYAAABGCAIAAAD+THXTAAAATUlEQVR4nO3TMQoAIQwEQL3//zk2coiWUU6OmSpNFrbYUgAA+Juaj4iInlU3pOU9yf+3z3R/KFvpQiotxv1csiUAAAAAAAAAAAAA4JgGt1sJCjqkBk8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=70x70 at 0x121515AC8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from numpy import interp\n",
    "from math import cos, sin, radians, pi\n",
    "\n",
    "\n",
    "def draw_weight(value, size=20):\n",
    "    rad = interp(value,[-.75,.75],[pi,0])\n",
    "    im = Image.new('RGB', (size, size), (0, 0, 0))\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    x, y, r = (\n",
    "        size/2 + size/3 * cos(rad), \n",
    "        size/2 - size/3 * sin(rad),\n",
    "        4)\n",
    "    draw.ellipse((x-r/2, y-r/2, x+r/2, y+r/2), fill=(255, 255, 255), outline=None)\n",
    "\n",
    "    return im\n",
    "\n",
    "draw_weight(-.25, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAAeCAIAAABc99v3AAABNElEQVR4nO3aMY7DMAwEQCu4/3/ZVwVwcXYl0tLeTJWKlAVx4Sg5jjLneSquuOKKK95W/FNXHYBOAh0gxM/bCziOy9eQMcbKNXuKt3XZbtvr2jUvu9qUx8k45NUtVhvSpzf082vCuh67/Pl5tZo9xdu6bLftde2al33tVTFfUx4n45BXt1hwSG8D/a1TDv+B+aKCO3SAEO8H+vVuaNY9VEXNnuJtXbbb9rp2zcuuNuVxMg55dYsFh/T2R9ExRtsvRdV7sVfxti7bbXtdu/4cL52vKQUzDnl1i9WG9OlfLgFvK7As88V071+5ADCFQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBC/cK7SKe8H8nUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=496x30 at 0x121515390>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw weights\n",
    "\n",
    "def draw_weights(layer, size=20):\n",
    "    weights = layer.weight.data.clone().numpy()\n",
    "\n",
    "    n_weights = len(weights[0])\n",
    "    im = Image.new('RGB', ((size+1)*n_weights, size), (255, 255, 255))\n",
    "\n",
    "    for i in range(n_weights):\n",
    "        weight = draw_weight(weights[0][i], size=size)\n",
    "        im.paste(weight,((size+1)*i,0))\n",
    "\n",
    "    return im\n",
    "\n",
    "draw_weights(model[4], size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAD8AAAA/CAIAAADYPYeIAAAA9UlEQVR4nO2awQoDIQxEtfT/f9keetkVNJpEx8i844KTh0QxpSkZKKVgl3/Ha+Scp6IVq2YTPoMRaWardKsUCYL94Vxt/+y58Q7WrfJNkIHfOVd3zuHQHgftcdAeB+1x0B5HbPtsfOgFBv5CFqbyPcO1ml7fbxuuR3L+VN8DnNrOFgSw79CzP3+4Fk6tvaRLQuvoy78EnkBrC+7t+/OhPQ7a46A9DtrjoD0OTuW45UteyF6TuJhT931r/lWUTOZJXMx52XsV3kbsO8ff3msSH8l5ndrO/KsubEHMqe+cVX8KWAP7HgftcdAeB+1x0B4H7XHEnsp/C5qQT/FM8BQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=63x63 at 0x1218654A8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw a filter\n",
    "def draw_filter(filter):\n",
    "    matrix = Image.new('RGB', (63, 63), (255, 255, 255))\n",
    "    data = filter.view(3, 3).numpy()\n",
    "    # go over filter\n",
    "    # rows\n",
    "    for x in range(0, data.shape[0]):\n",
    "        # cols\n",
    "        for y in range(0, data.shape[1]):\n",
    "            vis = draw_weight(data[y,x])\n",
    "            matrix.paste(vis,(x*21,y*21))\n",
    "    return matrix\n",
    "\n",
    "filters = model[0].weight.data\n",
    "draw_filter(filters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARoAAAA/CAIAAACwx5DcAAACiElEQVR4nO3czU7DMBBF4Rrx/q9cFpUQrajjes74JznfikU8jp3eQiIy5RZwv99LKROH1w+Ye24u7d3w+gFbL+275aDHDx/N1DeKraDxBly1iR+Mw6m/GsffGr5XgqPYCu0TPew4HCkOnsOAq4ZM0bfklqkP4nRuwWszdzhSfNjX1jpSl3zpOEmsgzj9/Rux/U/VvlFsBY034KpN/GC0TH38KCKehz4DNquUErmvnTscKY6fw5irFhzeveTD44/jdG7xazNxOFL8gr/885bsvZOEMU4SxjhJGOMkYYyThDFOEsY4SRjjJGGMk4QxThLGOEkY4yRhykVeGpMGCP1r7fROF/UDtm7iUT/Apb0rvnTrlbN2UJl7VnmzByt3D1/zKmeor7R277ROBxW2RUl3PxnkHPJ6FczqXZG6oviej+wts8GjiBXag6xwDldDNS2KF2m3QZykXdTidNYOKnPPKm/2YOXu4Wte5QyHKz14FLFCB5WMFiUdPTfAc8j7zM3qXZGxImTPB/eW2aP1ygrfeSucw9Xs0lzpl/dOEsY4SRjjJGGMk4QxThLGOEkY4yRhjJOEMU4SxjhJGOMkYYyThLH1ioSx9crb4i4taXj9gK2XlvKCBvWGCf6a00U6hHQsE9yZZRvLDJj09d4p3qcCbLeC1EEKsr1fUst2LBPc6tUaywR3+NNJn+Jkg5F/JW2Lu51t/A77ZE/C8HGiGnHgDT0u0iGkY5ngzizbWGbMpE+PIqg+FbMapCQVzOj9kle2rxq7LqpUsDLVvKX94Ncneyf+2o5I2hZ3O9vgHfbeScIYJwljnCSMcZIwxknCGCcJY5wkjHGSMMZJwhgnCWOcJIxxkjC2XpEwP13zN1vs/so5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=282x63 at 0x1223CDB38>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw all filters\n",
    "def draw_filters(layer):\n",
    "    matrix = Image.new('RGB', (282, 63), (255, 255, 255))\n",
    "    filters = layer.weight.data.clone()\n",
    "    for i, filter in enumerate(filters):\n",
    "        vis = draw_filter(filter)\n",
    "        matrix.paste(vis, (i*(63+10),0))\n",
    "    return matrix\n",
    "\n",
    "\n",
    "draw_filters(model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARoAAAA/CAIAAACwx5DcAAACiElEQVR4nO3czU7DMBBF4Rrx/q9cFpUQrajjes74JznfikU8jp3eQiIy5RZwv99LKROH1w+Ye24u7d3w+gFbL+275aDHDx/N1DeKraDxBly1iR+Mw6m/GsffGr5XgqPYCu0TPew4HCkOnsOAq4ZM0bfklqkP4nRuwWszdzhSfNjX1jpSl3zpOEmsgzj9/Rux/U/VvlFsBY034KpN/GC0TH38KCKehz4DNquUErmvnTscKY6fw5irFhzeveTD44/jdG7xazNxOFL8gr/885bsvZOEMU4SxjhJGOMkYYyThDFOEsY4SRjjJGGMk4QxThLGOEkY4yRhykVeGpMGCP1r7fROF/UDtm7iUT/Apb0rvnTrlbN2UJl7VnmzByt3D1/zKmeor7R277ROBxW2RUl3PxnkHPJ6FczqXZG6oviej+wts8GjiBXag6xwDldDNS2KF2m3QZykXdTidNYOKnPPKm/2YOXu4Wte5QyHKz14FLFCB5WMFiUdPTfAc8j7zM3qXZGxImTPB/eW2aP1ygrfeSucw9Xs0lzpl/dOEsY4SRjjJGGMk4QxThLGOEkY4yRhjJOEMU4SxjhJGOMkYYyThLH1ioSx9crb4i4taXj9gK2XlvKCBvWGCf6a00U6hHQsE9yZZRvLDJj09d4p3qcCbLeC1EEKsr1fUst2LBPc6tUaywR3+NNJn+Jkg5F/JW2Lu51t/A77ZE/C8HGiGnHgDT0u0iGkY5ngzizbWGbMpE+PIqg+FbMapCQVzOj9kle2rxq7LqpUsDLVvKX94Ncneyf+2o5I2hZ3O9vgHfbeScIYJwljnCSMcZIwxknCGCcJY5wkjHGSMMZJwhgnCWOcJIxxkjC2XpEwP13zN1vs/so5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=282x63 at 0x121D910B8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_filters(model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model[0].weight.data.fill_(0)\n",
    "#model[4].weight.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAABkCAIAAAA+Dt3DAAAD0UlEQVR4nO3dwW7dOAwF0LxB//+XPYtgMinQpNcSZdHOOasCDWlL9rutHYR5HcfxdqHX6zVcexzH3vLvv8DSvmpuaYvKh2vH/Lr4eH/1sQWn9nGsqrYD17vgqm28Mbrdk//sPoHffA7LPDjHqmo75Ad6d8fykuaF53DBVSs5xNiSL7snc73C4tkmL//e8pLmDT8Aqz1pycICiPQKi8/PZvlz2lhVbQeud8FV23hjNLwn273gnP+0X3ncs4eYeWW1t7ykefk5XHPVJsuHl9wkIz60C4tnm7/zNpaXNO/2AbjAY5bc6zEEaEtYABFhAUSEBRARFkBEWAARYQFEhAUQERZARFgAEWEBRIQFEHndfSAHcI2rf+r0wfNRLe2r5pa2qHy4dkyvH1F/6tzdvWe17uiTnYfLe17lFVqttNE7iz5zd2sH2w5PIS45h3UzIHfNBF26ovk9v9dE4lMahUUTHa5Qh3P4aaoGec83aUtYAJFGYfHUubt7z2rd0Sc7D5f3vMordFtprxecHeburhhsOzCptfAc1t1nu2aCrlhRyZ7fcSJxrldYNNHhCnU4h5/meR/vWo0eQ4DOhAUQERZARFgAEWEBRIQFEBEWQERYABFhAUSEBRARFkBEWAARA3uBiIG9J8q//wJL+6q5pS0qH64d84QfUa+aIFA+xqLVtNV1BpZZuDNtxxHf6KChze8s5qebFg7pLelT0rB2YvDStgPLLNzqbuOIJ3e4+QjPnWHRfGt2WbQtdnu1x++w74YAkduHRdVQ0/LhqN2mrS4ysMzCnWk7jvhGB83tfMFZNd1011jdRQ1XTAxe13asW+26qlpNdq4a+TtWeIHN3w3pvDUbLdoWu73as3f49o8hwDWEBRARFkBEWAARYQFEhAUQERZARFgAEWEBRIQFEBEWQERYABEDe4GI/1kAEWEBRIQFEBEWQERYABFhAUSEBRARFkBEWAARYQFEhAUQERZARFgAEWEBRIQFEBEWQERYAJFf3//1zK+QP45DuXLlNyr//gv+EhaLfJzW2bUNF5aUVzXZtfyZVoWHnrfl5Dde9w7lb2cfQ47/jB3so8kf/7yusKS8qsmu5c+0Kjz05z5j99KWk9943TuUvzsRFivuGH4m99IdecEJRDaExedHplOPT8OFJeVVTXYtf6ZV4aHnbTn5jde9Q/m7Ey84X6//f8lI4c16TWFJeVWTXcufaVWbEZP30paT33jdO5S/nf1uyPZ/VXgM99LteGcBRIQFEBEWQERYABFhAUSEBRARFkBEWAARYQFEhAUQERZARFgAkX8BXj0M4L2XhdsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=356x100 at 0x121515358>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw all the weights in the net\n",
    "def draw_net():\n",
    "    im = Image.new('RGB', (356, 100), (255, 255, 255))\n",
    "    im.paste(draw_filters(model[0]), (37,0))\n",
    "    im.paste(draw_weights(model[4]), (10,80))\n",
    "\n",
    "    return im\n",
    "\n",
    "draw_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABrCAYAAABXGGiIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAArZJREFUeJzt2zFOamEUhdGDsdBGYkepWEmHzsZRUFI5DGNLwhTsnYIUxobGxAHIBO7rrPW+nGd23lo9+yd/4OM2TIZhKAByHP32GwDgZ4QbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhjjtGHx8fW/+O+f7+3jlfVVUnJyet+/f395Mxr9tut613e3SU/1t+d3c36m43m03r3T49PXXOV1XVzc1N6/56vR51t1VVDw8Prfd7enraOV9VVZ+fn637q9XqW/eb/y0F+M8IN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMcdo4fDoWP2y+XlZet+VdXZ2Vn7GWN8fHy07r+8vLTuV1UtFov2M8Z4e3tr3b+6umrdr+r/fPyN5+fn1v3pdNq6X1W1XC7bz/gOT9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEEa4AcIIN0AY4QYIc9wx+vr62jH75fz8vHW/quri4qL9jDH2+33r/jAMrftVVfP5vP2MMWazWet+9/eiqur6+rr9jLFub29b9//F/e52u/YzvsMTN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEGYyDMNvvwcAfsATN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEOYPpUVDXdix804AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize weights\n",
    "def visualize_filters(layer):\n",
    "    filters = layer.weight.data.clone()\n",
    "    # visualize\n",
    "    for i in range(0, len(filters)):\n",
    "        data = filters[i].view(3, 3)\n",
    "        subplot(1, 4, i+1)\n",
    "        imshow(data, cmap='gray', vmin=-1, vmax=1)\n",
    "        axis('off');\n",
    "        \n",
    "visualize_filters(model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH]: 9900, [LOSS]: 0.522867, [ACCURACY]: 1.000\n",
      "tensor([[[[ 1.4405e-01, -4.0901e-04,  4.3509e-01],\n",
      "          [-5.5977e-02, -3.8172e-02,  6.7312e-01],\n",
      "          [-2.7486e-01, -2.3733e-01,  4.3573e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.9890e-01,  5.5453e-01,  7.6617e-01],\n",
      "          [-2.4859e-01, -3.3467e-01, -2.8994e-01],\n",
      "          [-3.9219e-01, -3.1880e-01,  1.1148e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.4940e-01, -3.5500e-01,  3.9897e-02],\n",
      "          [-5.5662e-02, -2.9234e-01, -1.5600e-01],\n",
      "          [ 4.5096e-02, -2.5738e-01, -1.3497e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3571e-01,  4.2108e-01,  3.4907e-01],\n",
      "          [-3.3318e-01, -2.4772e-01,  4.0894e-02],\n",
      "          [ 2.9095e-02, -2.5912e-01, -2.1687e-01]]]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(nb_epochs):\n",
    "    # Training steps\n",
    "    X, Y = get_batch()\n",
    "    logits = model(X).squeeze(1)  # feed-forward\n",
    "    J = loss(logits, Y)  # computes the loss\n",
    "    model.zero_grad()  # cleans up previous gradients\n",
    "    J.backward()\n",
    "    optimiser.step()\n",
    "    \n",
    "    # Accuracy computation and display\n",
    "    score, predicted = torch.max(logits, 0)\n",
    "    acc = (Y == (logits > 0)).sum().float() / len(Y)\n",
    "\n",
    "    if(epoch % 100 == 0):\n",
    "        display.clear_output(wait=True)\n",
    "        print(\"[EPOCH]: %i, [LOSS]: %.6f, [ACCURACY]: %.3f\" % (epoch, J.item(), acc))\n",
    "        \n",
    "        print(model[0].weight.data)\n",
    "        \n",
    "        figure(figsize=(10, 20))\n",
    "        #visualize_filters(model[0])\n",
    "        im = draw_net()\n",
    "        imshow(numpy.asarray(im), aspect='equal', interpolation='nearest')\n",
    "        \n",
    "        # im.save('%s.png' % epoch)\n",
    "        \n",
    "        #draw_filters(model[0]).save('%i.png' % epoch)\n",
    "        axis('off');\n",
    "        pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x10f52a4e0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# register hook to get activation after conv layer out\n",
    "\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "model[0].register_forward_hook(get_activation('act'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABrCAYAAABXGGiIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAABGtJREFUeJzt3LFLVX0cx/Ffj08SVEtSEGE3EKmI21Cr0BRdBEGcGySItv4AJyP6R9qbXAqCJiudCockoimiRSWC7hS3qWfuc+CU34fXa/7cc65HeXMWf0cmk0kDoI5//vYXACAj3ADFCDdAMcINUIxwAxQj3ADFCDdAMcINUIxwAxTzbx8X3d3djf4dc3d3N7r+YDCI9ufOnYv2rbW2tbUVfyaxtLR0pMvnVlZWome7srISXf/27dvR/k/Y29uL9jMzM52e7a1bt6Jnm/5d7e/vR/vl5eVo31pr4/E42g+Hw2i/sLDQ6dm21tqdO3ei53v16tXo+pcuXYr2o9Eo2rfW2sHBQbRPOzIajX7r+XrjBihGuAGKEW6AYoQboBjhBihGuAGKEW6AYoQboBjhBihGuAGKEW6AYno5q+TDhw/RfnNzM9pPTU1F+7dv30b7wyw9S+TLly/RPj0XZGNjI9r/Caurq50+9/3792ifPtu1tbVo/+zZs2jfxefPn6P9wsJC53sdP3482k8m0dEmsfX19V6v38Xvnp/ijRugGOEGKEa4AYoRboBihBugGOEGKEa4AYoRboBihBugGOEGKEa4AYrp5aySwWAQ7c+ePRvtt7e3o/3c3Fy0P8xmZ2ejfXr+xoMHD6L9tWvXov1h9v79+2j/6NGjaP/8+fNo/39z8uTJaP/x48do/+3bt2hfmTdugGKEG6AY4QYoRrgBihFugGKEG6AY4QYoRrgBihFugGKEG6AY4QYoppezSobDYbQfj8fR/uXLl71ev7XWXr9+He3Pnz8f36OL6enpaD81NRXtNzc3o/2nT5+ifWv5mRKXL1+O9qurq9H+l1OnTkX7N2/eRPv0LJRjx45F+9byn+HChQvxPbpKzwx68eJFtH/y5Em0v3LlSrRvLT8rqK/n640boBjhBihGuAGKEW6AYoQboBjhBihGuAGKEW6AYoQboBjhBihGuAGKEW6AYno5ZCp18eLFaH/9+vVov7e3F+1ba+3Hjx/R/ujRo/E9ujhx4kS0//r1a7RfXFyM9hsbG9G+tdbm5+ejfXpwUlej0SjaP378ONrfv38/2j99+jTad3H69One7/FL+nu8ceNGtD9z5ky0f/XqVbRvrbWdnZ1onx6o9ru8cQMUI9wAxQg3QDHCDVCMcAMUI9wAxQg3QDHCDVCMcAMUI9wAxQg3QDG9nFXy7t27Pi77n5mZmV6v31prg8Gg93t0MTc31+s+9fDhw16v31q3s2a6SM/tuHnzZrRP/6bu3bsX7VtrbTweR/vhcBjfo6v0/J/07Ji7d+9G+y4ODg6i/dbWVi/fwxs3QDHCDVCMcAMUI9wAxQg3QDHCDVCMcAMUI9wAxQg3QDHCDVCMcAMUc2Qymfzt7wBAwBs3QDHCDVCMcAMUI9wAxQg3QDHCDVCMcAMUI9wAxQg3QDHCDVCMcAMUI9wAxQg3QDHCDVCMcAMUI9wAxQg3QDHCDVCMcAMUI9wAxQg3QDHCDVCMcAMU8xPMWrmPc9TyzgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inference: C vs. D detector\n",
    "with torch.no_grad():\n",
    "    print('C' if model(generate_data(visualise=False)[0].unsqueeze_(0)) > 0 else 'D')\n",
    "    #print(activation['act'])\n",
    "    \n",
    "    # visualize activations after convolution\n",
    "    for i, act in enumerate(activation['act'][0]):\n",
    "        data = act.view(6,6)\n",
    "        subplot(1, 4, i+1)\n",
    "        imshow(data, cmap='gray', vmin=-1, vmax=1)\n",
    "        axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
