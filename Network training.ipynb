{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini neural net training\n",
    "Authors: Alfredo Canziani, Philipp Schmitt  \n",
    "Date: 15 Apr, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from IPython import display\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from matplotlib.pyplot import imshow, axis, figure, subplot, pause\n",
    "import numpy\n",
    "import random\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fcdd7348f10>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# static random seed\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input definition\n",
    "class input_settings:\n",
    "    batch_size = 1\n",
    "    channels = 1\n",
    "    height = 8\n",
    "    width = 8\n",
    "\n",
    "dummy_X = torch.randn(  # batch of inputs x\n",
    "    input_settings.batch_size,\n",
    "    input_settings.channels,\n",
    "    input_settings.height,\n",
    "    input_settings.width,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network architecture\n",
    "class model_settings:\n",
    "    conv_channels = 4\n",
    "    kernel = 3\n",
    "    pooling_kernel = 3\n",
    "    flattened = 16\n",
    "    output_size = 1\n",
    "    \n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(\n",
    "        in_channels=input_settings.channels,\n",
    "        out_channels=model_settings.conv_channels,\n",
    "        kernel_size=model_settings.kernel,\n",
    "        bias=True,\n",
    "    ),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(\n",
    "        kernel_size=model_settings.pooling_kernel,\n",
    "        stride=model_settings.pooling_kernel,\n",
    "    ),  # we have 4 x 2x2\n",
    "    nn.Flatten(),  # gives 16\n",
    "    nn.Linear(\n",
    "        in_features=model_settings.flattened,\n",
    "        out_features=model_settings.output_size,\n",
    "        bias=True,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "with torch.no_grad():\n",
    "    print(model(dummy_X).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Flatten()\n",
      "  (4): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weights and biases\n",
    "def get_weights():\n",
    "    print(\n",
    "        model[0],\n",
    "        model[0].weight,\n",
    "        model[0].bias,\n",
    "        sep='\\n',\n",
    "    )\n",
    "    print(\n",
    "        model[4],\n",
    "        model[4].weight,\n",
    "        model[4].bias,\n",
    "        sep='\\n',\n",
    "    )\n",
    "    # Maybe add some saving routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letter samples\n",
    "samples = [\n",
    "    [\n",
    "        [0,1,1,1],\n",
    "        [1,0,0,0],\n",
    "        [1,0,0,0],\n",
    "        [1,0,0,0],\n",
    "        [1,0,0,0],\n",
    "        [0,1,1,1]\n",
    "    ],\n",
    "    [\n",
    "        [1,1,1],\n",
    "        [1,0,0],\n",
    "        [1,0,0],\n",
    "        [1,1,1]\n",
    "    ],\n",
    "    [\n",
    "        [1,1,1,0],\n",
    "        [1,0,0,1],\n",
    "        [1,0,0,1],\n",
    "        [1,0,0,1],\n",
    "        [1,0,0,1],\n",
    "        [1,1,1,0]\n",
    "    ],\n",
    "    [\n",
    "        [1,1,0],\n",
    "        [1,0,1],\n",
    "        [1,0,1],\n",
    "        [1,1,0]\n",
    "    ]\n",
    "]\n",
    "\n",
    "sample_meta = [\n",
    "    [6,4,'C'],\n",
    "\t[4,3,'C'],\n",
    "\t[6,4,'D'],\n",
    "\t[4,3,'D']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0., 0., 0., 1., 1., 1., 0., 0.],\n",
       "           [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 1., 1., 1., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.]]]]), tensor(1.))"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAyFJREFUeJzt3cEJAzEMAEErpP+WnQZyj3Akhs1MBQKz6GPQrLX2ApIepwcAvkfgECZwCBM4hAkcwgQOYQKHMIFDmMAh7Hl6AK7t7ZPhXTNzeoSjbHAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziEOV30gV+fEvr3szvcZ4NDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAibtdY+PQTv7e1p7pqZ0yMcZYNDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhzOkiCLPBIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYS/Krw33u7HZCQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# updated gen. function to match teensy implementation\n",
    "def generate_data(visualise=False, target=None):\n",
    "    data = numpy.zeros(shape=(8,8), dtype=numpy.float32)\n",
    "    \n",
    "    sample = random.randint(0,len(samples)-1)\n",
    "    character = sample_meta[sample][2];\n",
    "    \n",
    "    x = random.randint(\n",
    "        0,\n",
    "        input_settings.width-sample_meta[sample][1]\n",
    "    )\n",
    "    y = random.randint(\n",
    "        0,\n",
    "        input_settings.height-sample_meta[sample][0]\n",
    "    )\n",
    "    \n",
    "    data[y:y+sample_meta[sample][0],x:x+sample_meta[sample][1]] = samples[sample]\n",
    "    \n",
    "    if visualise:\n",
    "        figure(facecolor='k')\n",
    "        imshow(data, cmap='gray')\n",
    "        axis('off');\n",
    "        \n",
    "    return torch.tensor(data).unsqueeze_(0).unsqueeze_(0), torch.tensor(character=='C', dtype=torch.float)\n",
    "        \n",
    "generate_data(visualise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEYAAABGCAIAAAD+THXTAAAATUlEQVR4nO3TMQoAIQwEQL3//zk2coiWUU6OmSpNFrbYUgAA+Juaj4iInlU3pOU9yf+3z3R/KFvpQiotxv1csiUAAAAAAAAAAAAA4JgGt1sJCjqkBk8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=70x70 at 0x7FCDDA4E28D0>"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from numpy import interp\n",
    "from math import cos, sin, radians, pi\n",
    "\n",
    "\n",
    "def draw_weight(value, size=20):\n",
    "    rad = interp(value,[-.75,.75],[pi,0])\n",
    "    im = Image.new('RGB', (size, size), (0, 0, 0))\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    x, y, r = (\n",
    "        size/2 + size/3 * cos(rad), \n",
    "        size/2 - size/3 * sin(rad),\n",
    "        4)\n",
    "    draw.ellipse((x-r/2, y-r/2, x+r/2, y+r/2), fill=(255, 255, 255), outline=None)\n",
    "\n",
    "    return im\n",
    "\n",
    "draw_weight(-.25, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAAeCAIAAABc99v3AAABNElEQVR4nO3aMY7DMAwEQCu4/3/ZVwVwcXYl0tLeTJWKlAVx4Sg5jjLneSquuOKKK95W/FNXHYBOAh0gxM/bCziOy9eQMcbKNXuKt3XZbtvr2jUvu9qUx8k45NUtVhvSpzf082vCuh67/Pl5tZo9xdu6bLftde2al33tVTFfUx4n45BXt1hwSG8D/a1TDv+B+aKCO3SAEO8H+vVuaNY9VEXNnuJtXbbb9rp2zcuuNuVxMg55dYsFh/T2R9ExRtsvRdV7sVfxti7bbXtdu/4cL52vKQUzDnl1i9WG9OlfLgFvK7As88V071+5ADCFQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBC/cK7SKe8H8nUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=496x30 at 0x7FCDDA7830B8>"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw weights\n",
    "\n",
    "def draw_weights(layer, size=20):\n",
    "    weights = layer.weight.data.clone().numpy()\n",
    "\n",
    "    n_weights = len(weights[0])\n",
    "    im = Image.new('RGB', ((size+1)*n_weights, size), (255, 255, 255))\n",
    "\n",
    "    for i in range(n_weights):\n",
    "        weight = draw_weight(weights[0][i], size=size)\n",
    "        im.paste(weight,((size+1)*i,0))\n",
    "\n",
    "    return im\n",
    "\n",
    "draw_weights(model[4], size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAD8AAAA/CAIAAADYPYeIAAAA9UlEQVR4nO2awQoDIQxEtfT/f9keetkVNJpEx8i844KTh0QxpSkZKKVgl3/Ha+Scp6IVq2YTPoMRaWardKsUCYL94Vxt/+y58Q7WrfJNkIHfOVd3zuHQHgftcdAeB+1x0B5HbPtsfOgFBv5CFqbyPcO1ml7fbxuuR3L+VN8DnNrOFgSw79CzP3+4Fk6tvaRLQuvoy78EnkBrC+7t+/OhPQ7a46A9DtrjoD0OTuW45UteyF6TuJhT931r/lWUTOZJXMx52XsV3kbsO8ff3msSH8l5ndrO/KsubEHMqe+cVX8KWAP7HgftcdAeB+1x0B4H7XHEnsp/C5qQT/FM8BQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=63x63 at 0x7FCDDAB83208>"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw a filter\n",
    "def draw_filter(filter):\n",
    "    matrix = Image.new('RGB', (63, 63), (255, 255, 255))\n",
    "    data = filter.view(3, 3).numpy()\n",
    "    # go over filter\n",
    "    # rows\n",
    "    for x in range(0, data.shape[0]):\n",
    "        # cols\n",
    "        for y in range(0, data.shape[1]):\n",
    "            vis = draw_weight(data[y,x])\n",
    "            matrix.paste(vis,(x*21,y*21))\n",
    "    return matrix\n",
    "\n",
    "filters = model[0].weight.data\n",
    "draw_filter(filters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARoAAAA/CAIAAACwx5DcAAACiElEQVR4nO3czU7DMBBF4Rrx/q9cFpUQrajjes74JznfikU8jp3eQiIy5RZwv99LKROH1w+Ye24u7d3w+gFbL+275aDHDx/N1DeKraDxBly1iR+Mw6m/GsffGr5XgqPYCu0TPew4HCkOnsOAq4ZM0bfklqkP4nRuwWszdzhSfNjX1jpSl3zpOEmsgzj9/Rux/U/VvlFsBY034KpN/GC0TH38KCKehz4DNquUErmvnTscKY6fw5irFhzeveTD44/jdG7xazNxOFL8gr/885bsvZOEMU4SxjhJGOMkYYyThDFOEsY4SRjjJGGMk4QxThLGOEkY4yRhykVeGpMGCP1r7fROF/UDtm7iUT/Apb0rvnTrlbN2UJl7VnmzByt3D1/zKmeor7R277ROBxW2RUl3PxnkHPJ6FczqXZG6oviej+wts8GjiBXag6xwDldDNS2KF2m3QZykXdTidNYOKnPPKm/2YOXu4Wte5QyHKz14FLFCB5WMFiUdPTfAc8j7zM3qXZGxImTPB/eW2aP1ygrfeSucw9Xs0lzpl/dOEsY4SRjjJGGMk4QxThLGOEkY4yRhjJOEMU4SxjhJGOMkYYyThLH1ioSx9crb4i4taXj9gK2XlvKCBvWGCf6a00U6hHQsE9yZZRvLDJj09d4p3qcCbLeC1EEKsr1fUst2LBPc6tUaywR3+NNJn+Jkg5F/JW2Lu51t/A77ZE/C8HGiGnHgDT0u0iGkY5ngzizbWGbMpE+PIqg+FbMapCQVzOj9kle2rxq7LqpUsDLVvKX94Ncneyf+2o5I2hZ3O9vgHfbeScIYJwljnCSMcZIwxknCGCcJY5wkjHGSMMZJwhgnCWOcJIxxkjC2XpEwP13zN1vs/so5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=282x63 at 0x7FCDDAB838D0>"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw all filters\n",
    "def draw_filters(layer):\n",
    "    matrix = Image.new('RGB', (282, 63), (255, 255, 255))\n",
    "    filters = layer.weight.data.clone()\n",
    "    for i, filter in enumerate(filters):\n",
    "        vis = draw_filter(filter)\n",
    "        matrix.paste(vis, (i*(63+10),0))\n",
    "    return matrix\n",
    "\n",
    "\n",
    "draw_filters(model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAABkCAIAAAA+Dt3DAAAD0UlEQVR4nO3dwW7dOAwF0LxB//+XPYtgMinQpNcSZdHOOasCDWlL9rutHYR5HcfxdqHX6zVcexzH3vLvv8DSvmpuaYvKh2vH/Lr4eH/1sQWn9nGsqrYD17vgqm28Mbrdk//sPoHffA7LPDjHqmo75Ad6d8fykuaF53DBVSs5xNiSL7snc73C4tkmL//e8pLmDT8Aqz1pycICiPQKi8/PZvlz2lhVbQeud8FV23hjNLwn273gnP+0X3ncs4eYeWW1t7ykefk5XHPVJsuHl9wkIz60C4tnm7/zNpaXNO/2AbjAY5bc6zEEaEtYABFhAUSEBRARFkBEWAARYQFEhAUQERZARFgAEWEBRIQFEHndfSAHcI2rf+r0wfNRLe2r5pa2qHy4dkyvH1F/6tzdvWe17uiTnYfLe17lFVqttNE7iz5zd2sH2w5PIS45h3UzIHfNBF26ovk9v9dE4lMahUUTHa5Qh3P4aaoGec83aUtYAJFGYfHUubt7z2rd0Sc7D5f3vMordFtprxecHeburhhsOzCptfAc1t1nu2aCrlhRyZ7fcSJxrldYNNHhCnU4h5/meR/vWo0eQ4DOhAUQERZARFgAEWEBRIQFEBEWQERYABFhAUSEBRARFkBEWAARA3uBiIG9J8q//wJL+6q5pS0qH64d84QfUa+aIFA+xqLVtNV1BpZZuDNtxxHf6KChze8s5qebFg7pLelT0rB2YvDStgPLLNzqbuOIJ3e4+QjPnWHRfGt2WbQtdnu1x++w74YAkduHRdVQ0/LhqN2mrS4ysMzCnWk7jvhGB83tfMFZNd1011jdRQ1XTAxe13asW+26qlpNdq4a+TtWeIHN3w3pvDUbLdoWu73as3f49o8hwDWEBRARFkBEWAARYQFEhAUQERZARFgAEWEBRIQFEBEWQERYABEDe4GI/1kAEWEBRIQFEBEWQERYABFhAUSEBRARFkBEWAARYQFEhAUQERZARFgAEWEBRIQFEBEWQERYAJFf3//1zK+QP45DuXLlNyr//gv+EhaLfJzW2bUNF5aUVzXZtfyZVoWHnrfl5Dde9w7lb2cfQ47/jB3so8kf/7yusKS8qsmu5c+0Kjz05z5j99KWk9943TuUvzsRFivuGH4m99IdecEJRDaExedHplOPT8OFJeVVTXYtf6ZV4aHnbTn5jde9Q/m7Ey84X6//f8lI4c16TWFJeVWTXcufaVWbEZP30paT33jdO5S/nf1uyPZ/VXgM99LteGcBRIQFEBEWQERYABFhAUSEBRARFkBEWAARYQFEhAUQERZARFgAkX8BXj0M4L2XhdsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=356x100 at 0x7FCDDAB835C0>"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw all the weights in the net\n",
    "def draw_net():\n",
    "    im = Image.new('RGB', (356, 100), (255, 255, 255))\n",
    "    im.paste(draw_filters(model[0]), (37,0))\n",
    "    im.paste(draw_weights(model[4]), (10,80))\n",
    "\n",
    "    return im\n",
    "\n",
    "draw_net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up network training\n",
    "nb_epochs = 20_000\n",
    "lr = 1e-3\n",
    "optimiser = optim.SGD(params=model.parameters(), lr=lr)\n",
    "#loss = nn.BCEWithLogitsLoss()\n",
    "loss = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH]: 19900, [LOSS]: 0.279057, [ACCURACY]: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(nb_epochs):\n",
    "    # Training steps\n",
    "    X, Y = generate_data()\n",
    "    logits = model(X)  # feed-forward\n",
    "    \n",
    "    # not sure if I'm doing this right ...\n",
    "    logits = logits.squeeze(-2)\n",
    "    Y = Y.unsqueeze(0)\n",
    "\n",
    "    J = loss(logits, Y)  # computes the loss\n",
    "    model.zero_grad()  # cleans up previous gradients\n",
    "    J.backward()\n",
    "    optimiser.step()\n",
    "    \n",
    "    # Accuracy computation and display\n",
    "    score, predicted = torch.max(logits, 0)\n",
    "    acc = (Y == (logits > 0)).sum().float() / len(Y)\n",
    "    \n",
    "    if(epoch % 100 == 0):\n",
    "        display.clear_output(wait=True)\n",
    "        print(\"[EPOCH]: %i, [LOSS]: %.6f, [ACCURACY]: %.3f\" % (epoch, J.item(), acc))\n",
    "        \n",
    "        continue\n",
    "        # skip the code below, used to visualize weight movements on physical net\n",
    "        \n",
    "        print(model[0].weight.data)\n",
    "        \n",
    "        figure(figsize=(10, 20))\n",
    "        #visualize_filters(model[0])\n",
    "        im = draw_net()\n",
    "        imshow(numpy.asarray(im), aspect='equal', interpolation='nearest')\n",
    "        \n",
    "        # im.save('%s.png' % epoch)\n",
    "        \n",
    "        #draw_filters(model[0]).save('%i.png' % epoch)\n",
    "        axis('off');\n",
    "        pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAydJREFUeJzt3dEJAyEQQEEN13/LpojEM/cyU8EiPPZH2DnGWANIep0eANhH4BAmcAgTOIQJHMIEDmEChzCBQ5jAIew6PcCn1vIR7xvmnKdHYAMbHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmGPP110p/J5nztPQJXf8dfY4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwq7TAzzJWuv0CNvMOU+PwAY2OIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMLmGKN7jwf+nA0OYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIewMN3wz+DQzlFQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inference: C vs. D detector\n",
    "with torch.no_grad():\n",
    "    print('C' if model(generate_data(visualise=True)[0]) > 0 else 'D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Visualization & Printing of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7fcdda3783c8>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# register hook to get activation after conv layer out\n",
    "\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "backward = {}\n",
    "def get_backward(name):\n",
    "    def hook(model, input, output):\n",
    "        backward[name] = {}\n",
    "        backward[name]['input'] = input\n",
    "        backward[name]['output'] = output\n",
    "    return hook\n",
    "\n",
    "model[0].register_forward_hook(get_activation('conv'))\n",
    "model[1].register_forward_hook(get_activation('relu'))\n",
    "model[2].register_forward_hook(get_activation('pool'))\n",
    "model[3].register_forward_hook(get_activation('flatten'))\n",
    "\n",
    "model[0].register_backward_hook(get_backward('conv'))\n",
    "model[1].register_backward_hook(get_backward('relu'))\n",
    "model[2].register_backward_hook(get_backward('pool'))\n",
    "model[3].register_backward_hook(get_backward('flatten'))\n",
    "model[4].register_backward_hook(get_backward('lin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABrCAYAAABXGGiIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAspJREFUeJzt2yFOa2EUhdHDyxWgEGgmgCUpQ+gEqjsLpoBBdQAMogkCSy2KKbRpK5GtK44EBzfvhOxkLU33f/On/XINZ6fTqQDI8e+vHwCA3xFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEGTpGX19fW/8d83A4dM5XVdVqtWrdf3h4OBvzue67vbi46JyvqqqPj4/W/el0OupuX15eWu/26empc76qqiaTSev+/f39qLutqnp/f2+93+Px2DlfVVWbzaZ1fzab/eh+vXEDhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEEa4AcIIN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhho7R/X7fMfvl+fm5db+q6vHxsf2MMRaLRev+8Xhs3a+qGoaWr92X6XQ66nPL5fI/P8l319fXrftVVev1uv2Msebzeev+1dVV635V1d3dXev+bDb70d954wYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEEa4AcIIN0CYoWN0u912zH7Z7Xat+1VV5+fn7WeMcTgcWveHoeUr8c1kMmk/Y4zLy8vW/e7fRVXVzc1N+xlj3d7etu7v9/vW/aqqt7e39jN+whs3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEEa4AcIIN0AY4QYII9wAYYQbIIxwA4QRboAwwg0Q5ux0Ov31MwDwC964AcIIN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMJ9GkE7cxJu3hwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize weights\n",
    "def visualize_filters(layer):\n",
    "    filters = layer.weight.data\n",
    "    # visualize\n",
    "    for i in range(0, len(filters)):\n",
    "        data = filters[i].view(3, 3)\n",
    "        subplot(1, 4, i+1)\n",
    "        imshow(data, cmap='gray', vmin=-1, vmax=1)\n",
    "        axis('off');\n",
    "        \n",
    "visualize_filters(model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABrCAYAAABXGGiIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAABG1JREFUeJzt3DtrVWkYhuHXMQnGLtiIiqB4QGzEIh5AUdIINrHRWluDTQp7Ayo2Ftb+BhvBNgQhiClExEPrsbFSPCA7bJuZgenybEicF66rfrK+lRW4WU3WpuFwWAD08defvgEAMsIN0IxwAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAM2PrdN3o3zHv3LkTXXx+fj7aDwaDaF9Vdf369Wi/b9++aD83N7cp+oG/3bhxI3q29+7di67/+fPnaD87Oxvtq6pWV1ej/eHDh6P9rVu3Rnq2c3Nz0bN98uRJdP3NmzdH+71790b7qqoPHz5E+6NHj0b7u3fvjvRsq6ouXrwYPd/l5eXo+u/fv4/2o5iamor2V69ejfYLCwtrer7euAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboJn1+lZJZGVlJdqn33xI91VV3759i/YHDx6MzxjF8ePHo/25c+ei/fT0dLQfxe3bt6P90tLSOt3Jf23dujXaf/nyJdqnf4stW7ZE+6qqAwcORPs3b97EZ4wq/ebMzMxMtL906VK0Hw6jT6dUVdXNmzej/YMHD6L9wsLCmnbeuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboJn/xbdKJiYmov1gMIj2Y2P5r/njx49of/bs2fiMjbC8vBztFxcXo/2RI0eifVXV5ORktD9z5kx8xkb4/v17tN+zZ0+0//jxY7Svqrp//360n5+fj8/YKC9evIj27969i/bj4+PRvqrq58+f0X52djY+Yy28cQM0I9wAzQg3QDPCDdCMcAM0I9wAzQg3QDPCDdCMcAM0I9wAzQg3QDPCDdCMcAM0I9wAzQg3QDPCDdCMcAM0I9wAzQg3QDPCDdCMcAM0I9wAzQg3QDPCDdDM2J++gaqqa9euRfuxsey2Hz58GO2rqs6fPx/tv379Gu2npqai/ajGx8ej/dOnT6P94uJitK+qmpmZifbHjh2Lz9gIExMT0f7t27fR/vnz59G+qmrHjh3RfnJyMj5jozx+/Djav3r1Ktpfvnw52ldV7d69O9pv27YtPmMtvHEDNCPcAM0IN0Azwg3QjHADNCPcAM0IN0Azwg3QjHADNCPcAM0IN0Az6/Ktkk+fPkX76enp9biNfz179iz+mStXrkT7169fR/sTJ05E+3/8+vUr2g8Gg2i/uroa7U+ePBntq6pOnz4d7ffv3x+fMYr02abf+Ui/bbJz585oX1X18uXLaL99+/b4jFGdOnUq2u/atSvaP3r0KNqvrKxE+6qqQ4cORfsLFy7EZ6yFN26AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhm03A4/NP3AEDAGzdAM8IN0IxwAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAM8IN0IxwAzTzG9Q/qYjfnMtvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inference: C vs. D \n",
    "# Conv. activations visualized\n",
    "with torch.no_grad():\n",
    "    print('C' if model(generate_data(visualise=False)[0]) > 0 else 'D')\n",
    "    \n",
    "    # visualize activations after convolution\n",
    "    for i, act in enumerate(activation['conv'][0]):\n",
    "        data = act.view(6,6)\n",
    "        subplot(1, 4, i+1)\n",
    "        imshow(data, cmap='gray', vmin=-1, vmax=1)\n",
    "        axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# A printout of sample data, activations, outputs to troubleshoot Teensy implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CONV WEIGHTS\")\n",
    "print(model[0].weight.clone().detach().squeeze(1).numpy())\n",
    "print('\\nCONV BIAS')\n",
    "print(model[0].bias.clone().detach().numpy())\n",
    "\n",
    "print('\\nLIN WEIGHTS')\n",
    "print(model[4].weight.clone().detach().numpy())\n",
    "print('\\nLIN BIAS')\n",
    "print(model[4].bias.clone().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 1., 1., 1., 0., 0., 0.],\n",
      "          [0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 1., 1., 1., 0., 0., 0.]]]]), tensor(1.))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAx5JREFUeJzt3dEJQyEQRUE3pP+WTRNJxPNmKrgIh/101lp7AUmv0wOA3xE4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCHsfXrATfbepyckzMzpCY/hgkOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BB2/d9k//wvzJ9a3MYFhzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQNmutfXrELfb2VN8wM6cnPIYLDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzBfF0GYCw5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziEfQAT0A33vfl7UgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a sample for all following data dumps\n",
    "dat = generate_data(visualise=True)\n",
    "print(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n",
      "\n",
      "\n",
      "CONV:\n",
      "tensor([[ 0.9255,  0.4525,  0.5764, -0.2918,  0.1811,  0.0572],\n",
      "        [ 0.3965,  0.6976,  0.8702,  0.0580,  0.3538,  0.0572],\n",
      "        [-0.7542,  0.8725,  0.9386,  0.9813,  0.5438,  0.0572],\n",
      "        [-0.2739,  0.9642,  0.0572,  0.0572,  0.0572,  0.0572],\n",
      "        [-0.2739,  0.9642,  0.0572,  0.0572,  0.0572,  0.0572],\n",
      "        [ 1.0673,  1.2357,  0.5764, -0.2918,  0.1811,  0.0572]])\n",
      "tensor([[ 4.0061e-01,  1.0936e-02, -4.2366e-01, -4.6347e-01, -7.3797e-02,\n",
      "          3.6079e-01],\n",
      "        [-4.2153e-01, -8.7835e-01, -8.0255e-01, -4.0990e-01,  2.0031e-03,\n",
      "          3.6079e-01],\n",
      "        [-1.3575e-04,  5.7394e-01,  1.8670e+00,  1.4264e+00,  8.6051e-01,\n",
      "          3.6079e-01],\n",
      "        [ 1.2510e-01,  6.7130e-02,  3.6079e-01,  3.6079e-01,  3.6079e-01,\n",
      "          3.6079e-01],\n",
      "        [ 1.2510e-01,  6.7130e-02,  3.6079e-01,  3.6079e-01,  3.6079e-01,\n",
      "          3.6079e-01],\n",
      "        [ 5.5459e-01,  1.5186e-01, -4.2366e-01, -4.6347e-01, -7.3797e-02,\n",
      "          3.6079e-01]])\n",
      "tensor([[ 0.0119, -0.2729, -0.3606, -0.4110, -0.1261, -0.0385],\n",
      "        [-0.4831, -0.3977, -0.5095, -0.3497, -0.2379, -0.0385],\n",
      "        [-0.3520, -0.5754,  0.1457,  0.0626,  0.3956, -0.0385],\n",
      "        [-0.7681,  0.1085, -0.0385, -0.0385, -0.0385, -0.0385],\n",
      "        [-0.7681,  0.1085, -0.0385, -0.0385, -0.0385, -0.0385],\n",
      "        [-0.4329, -0.0383, -0.3606, -0.4110, -0.1261, -0.0385]])\n",
      "tensor([[-0.2746, -0.7084, -0.9504, -0.4741, -0.0403,  0.2017],\n",
      "        [-0.3002, -0.6033, -1.0125, -0.9445, -0.4496,  0.2017],\n",
      "        [-0.3779,  0.2139,  1.7490,  1.3998,  0.8435,  0.2017],\n",
      "        [-0.1708, -0.0497,  0.2017,  0.2017,  0.2017,  0.2017],\n",
      "        [-0.1708, -0.0497,  0.2017,  0.2017,  0.2017,  0.2017],\n",
      "        [-0.2133, -0.7178, -0.9504, -0.4741, -0.0403,  0.2017]])\n",
      "\n",
      "\n",
      "RELU:\n",
      "tensor([[[[0.9255, 0.4525, 0.5764, 0.0000, 0.1811, 0.0572],\n",
      "          [0.3965, 0.6976, 0.8702, 0.0580, 0.3538, 0.0572],\n",
      "          [0.0000, 0.8725, 0.9386, 0.9813, 0.5438, 0.0572],\n",
      "          [0.0000, 0.9642, 0.0572, 0.0572, 0.0572, 0.0572],\n",
      "          [0.0000, 0.9642, 0.0572, 0.0572, 0.0572, 0.0572],\n",
      "          [1.0673, 1.2357, 0.5764, 0.0000, 0.1811, 0.0572]],\n",
      "\n",
      "         [[0.4006, 0.0109, 0.0000, 0.0000, 0.0000, 0.3608],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0020, 0.3608],\n",
      "          [0.0000, 0.5739, 1.8670, 1.4264, 0.8605, 0.3608],\n",
      "          [0.1251, 0.0671, 0.3608, 0.3608, 0.3608, 0.3608],\n",
      "          [0.1251, 0.0671, 0.3608, 0.3608, 0.3608, 0.3608],\n",
      "          [0.5546, 0.1519, 0.0000, 0.0000, 0.0000, 0.3608]],\n",
      "\n",
      "         [[0.0119, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.1457, 0.0626, 0.3956, 0.0000],\n",
      "          [0.0000, 0.1085, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1085, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2017],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2017],\n",
      "          [0.0000, 0.2139, 1.7490, 1.3998, 0.8435, 0.2017],\n",
      "          [0.0000, 0.0000, 0.2017, 0.2017, 0.2017, 0.2017],\n",
      "          [0.0000, 0.0000, 0.2017, 0.2017, 0.2017, 0.2017],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2017]]]])\n",
      "\n",
      "\n",
      "POOL:\n",
      "tensor([[[[0.9386, 0.9813],\n",
      "          [1.2357, 0.1811]],\n",
      "\n",
      "         [[1.8670, 1.4264],\n",
      "          [0.5546, 0.3608]],\n",
      "\n",
      "         [[0.1457, 0.3956],\n",
      "          [0.1085, 0.0000]],\n",
      "\n",
      "         [[1.7490, 1.3998],\n",
      "          [0.2017, 0.2017]]]])\n",
      "\n",
      "\n",
      "FLATTEN:\n",
      "tensor([[0.9386, 0.9813, 1.2357, 0.1811, 1.8670, 1.4264, 0.5546, 0.3608, 0.1457,\n",
      "         0.3956, 0.1085, 0.0000, 1.7490, 1.3998, 0.2017, 0.2017]])\n",
      "\n",
      "\n",
      "LINEAR:\n",
      "2.4335522651672363\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    #dat = generate_data(visualise=False)\n",
    "    x = dat[0]\n",
    "    y = model(x)\n",
    "    print('C' if y > 0 else 'D')\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"CONV:\")\n",
    "    \n",
    "    # visualize activations after convolution\n",
    "    for i, act in enumerate(activation['conv'][0]):\n",
    "        print(act)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"RELU:\")\n",
    "    print(activation[\"relu\"])\n",
    "    print(\"\\n\")\n",
    "    print(\"POOL:\")\n",
    "    print(activation[\"pool\"])\n",
    "    print(\"\\n\")\n",
    "    print(\"FLATTEN:\")\n",
    "    print(activation[\"flatten\"])\n",
    "    print(\"\\n\")\n",
    "    print(\"LINEAR:\")\n",
    "    print(y.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y      2.4335522651672363\n",
      "target 1.0\n",
      "loss   0.08408807218074799\n"
     ]
    }
   ],
   "source": [
    "# Loss\n",
    "X, Y = dat\n",
    "logits = model(X)  # feed-forward\n",
    "\n",
    "# not sure if I'm doing this right ...\n",
    "logits = logits.squeeze(-2)\n",
    "Y = Y.unsqueeze(0)\n",
    "\n",
    "J = loss(logits, Y)  # computes the loss\n",
    "\n",
    "print('y     ', logits.item())\n",
    "print('target', Y.item())\n",
    "print('loss  ', J.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Framework-less backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()  # cleans up previous gradients\n",
    "J.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache weights + biases BEFORE optimiser step\n",
    "w_old = {\n",
    "    'lin': model[4].weight.clone().detach(),\n",
    "    'lin_bias': model[4].bias.clone().detach(),\n",
    "    'conv': model[0].weight.clone().detach(),\n",
    "    'conv_bias': model[0].bias.clone().detach(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    # e^x => math.e ** 2\n",
    "    return 1 / (1 + math.e ** -x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L:  0.08408807218074799\n",
      "dL: -0.080649733543396\n",
      "\n",
      "GOAL\n",
      " 0.08408807218074799 \n",
      " -0.080649733543396\n"
     ]
    }
   ],
   "source": [
    "# BCEwithLogits Loss, formula from\n",
    "# https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/Loss.cpp\n",
    "\n",
    "y = logits\n",
    "\n",
    "max_val = max(0, -y)\n",
    "l = (1-Y) * y + max_val + math.log((math.e ** -max_val) + math.e ** (-y-max_val))\n",
    "\n",
    "# Derivative of BCEwithLogits Loss\n",
    "# grad_input = (input.sigmoid() - target).mul_(grad);\n",
    "dl = (sigmoid(y) - Y) * 1\n",
    "\n",
    "print(\"L: \", l.item())\n",
    "print(\"dL:\", dl.item())\n",
    "print('\\nGOAL\\n', J.item(), \"\\n\", backward[\"lin\"][\"input\"][0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dW\n",
      " tensor([[-0.0757, -0.0791, -0.0997, -0.0146, -0.1506, -0.1150, -0.0447, -0.0291,\n",
      "         -0.0118, -0.0319, -0.0088, -0.0000, -0.1411, -0.1129, -0.0163, -0.0163]],\n",
      "       grad_fn=<MulBackward0>)\n",
      " GOAL\n",
      " tensor([[-0.0757, -0.0791, -0.0997, -0.0146, -0.1506, -0.1150, -0.0447, -0.0291,\n",
      "         -0.0118, -0.0319, -0.0088,  0.0000, -0.1411, -0.1129, -0.0163, -0.0163]])\n",
      " DIFF 0.0\n",
      "\n",
      "\n",
      "dX\n",
      " tensor([[ 0.0715,  0.0778,  0.0247,  0.0359, -0.0194, -0.0776, -0.0050, -0.0287,\n",
      "          0.0086, -0.0294, -0.0087,  0.0332, -0.0269, -0.0869, -0.0305, -0.0378]],\n",
      "       grad_fn=<MulBackward0>)\n",
      " GOAL\n",
      " tensor([[ 0.0715,  0.0778,  0.0247,  0.0359, -0.0194, -0.0776, -0.0050, -0.0287,\n",
      "          0.0086, -0.0294, -0.0087,  0.0332, -0.0269, -0.0869, -0.0305, -0.0378]])\n",
      " DIFF 0.0\n",
      "\n",
      "\n",
      "dB\n",
      " tensor([-0.0806], grad_fn=<MulBackward0>)\n",
      " GOAL\n",
      " tensor([-0.0806])\n",
      " DIFF 0.0\n"
     ]
    }
   ],
   "source": [
    "# backward pass, linear layer\n",
    "dx = model[4].weight * dl\n",
    "dw = activation['flatten'] * dl\n",
    "db = dl\n",
    "\n",
    "print('\\ndW\\n',dw)\n",
    "print(' GOAL\\n', model[4].weight.grad)\n",
    "print(' DIFF', numpy.sum(a=(dw.detach().numpy() - model[4].weight.grad.detach().numpy())))\n",
    "\n",
    "print('\\n\\ndX\\n',dx)\n",
    "print(' GOAL\\n', backward[\"lin\"][\"input\"][1])\n",
    "print(' DIFF', numpy.sum(a=(dx.detach().numpy() - numpy.array(backward[\"lin\"][\"input\"][1]))))\n",
    "\n",
    "print('\\n\\ndB\\n',db)\n",
    "print(' GOAL\\n', model[4].bias.grad)\n",
    "print(' DIFF', numpy.sum(a=(db.detach().numpy() - model[4].bias.grad.detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0715,  0.0778],\n",
      "         [ 0.0247,  0.0359]],\n",
      "\n",
      "        [[-0.0194, -0.0776],\n",
      "         [-0.0050, -0.0287]],\n",
      "\n",
      "        [[ 0.0086, -0.0294],\n",
      "         [-0.0087,  0.0332]],\n",
      "\n",
      "        [[-0.0269, -0.0869],\n",
      "         [-0.0305, -0.0378]]], grad_fn=<ViewBackward>)\n",
      "\n",
      "GOAL\n",
      " (tensor([[[[ 0.0715,  0.0778],\n",
      "          [ 0.0247,  0.0359]],\n",
      "\n",
      "         [[-0.0194, -0.0776],\n",
      "          [-0.0050, -0.0287]],\n",
      "\n",
      "         [[ 0.0086, -0.0294],\n",
      "          [-0.0087,  0.0332]],\n",
      "\n",
      "         [[-0.0269, -0.0869],\n",
      "          [-0.0305, -0.0378]]]]),)\n"
     ]
    }
   ],
   "source": [
    "# backward pass, flatten\n",
    "out = dx.reshape((4,2,2))\n",
    "goal = backward['pool']['output']\n",
    "\n",
    "print(out)\n",
    "print('\\nGOAL\\n', goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GOAL\n",
      " (tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0715,  0.0778,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0247,  0.0000,  0.0000,  0.0359,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0194, -0.0776,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000, -0.0287,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.0050,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0086,  0.0000, -0.0294,  0.0000],\n",
      "          [ 0.0000, -0.0087,  0.0000,  0.0332,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0269, -0.0869,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0305, -0.0378,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]]),)\n"
     ]
    }
   ],
   "source": [
    "# backward pass, maxpool2d\n",
    "# not implemented here... but it's easy:\n",
    "# the gradient gets assigned to the item that was max() during forward pass\n",
    "\n",
    "print('\\nGOAL\\n', backward['pool']['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0715,  0.0778,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0247,  0.0000,  0.0000,  0.0359,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0194, -0.0776,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000, -0.0287,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0050,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0086,  0.0000, -0.0294,  0.0000],\n",
      "         [ 0.0000, -0.0087,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0269, -0.0869,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0305, -0.0378,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]])\n",
      "\n",
      "GOAL\n",
      " tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0715,  0.0778,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0247,  0.0000,  0.0000,  0.0359,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0194, -0.0776,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000, -0.0287,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0050,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0086,  0.0000, -0.0294,  0.0000],\n",
      "         [ 0.0000, -0.0087,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0269, -0.0869,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0305, -0.0378,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]])\n",
      "\n",
      "DIFF 0.0\n"
     ]
    }
   ],
   "source": [
    "# derivative of relu\n",
    "# see here: https://towardsdatascience.com/back-propagation-simplified-218430e21ad0\n",
    "\n",
    "# d = numpy.array(backward['pool']['input'][0][0][0], copy = True)\n",
    "# d[activation['relu'][0][0] < 0] = 0.\n",
    "\n",
    "relu_grad = backward['pool']['input'][0][0].clone().detach()\n",
    "\n",
    "for f in range(0,4):\n",
    "    for y in range(0,6):\n",
    "        for x in range(0,6):\n",
    "            if(activation['act'][0][f][y][x] <= 0):\n",
    "                relu_grad[f][y][x] = 0\n",
    "                \n",
    "print(relu_grad)\n",
    "print('\\nGOAL\\n', backward['relu']['input'][0][0])\n",
    "\n",
    "print('\\nDIFF', (backward['relu']['input'][0][0] - relu_grad).sum().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Make an optimiser step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache weights + biases AFTER optimiser step\n",
    "w_new = {\n",
    "    'lin': model[4].weight.clone().detach(),\n",
    "    'lin_bias': model[4].bias.clone().detach(),\n",
    "    'conv': model[0].weight.clone().detach(),\n",
    "    'conv_bias': model[0].bias.clone().detach(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8860, -0.9646, -0.3057, -0.4446,  0.2404,  0.9619,  0.0626,  0.3562,\n",
      "         -0.1067,  0.3641,  0.1073, -0.4122,  0.3337,  1.0777,  0.3787,  0.4688]])\n",
      "\n",
      "GOAL\n",
      " [-0.8859708  -0.9646351  -0.30574358 -0.44463044  0.24039814  0.9618884\n",
      "  0.06261699  0.35623348 -0.10668962  0.36407247  0.10729297 -0.41222888\n",
      "  0.33366507  1.0777308   0.3787301   0.46880627]\n",
      "\n",
      "DIFF: 0.0\n"
     ]
    }
   ],
   "source": [
    "# lin layer, weight update\n",
    "# https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n",
    "weight_update = w_old['lin'].clone()\n",
    "weight_update -= lr * dw.clone().detach()\n",
    "\n",
    "# goal\n",
    "goal = w_new['lin'][0].numpy()\n",
    "print(weight_update)\n",
    "print('\\nGOAL\\n', goal)\n",
    "print('\\nDIFF:', numpy.sum(a=(goal - weight_update[0].numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALC: 0.2839290499687195\n",
      "GOAL: 0.2839290499687195\n",
      "DIFF: 0.0\n"
     ]
    }
   ],
   "source": [
    "# lin layer, bias update\n",
    "new_bias = w_old['lin_bias'].clone() - db * lr\n",
    "\n",
    "print('CALC:', new_bias.item())\n",
    "print('GOAL:', model[4].bias.item())\n",
    "print('DIFF:', (model[4].bias.item()-new_bias).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### conv weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.17392953  0.14926335  0.07145941]\n",
      "  [ 0.02466618  0.          0.        ]\n",
      "  [ 0.0358605   0.02466618  0.02466618]]\n",
      "\n",
      " [[-0.09694266 -0.1019891  -0.0193759 ]\n",
      "  [ 0.         -0.00504644  0.        ]\n",
      "  [ 0.          0.         -0.00504644]]\n",
      "\n",
      " [[-0.02940678  0.00860544  0.00860544]\n",
      "  [-0.00865244  0.          0.        ]\n",
      "  [-0.00865244  0.          0.        ]]\n",
      "\n",
      " [[-0.11380821 -0.11380821 -0.02689862]\n",
      "  [ 0.          0.          0.        ]\n",
      "  [ 0.          0.          0.        ]]]\n",
      "\n",
      "GOAL\n",
      " tensor([[[ 0.1739,  0.1493,  0.0715],\n",
      "         [ 0.0247,  0.0000,  0.0000],\n",
      "         [ 0.0359,  0.0247,  0.0247]],\n",
      "\n",
      "        [[-0.0969, -0.1020, -0.0194],\n",
      "         [ 0.0000, -0.0050,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0050]],\n",
      "\n",
      "        [[-0.0294,  0.0086,  0.0086],\n",
      "         [-0.0087,  0.0000,  0.0000],\n",
      "         [-0.0087,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.1138, -0.1138, -0.0269],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]]])\n",
      "DIFF 0.0\n"
     ]
    }
   ],
   "source": [
    "# backward pass, conv\n",
    "\n",
    "# only doing it here, after optimiser.step() so that model[0].weight.grad has a gradient for comparison\n",
    "\n",
    "# incoming gradient\n",
    "g = backward['relu']['input'][0][0]\n",
    "\n",
    "# gradient var\n",
    "conv_grad = torch.zeros((4,3,3))\n",
    "\n",
    "# filters\n",
    "for f in range(0,4):\n",
    "    for fy in range(0,3):\n",
    "        for fx in range(0,3):\n",
    "            # slide gradient over input X to get dF\n",
    "            for y in range(0,6):\n",
    "                for x in range(0,6):\n",
    "                    conv_grad[f][fy][fx] += g[f][y][x] * dat[0][0][0][y+fy][x+fx]\n",
    "\n",
    "goal = model[0].weight.grad.clone().squeeze(1)\n",
    "\n",
    "print(conv_grad.numpy())\n",
    "print('\\nGOAL\\n', goal)\n",
    "print('DIFF', (conv_grad - goal).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4864,  0.4374, -0.0428],\n",
      "         [ 0.2965, -0.2957,  0.8122],\n",
      "         [ 0.1239, -0.4730,  0.8683]],\n",
      "\n",
      "        [[ 0.4998,  0.5660,  0.4407],\n",
      "         [-0.3588, -0.4119, -0.3926],\n",
      "         [-0.4346, -0.3897,  0.0398]],\n",
      "\n",
      "        [[ 0.4341, -0.3330,  0.0831],\n",
      "         [-0.1994, -0.1118, -0.1598],\n",
      "         [-0.0877, -0.2849,  0.0504]],\n",
      "\n",
      "        [[ 0.6420,  0.5564,  0.3492],\n",
      "         [-0.6512, -0.4949, -0.0681],\n",
      "         [-0.2420, -0.4338, -0.4763]]])\n",
      "\n",
      "GOAL: tensor([[[ 0.4864,  0.4374, -0.0428],\n",
      "         [ 0.2965, -0.2957,  0.8122],\n",
      "         [ 0.1239, -0.4730,  0.8683]],\n",
      "\n",
      "        [[ 0.4998,  0.5660,  0.4407],\n",
      "         [-0.3588, -0.4119, -0.3926],\n",
      "         [-0.4346, -0.3897,  0.0398]],\n",
      "\n",
      "        [[ 0.4341, -0.3330,  0.0831],\n",
      "         [-0.1994, -0.1118, -0.1598],\n",
      "         [-0.0877, -0.2849,  0.0504]],\n",
      "\n",
      "        [[ 0.6420,  0.5564,  0.3492],\n",
      "         [-0.6512, -0.4949, -0.0681],\n",
      "         [-0.2420, -0.4338, -0.4763]]])\n",
      "DIFF: 0.0\n"
     ]
    }
   ],
   "source": [
    "new_weights = w_old['conv'].clone().squeeze(1)\n",
    "new_weights -= lr * conv_grad\n",
    "goal = w_new['conv'].clone().squeeze(1)\n",
    "\n",
    "print(new_weights)\n",
    "print('\\nGOAL:', goal)\n",
    "print('DIFF:', (goal - new_weights).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0570,  0.3609, -0.0384,  0.2019])\n",
      "GOAL: tensor([ 0.0570,  0.3609, -0.0384,  0.2019])\n",
      "DIFF: 0.0\n"
     ]
    }
   ],
   "source": [
    "# conv layer, bias update\n",
    "# -> sum of filter gradient is dB\n",
    "# https://stackoverflow.com/questions/3775032/how-to-update-the-bias-in-neural-network-backpropagation\n",
    "# https://datascience.stackexchange.com/questions/25081/how-to-update-bias-in-cnn\n",
    "\n",
    "# biases before weight update\n",
    "biases = w_old['conv_bias'].clone()\n",
    "\n",
    "for i in range(len(biases)):\n",
    "    biases[i] -= g[i].sum() * lr\n",
    "\n",
    "goal = model[0].bias.clone().detach()\n",
    "\n",
    "print(biases)\n",
    "print('GOAL:', goal)\n",
    "print('DIFF:', (goal - biases).sum().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Histogram of trained weights -> needed to calibrate Teensy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_weights = model[0].weight.clone().detach().numpy().flatten()\n",
    "l_weights = model[4].weight.clone().detach().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = numpy.hstack(c_weights)\n",
    "_ = plt.hist(a, bins=20)  # arguments are passed to np.histogram\n",
    "plt.title(\"conv layer weigths\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = numpy.hstack(l_weights)\n",
    "_ = plt.hist(a, bins=20)  # arguments are passed to np.histogram\n",
    "plt.title(\"linear layer weights\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.7113621  2.652094   1.6652656  1.6652656  1.0914052  1.09125\n",
      " 0.45121658 0.87274873 0.12399553 0.12399553 0.12399553 0.377969\n",
      " 0.867496   0.86399525 0.47998905 0.8315278 ]\n"
     ]
    }
   ],
   "source": [
    "at = activation['flatten'][0].numpy().flatten()\n",
    "print(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = numpy.hstack(l_weights)\n",
    "_ = plt.hist(at, bins=20)  # arguments are passed to np.histogram\n",
    "plt.title(\"linear layer weights\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
