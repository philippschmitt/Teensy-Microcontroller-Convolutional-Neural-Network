{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini neural net training\n",
    "Authors: Alfredo Canziani, Philipp Schmitt  \n",
    "Date: Tue 24 Feb 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from IPython import display\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from matplotlib.pyplot import imshow, axis, figure, subplot, pause\n",
    "import numpy\n",
    "import random\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11e703150>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# static random seed\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input definition\n",
    "class input_settings:\n",
    "    batch_size = 1\n",
    "    channels = 1\n",
    "    height = 8\n",
    "    width = 8\n",
    "\n",
    "dummy_X = torch.randn(  # batch of inputs x\n",
    "    input_settings.batch_size,\n",
    "    input_settings.channels,\n",
    "    input_settings.height,\n",
    "    input_settings.width,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network architecture\n",
    "class model_settings:\n",
    "    conv_channels = 4\n",
    "    kernel = 3\n",
    "    pooling_kernel = 3\n",
    "    flattened = 16\n",
    "    output_size = 1\n",
    "    \n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(\n",
    "        in_channels=input_settings.channels,\n",
    "        out_channels=model_settings.conv_channels,\n",
    "        kernel_size=model_settings.kernel,\n",
    "        bias=True,\n",
    "    ),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(\n",
    "        kernel_size=model_settings.pooling_kernel,\n",
    "        stride=model_settings.pooling_kernel,\n",
    "    ),  # we have 4 x 2x2\n",
    "    nn.Flatten(),  # gives 16\n",
    "    nn.Linear(\n",
    "        in_features=model_settings.flattened,\n",
    "        out_features=model_settings.output_size,\n",
    "        bias=True,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "with torch.no_grad():\n",
    "    print(model(dummy_X).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Flatten()\n",
      "  (4): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weights and biases\n",
    "def get_weights():\n",
    "    print(\n",
    "        model[0],\n",
    "        model[0].weight,\n",
    "        model[0].bias,\n",
    "        sep='\\n',\n",
    "    )\n",
    "    print(\n",
    "        model[4],\n",
    "        model[4].weight,\n",
    "        model[4].bias,\n",
    "        sep='\\n',\n",
    "    )\n",
    "    # Maybe add some saving routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = ImageFont.truetype('Verdana', 8)  # let's keep it to Verdana 8pt\n",
    "data_set_settings = dict(\n",
    "    D=dict(\n",
    "        x_min = -1,\n",
    "        x_max = 2,\n",
    "        y_min = -3,\n",
    "        y_max = -1,\n",
    "    ),\n",
    "    C=dict(\n",
    "        x_min = 0,\n",
    "        x_max = 3,\n",
    "        y_min = -4,\n",
    "        y_max = -2,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(visualise=False, target=None):\n",
    "    image = Image.new('L', (input_settings.height, input_settings.width))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.fontmode = '1'\n",
    "    if not target:\n",
    "        character = random.choice(('C', 'D'))\n",
    "    else:\n",
    "        character = target\n",
    "\n",
    "    x = random.randint(\n",
    "        data_set_settings[character]['x_min'],\n",
    "        data_set_settings[character]['x_max'],\n",
    "    )\n",
    "    y = random.randint(\n",
    "        data_set_settings[character]['y_min'],\n",
    "        data_set_settings[character]['y_max'],\n",
    "    )\n",
    "\n",
    "    draw.text((x, y), character, (255,), font=font)\n",
    "    data = numpy.array(image, dtype=numpy.float32) / 255\n",
    "    \n",
    "    if visualise:\n",
    "        figure(facecolor='k')\n",
    "        imshow(data, cmap='gray')\n",
    "        axis('off');\n",
    "    \n",
    "    return torch.tensor(data).unsqueeze_(0), torch.tensor(character=='C', dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 1., 1., 1.]]]), tensor(1.))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAzRJREFUeJzt3UFuwzAMAEEqyP+/rD4hBtJaxXrmbMA8aMEj18zsAZJepwcA/o7AIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5h79MD8Dx779MjJKy1Pn5jg0OYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BDmNhkzc++9sCs3tfgdNjiECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCnC76x5wT4ls2OIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ9iamX16CM7b+75nsNa67V9PZ4NDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQ9j49AM9z5x20sis33mxwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hK2ZcUcGomxwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIewHeWIT+1jnBScAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_data(visualise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letter samples\n",
    "samples = [\n",
    "    [\n",
    "        [0,1,1,1],\n",
    "        [1,0,0,0],\n",
    "        [1,0,0,0],\n",
    "        [1,0,0,0],\n",
    "        [1,0,0,0],\n",
    "        [0,1,1,1]\n",
    "    ],\n",
    "    [\n",
    "        [1,1,1],\n",
    "        [1,0,0],\n",
    "        [1,0,0],\n",
    "        [1,1,1]\n",
    "    ],\n",
    "    [\n",
    "        [1,1,1,0],\n",
    "        [1,0,0,1],\n",
    "        [1,0,0,1],\n",
    "        [1,0,0,1],\n",
    "        [1,0,0,1],\n",
    "        [1,1,1,0]\n",
    "    ],\n",
    "    [\n",
    "        [1,1,0],\n",
    "        [1,0,1],\n",
    "        [1,0,1],\n",
    "        [1,1,0]\n",
    "    ]\n",
    "]\n",
    "\n",
    "sample_meta = [\n",
    "    [6,4,'C'],\n",
    "\t[4,3,'C'],\n",
    "\t[6,4,'D'],\n",
    "\t[4,3,'D']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 1., 1., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 1., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.]]]), tensor(1.))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAx5JREFUeJzt3cENwzAMBEExcP8tK+8U4MhYz1RwnwWfnLXWXkDS5/QA4D4ChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziEXacH8Ax779MTEmbm9IQfLjiECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hfpPxd0/731XmgkOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIRdpwfwPnvv0xNuMzOnJ/xwwSFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BA2a63uHxl4ORccwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQ9gWsvwn+Q+XkiQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# updated gen. function to match teensy implementation\n",
    "def generate_data(visualise=False, target=None):\n",
    "    data = numpy.zeros(shape=(8,8), dtype=numpy.float32)\n",
    "    \n",
    "    sample = random.randint(0,len(samples)-1)\n",
    "    character = sample_meta[sample][2];\n",
    "    \n",
    "    x = random.randint(\n",
    "        0,\n",
    "        input_settings.width-sample_meta[sample][1]\n",
    "    )\n",
    "    y = random.randint(\n",
    "        0,\n",
    "        input_settings.height-sample_meta[sample][0]\n",
    "    )\n",
    "    \n",
    "    data[y:y+sample_meta[sample][0],x:x+sample_meta[sample][1]] = samples[sample]\n",
    "    \n",
    "    if visualise:\n",
    "        figure(facecolor='k')\n",
    "        imshow(data, cmap='gray')\n",
    "        axis('off');\n",
    "        \n",
    "    return torch.tensor(data).unsqueeze_(0), torch.tensor(character=='C', dtype=torch.float)\n",
    "        \n",
    "generate_data(visualise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a C, D batch\n",
    "def get_batch(visualise=False):\n",
    "    Cx, Cy = generate_data(target='C', visualise=visualise)\n",
    "    Dx, Dy = generate_data(target='D', visualise=visualise)\n",
    "    x = torch.stack((Cx, Dx))\n",
    "    y = torch.stack((Cy, Dy))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEYAAABGCAIAAAD+THXTAAAATUlEQVR4nO3TMQoAIQwEQL3//zk2coiWUU6OmSpNFrbYUgAA+Juaj4iInlU3pOU9yf+3z3R/KFvpQiotxv1csiUAAAAAAAAAAAAA4JgGt1sJCjqkBk8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=70x70 at 0x10B9F7208>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from numpy import interp\n",
    "from math import cos, sin, radians, pi\n",
    "\n",
    "\n",
    "def draw_weight(value, size=20):\n",
    "    rad = interp(value,[-.75,.75],[pi,0])\n",
    "    im = Image.new('RGB', (size, size), (0, 0, 0))\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    x, y, r = (\n",
    "        size/2 + size/3 * cos(rad), \n",
    "        size/2 - size/3 * sin(rad),\n",
    "        4)\n",
    "    draw.ellipse((x-r/2, y-r/2, x+r/2, y+r/2), fill=(255, 255, 255), outline=None)\n",
    "\n",
    "    return im\n",
    "\n",
    "draw_weight(-.25, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAAeCAIAAABc99v3AAABNElEQVR4nO3aMY7DMAwEQCu4/3/ZVwVwcXYl0tLeTJWKlAVx4Sg5jjLneSquuOKKK95W/FNXHYBOAh0gxM/bCziOy9eQMcbKNXuKt3XZbtvr2jUvu9qUx8k45NUtVhvSpzf082vCuh67/Pl5tZo9xdu6bLftde2al33tVTFfUx4n45BXt1hwSG8D/a1TDv+B+aKCO3SAEO8H+vVuaNY9VEXNnuJtXbbb9rp2zcuuNuVxMg55dYsFh/T2R9ExRtsvRdV7sVfxti7bbXtdu/4cL52vKQUzDnl1i9WG9OlfLgFvK7As88V071+5ADCFQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBACHSCEQAcIIdABQgh0gBC/cK7SKe8H8nUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=496x30 at 0x10B9EDC88>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw weights\n",
    "\n",
    "def draw_weights(layer, size=20):\n",
    "    weights = layer.weight.data.clone().numpy()\n",
    "\n",
    "    n_weights = len(weights[0])\n",
    "    im = Image.new('RGB', ((size+1)*n_weights, size), (255, 255, 255))\n",
    "\n",
    "    for i in range(n_weights):\n",
    "        weight = draw_weight(weights[0][i], size=size)\n",
    "        im.paste(weight,((size+1)*i,0))\n",
    "\n",
    "    return im\n",
    "\n",
    "draw_weights(model[4], size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAD8AAAA/CAIAAADYPYeIAAAA9UlEQVR4nO2awQoDIQxEtfT/f9keetkVNJpEx8i844KTh0QxpSkZKKVgl3/Ha+Scp6IVq2YTPoMRaWardKsUCYL94Vxt/+y58Q7WrfJNkIHfOVd3zuHQHgftcdAeB+1x0B5HbPtsfOgFBv5CFqbyPcO1ml7fbxuuR3L+VN8DnNrOFgSw79CzP3+4Fk6tvaRLQuvoy78EnkBrC+7t+/OhPQ7a46A9DtrjoD0OTuW45UteyF6TuJhT931r/lWUTOZJXMx52XsV3kbsO8ff3msSH8l5ndrO/KsubEHMqe+cVX8KWAP7HgftcdAeB+1x0B4H7XHEnsp/C5qQT/FM8BQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=63x63 at 0x123F1F128>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw a filter\n",
    "def draw_filter(filter):\n",
    "    matrix = Image.new('RGB', (63, 63), (255, 255, 255))\n",
    "    data = filter.view(3, 3).numpy()\n",
    "    # go over filter\n",
    "    # rows\n",
    "    for x in range(0, data.shape[0]):\n",
    "        # cols\n",
    "        for y in range(0, data.shape[1]):\n",
    "            vis = draw_weight(data[y,x])\n",
    "            matrix.paste(vis,(x*21,y*21))\n",
    "    return matrix\n",
    "\n",
    "filters = model[0].weight.data\n",
    "draw_filter(filters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARoAAAA/CAIAAACwx5DcAAACiElEQVR4nO3czU7DMBBF4Rrx/q9cFpUQrajjes74JznfikU8jp3eQiIy5RZwv99LKROH1w+Ye24u7d3w+gFbL+275aDHDx/N1DeKraDxBly1iR+Mw6m/GsffGr5XgqPYCu0TPew4HCkOnsOAq4ZM0bfklqkP4nRuwWszdzhSfNjX1jpSl3zpOEmsgzj9/Rux/U/VvlFsBY034KpN/GC0TH38KCKehz4DNquUErmvnTscKY6fw5irFhzeveTD44/jdG7xazNxOFL8gr/885bsvZOEMU4SxjhJGOMkYYyThDFOEsY4SRjjJGGMk4QxThLGOEkY4yRhykVeGpMGCP1r7fROF/UDtm7iUT/Apb0rvnTrlbN2UJl7VnmzByt3D1/zKmeor7R277ROBxW2RUl3PxnkHPJ6FczqXZG6oviej+wts8GjiBXag6xwDldDNS2KF2m3QZykXdTidNYOKnPPKm/2YOXu4Wte5QyHKz14FLFCB5WMFiUdPTfAc8j7zM3qXZGxImTPB/eW2aP1ygrfeSucw9Xs0lzpl/dOEsY4SRjjJGGMk4QxThLGOEkY4yRhjJOEMU4SxjhJGOMkYYyThLH1ioSx9crb4i4taXj9gK2XlvKCBvWGCf6a00U6hHQsE9yZZRvLDJj09d4p3qcCbLeC1EEKsr1fUst2LBPc6tUaywR3+NNJn+Jkg5F/JW2Lu51t/A77ZE/C8HGiGnHgDT0u0iGkY5ngzizbWGbMpE+PIqg+FbMapCQVzOj9kle2rxq7LqpUsDLVvKX94Ncneyf+2o5I2hZ3O9vgHfbeScIYJwljnCSMcZIwxknCGCcJY5wkjHGSMMZJwhgnCWOcJIxxkjC2XpEwP13zN1vs/so5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=282x63 at 0x123F24F28>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw all filters\n",
    "def draw_filters(layer):\n",
    "    matrix = Image.new('RGB', (282, 63), (255, 255, 255))\n",
    "    filters = layer.weight.data.clone()\n",
    "    for i, filter in enumerate(filters):\n",
    "        vis = draw_filter(filter)\n",
    "        matrix.paste(vis, (i*(63+10),0))\n",
    "    return matrix\n",
    "\n",
    "\n",
    "draw_filters(model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARoAAAA/CAIAAACwx5DcAAACiElEQVR4nO3czU7DMBBF4Rrx/q9cFpUQrajjes74JznfikU8jp3eQiIy5RZwv99LKROH1w+Ye24u7d3w+gFbL+275aDHDx/N1DeKraDxBly1iR+Mw6m/GsffGr5XgqPYCu0TPew4HCkOnsOAq4ZM0bfklqkP4nRuwWszdzhSfNjX1jpSl3zpOEmsgzj9/Rux/U/VvlFsBY034KpN/GC0TH38KCKehz4DNquUErmvnTscKY6fw5irFhzeveTD44/jdG7xazNxOFL8gr/885bsvZOEMU4SxjhJGOMkYYyThDFOEsY4SRjjJGGMk4QxThLGOEkY4yRhykVeGpMGCP1r7fROF/UDtm7iUT/Apb0rvnTrlbN2UJl7VnmzByt3D1/zKmeor7R277ROBxW2RUl3PxnkHPJ6FczqXZG6oviej+wts8GjiBXag6xwDldDNS2KF2m3QZykXdTidNYOKnPPKm/2YOXu4Wte5QyHKz14FLFCB5WMFiUdPTfAc8j7zM3qXZGxImTPB/eW2aP1ygrfeSucw9Xs0lzpl/dOEsY4SRjjJGGMk4QxThLGOEkY4yRhjJOEMU4SxjhJGOMkYYyThLH1ioSx9crb4i4taXj9gK2XlvKCBvWGCf6a00U6hHQsE9yZZRvLDJj09d4p3qcCbLeC1EEKsr1fUst2LBPc6tUaywR3+NNJn+Jkg5F/JW2Lu51t/A77ZE/C8HGiGnHgDT0u0iGkY5ngzizbWGbMpE+PIqg+FbMapCQVzOj9kle2rxq7LqpUsDLVvKX94Ncneyf+2o5I2hZ3O9vgHfbeScIYJwljnCSMcZIwxknCGCcJY5wkjHGSMMZJwhgnCWOcJIxxkjC2XpEwP13zN1vs/so5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=282x63 at 0x10B9BFE80>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_filters(model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model[0].weight.data.fill_(0)\n",
    "#model[4].weight.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAABkCAIAAAA+Dt3DAAAD0UlEQVR4nO3dwW7dOAwF0LxB//+XPYtgMinQpNcSZdHOOasCDWlL9rutHYR5HcfxdqHX6zVcexzH3vLvv8DSvmpuaYvKh2vH/Lr4eH/1sQWn9nGsqrYD17vgqm28Mbrdk//sPoHffA7LPDjHqmo75Ad6d8fykuaF53DBVSs5xNiSL7snc73C4tkmL//e8pLmDT8Aqz1pycICiPQKi8/PZvlz2lhVbQeud8FV23hjNLwn273gnP+0X3ncs4eYeWW1t7ykefk5XHPVJsuHl9wkIz60C4tnm7/zNpaXNO/2AbjAY5bc6zEEaEtYABFhAUSEBRARFkBEWAARYQFEhAUQERZARFgAEWEBRIQFEHndfSAHcI2rf+r0wfNRLe2r5pa2qHy4dkyvH1F/6tzdvWe17uiTnYfLe17lFVqttNE7iz5zd2sH2w5PIS45h3UzIHfNBF26ovk9v9dE4lMahUUTHa5Qh3P4aaoGec83aUtYAJFGYfHUubt7z2rd0Sc7D5f3vMordFtprxecHeburhhsOzCptfAc1t1nu2aCrlhRyZ7fcSJxrldYNNHhCnU4h5/meR/vWo0eQ4DOhAUQERZARFgAEWEBRIQFEBEWQERYABFhAUSEBRARFkBEWAARA3uBiIG9J8q//wJL+6q5pS0qH64d84QfUa+aIFA+xqLVtNV1BpZZuDNtxxHf6KChze8s5qebFg7pLelT0rB2YvDStgPLLNzqbuOIJ3e4+QjPnWHRfGt2WbQtdnu1x++w74YAkduHRdVQ0/LhqN2mrS4ysMzCnWk7jvhGB83tfMFZNd1011jdRQ1XTAxe13asW+26qlpNdq4a+TtWeIHN3w3pvDUbLdoWu73as3f49o8hwDWEBRARFkBEWAARYQFEhAUQERZARFgAEWEBRIQFEBEWQERYABEDe4GI/1kAEWEBRIQFEBEWQERYABFhAUSEBRARFkBEWAARYQFEhAUQERZARFgAEWEBRIQFEBEWQERYAJFf3//1zK+QP45DuXLlNyr//gv+EhaLfJzW2bUNF5aUVzXZtfyZVoWHnrfl5Dde9w7lb2cfQ47/jB3so8kf/7yusKS8qsmu5c+0Kjz05z5j99KWk9943TuUvzsRFivuGH4m99IdecEJRDaExedHplOPT8OFJeVVTXYtf6ZV4aHnbTn5jde9Q/m7Ey84X6//f8lI4c16TWFJeVWTXcufaVWbEZP30paT33jdO5S/nf1uyPZ/VXgM99LteGcBRIQFEBEWQERYABFhAUSEBRARFkBEWAARYQFEhAUQERZARFgAkX8BXj0M4L2XhdsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=356x100 at 0x10B9ED320>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw all the weights in the net\n",
    "def draw_net():\n",
    "    im = Image.new('RGB', (356, 100), (255, 255, 255))\n",
    "    im.paste(draw_filters(model[0]), (37,0))\n",
    "    im.paste(draw_weights(model[4]), (10,80))\n",
    "\n",
    "    return im\n",
    "\n",
    "draw_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABrCAYAAABXGGiIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAArZJREFUeJzt2zFOamEUhdGDsdBGYkepWEmHzsZRUFI5DGNLwhTsnYIUxobGxAHIBO7rrPW+nGd23lo9+yd/4OM2TIZhKAByHP32GwDgZ4QbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhjjtGHx8fW/+O+f7+3jlfVVUnJyet+/f395Mxr9tut613e3SU/1t+d3c36m43m03r3T49PXXOV1XVzc1N6/56vR51t1VVDw8Prfd7enraOV9VVZ+fn637q9XqW/eb/y0F+M8IN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMcdo4fDoWP2y+XlZet+VdXZ2Vn7GWN8fHy07r+8vLTuV1UtFov2M8Z4e3tr3b+6umrdr+r/fPyN5+fn1v3pdNq6X1W1XC7bz/gOT9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEEa4AcIIN0AY4QYIc9wx+vr62jH75fz8vHW/quri4qL9jDH2+33r/jAMrftVVfP5vP2MMWazWet+9/eiqur6+rr9jLFub29b9//F/e52u/YzvsMTN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEGYyDMNvvwcAfsATN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEOYPpUVDXdix804AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize weights\n",
    "def visualize_filters(layer):\n",
    "    filters = layer.weight.data.clone()\n",
    "    # visualize\n",
    "    for i in range(0, len(filters)):\n",
    "        data = filters[i].view(3, 3)\n",
    "        subplot(1, 4, i+1)\n",
    "        imshow(data, cmap='gray', vmin=-1, vmax=1)\n",
    "        axis('off');\n",
    "        \n",
    "visualize_filters(model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up network training\n",
    "nb_epochs = 10_000\n",
    "optimiser = optim.SGD(params=model.parameters(), lr=1e-4)\n",
    "#loss = nn.BCEWithLogitsLoss()\n",
    "loss = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH]: 900, [LOSS]: 0.587386, [ACCURACY]: 1.000\n",
      "tensor([[[[ 0.2583,  0.1130,  0.1664],\n",
      "          [ 0.1290, -0.1066,  0.5152],\n",
      "          [-0.1506, -0.3007,  0.5802]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4498,  0.4808,  0.4108],\n",
      "          [-0.2379, -0.3478, -0.2646],\n",
      "          [-0.3933, -0.3176,  0.0442]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4306, -0.3333,  0.0822],\n",
      "          [-0.1255, -0.1022, -0.1554],\n",
      "          [ 0.0010, -0.2646,  0.0243]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4248,  0.3947,  0.2808],\n",
      "          [-0.4287, -0.3338,  0.0354],\n",
      "          [-0.0901, -0.3116, -0.3454]]]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-356-6fc6b576bfea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#draw_filters(model[0]).save('%i.png' % epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mpause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mpause\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \"\"\"\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     41\u001b[0m             display(\n\u001b[1;32m     42\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2208\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2209\u001b[0m                     \u001b[0mdryrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2210\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2211\u001b[0m                 \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cachedRenderer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m                 \u001b[0mbbox_inches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 _png.write_png(renderer._renderer, fh,\n\u001b[0;32m--> 526\u001b[0;31m                                self.figure.dpi, metadata=metadata)\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_dpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(nb_epochs):\n",
    "    # Training steps\n",
    "    X, Y = generate_data()\n",
    "    logits = model(X.unsqueeze(0))  # feed-forward\n",
    "    \n",
    "    # not sure if I'm doing this right ...\n",
    "    logits = logits.squeeze(-2)\n",
    "    Y = Y.unsqueeze(0)\n",
    "\n",
    "    J = loss(logits, Y)  # computes the loss\n",
    "    model.zero_grad()  # cleans up previous gradients\n",
    "    J.backward()\n",
    "    optimiser.step()\n",
    "    \n",
    "    # Accuracy computation and display\n",
    "    score, predicted = torch.max(logits, 0)\n",
    "    acc = (Y == (logits > 0)).sum().float() / len(Y)\n",
    "\n",
    "    if(epoch % 100 == 0):\n",
    "        display.clear_output(wait=True)\n",
    "        print(\"[EPOCH]: %i, [LOSS]: %.6f, [ACCURACY]: %.3f\" % (epoch, J.item(), acc))\n",
    "        \n",
    "        print(model[0].weight.data)\n",
    "        \n",
    "        figure(figsize=(10, 20))\n",
    "        #visualize_filters(model[0])\n",
    "        im = draw_net()\n",
    "        imshow(numpy.asarray(im), aspect='equal', interpolation='nearest')\n",
    "        \n",
    "        # im.save('%s.png' % epoch)\n",
    "        \n",
    "        #draw_filters(model[0]).save('%i.png' % epoch)\n",
    "        axis('off');\n",
    "        pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAx9JREFUeJzt3bENAjAMAMEYsf/KYQIqFCKeuwEsNy+XnrXWXkDS4/YCwDkChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziEPU8M3XufGPt3Zub2Cvw4FxzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAoewI7/Jvsn/LnjPBYcwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAh73l7gU3vv2yscMzO3V+DHueAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIm7VW9/cP/DkXHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgEPYC6nEJ/hpjB4oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inference: C vs. D detector\n",
    "with torch.no_grad():\n",
    "    print('C' if model(generate_data(visualise=True)[0].unsqueeze_(0)) > 0 else 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x123e1c080>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# register hook to get activation after conv layer out\n",
    "\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "model[0].register_forward_hook(get_activation('act'))\n",
    "model[1].register_forward_hook(get_activation('relu'))\n",
    "model[2].register_forward_hook(get_activation('pool'))\n",
    "model[3].register_forward_hook(get_activation('flatten'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n",
      "tensor([[[[ 0.3136,  0.3136,  0.3136,  0.3136,  0.3136,  0.3136],\n",
      "          [ 0.3136,  0.3136,  0.3136,  0.3136,  0.3136,  0.3136],\n",
      "          [ 0.4446,  0.3224,  0.0656, -0.0654,  0.0567,  0.3136],\n",
      "          [ 0.7647,  0.7183,  0.6608,  0.5976,  0.3908,  0.3136],\n",
      "          [ 0.7774,  0.3689,  0.2876,  0.4545,  0.4966,  0.3136],\n",
      "          [ 0.7774,  0.4871,  0.3258, -0.0654,  0.0567,  0.3136]],\n",
      "\n",
      "         [[ 0.2246,  0.2246,  0.2246,  0.2246,  0.2246,  0.2246],\n",
      "          [ 0.2246,  0.2246,  0.2246,  0.2246,  0.2246,  0.2246],\n",
      "          [ 0.5208,  0.2101,  0.0016, -0.2946,  0.0161,  0.2246],\n",
      "          [ 0.5514, -0.3452, -0.1768,  0.0011,  0.2909,  0.2246],\n",
      "          [ 0.8456,  0.2083,  0.9428,  0.7909,  0.5008,  0.2246],\n",
      "          [ 0.8456,  0.2103,  0.3441, -0.2946,  0.0161,  0.2246]],\n",
      "\n",
      "         [[-0.1453, -0.1453, -0.1453, -0.1453, -0.1453, -0.1453],\n",
      "          [-0.1453, -0.1453, -0.1453, -0.1453, -0.1453, -0.1453],\n",
      "          [-0.0231, -0.2206, -0.0924, -0.2146, -0.0172, -0.1453],\n",
      "          [-0.1757, -0.5502, -0.2807, -0.2563, -0.2015, -0.1453],\n",
      "          [-0.1133, -0.6677, -0.0900, -0.2244,  0.1081, -0.1453],\n",
      "          [-0.1133, -0.6079,  0.1049, -0.2146, -0.0172, -0.1453]],\n",
      "\n",
      "         [[-0.0839, -0.0839, -0.0839, -0.0839, -0.0839, -0.0839],\n",
      "          [-0.0839, -0.0839, -0.0839, -0.0839, -0.0839, -0.0839],\n",
      "          [-0.2758, -0.5359, -0.4661, -0.2742, -0.0141, -0.0839],\n",
      "          [-0.1094, -0.3937, -0.3938, -0.6300, -0.4138, -0.0839],\n",
      "          [ 0.0152, -0.1969,  0.1878,  0.3233,  0.0847, -0.0839],\n",
      "          [ 0.0152, -0.5135, -0.6274, -0.2742, -0.0141, -0.0839]]]])\n",
      "tensor([[ 0.3136,  0.3136,  0.3136,  0.3136,  0.3136,  0.3136],\n",
      "        [ 0.3136,  0.3136,  0.3136,  0.3136,  0.3136,  0.3136],\n",
      "        [ 0.4446,  0.3224,  0.0656, -0.0654,  0.0567,  0.3136],\n",
      "        [ 0.7647,  0.7183,  0.6608,  0.5976,  0.3908,  0.3136],\n",
      "        [ 0.7774,  0.3689,  0.2876,  0.4545,  0.4966,  0.3136],\n",
      "        [ 0.7774,  0.4871,  0.3258, -0.0654,  0.0567,  0.3136]])\n",
      "tensor([[ 0.2246,  0.2246,  0.2246,  0.2246,  0.2246,  0.2246],\n",
      "        [ 0.2246,  0.2246,  0.2246,  0.2246,  0.2246,  0.2246],\n",
      "        [ 0.5208,  0.2101,  0.0016, -0.2946,  0.0161,  0.2246],\n",
      "        [ 0.5514, -0.3452, -0.1768,  0.0011,  0.2909,  0.2246],\n",
      "        [ 0.8456,  0.2083,  0.9428,  0.7909,  0.5008,  0.2246],\n",
      "        [ 0.8456,  0.2103,  0.3441, -0.2946,  0.0161,  0.2246]])\n",
      "tensor([[-0.1453, -0.1453, -0.1453, -0.1453, -0.1453, -0.1453],\n",
      "        [-0.1453, -0.1453, -0.1453, -0.1453, -0.1453, -0.1453],\n",
      "        [-0.0231, -0.2206, -0.0924, -0.2146, -0.0172, -0.1453],\n",
      "        [-0.1757, -0.5502, -0.2807, -0.2563, -0.2015, -0.1453],\n",
      "        [-0.1133, -0.6677, -0.0900, -0.2244,  0.1081, -0.1453],\n",
      "        [-0.1133, -0.6079,  0.1049, -0.2146, -0.0172, -0.1453]])\n",
      "tensor([[-0.0839, -0.0839, -0.0839, -0.0839, -0.0839, -0.0839],\n",
      "        [-0.0839, -0.0839, -0.0839, -0.0839, -0.0839, -0.0839],\n",
      "        [-0.2758, -0.5359, -0.4661, -0.2742, -0.0141, -0.0839],\n",
      "        [-0.1094, -0.3937, -0.3938, -0.6300, -0.4138, -0.0839],\n",
      "        [ 0.0152, -0.1969,  0.1878,  0.3233,  0.0847, -0.0839],\n",
      "        [ 0.0152, -0.5135, -0.6274, -0.2742, -0.0141, -0.0839]])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABrCAYAAABXGGiIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAA9VJREFUeJzt3D1OlW0UhtGNkCCFAQp+O36CwYSGSTAEOxp7SwdhSc8AKOxsLBgANZBAIBEaiUEjGoORhq//GtgnOeqdrFXfhwde4uXb8Izc398XADme/O1vAIAe4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QJixYXzRvb09f475gJcvX44M8rnd3V3P9gGvXr0a6Nm+fv3as33Azs7OQM+2qurNmzee7wPevn37qOfrjRsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEEa4AcIIN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QRrgBwgg3QBjhBggzNowvOjU11dp///69tf/48WNr/+3bt9a+qv8zLC0ttc8YxNraWmt/cnLS2n/69Km1Pz09be2rqtbX11v7xcXF9hmD6P7Ou89qenq6tb+5uWntq6oWFhaGfsagrq6uWvvuv/OJiYnWfn5+vrWvqlpeXm7tf/361T7jMbxxA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBmKHeVdO+iuLu7a+1fvHjR2v/+/bu1r+rfQ3F7e9s+YxBjY71f2YcPH1r72dnZ1v758+etfVXVyspKaz+s+x7+78uXL6398fFxa7+6utraj46OtvZVVZ8/f27tx8fH22cMamZmprXv3mHUdXh42P5M996jbqseyxs3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyDMUC6ZevKk9//B0dFRa//z58/Wfm5urrWvqnr27Flr/6cumVpbW2vtt7a2Wvvt7e3W/uvXr619VdXZ2Vlrf35+3j5jEE+fPm3tf/z40drPz8+39t0Ljar6l35dXFy0zxjU1NRUa7+wsNDab25utvbT09OtfVXV5eVla399fd0+4zG8cQOEEW6AMMINEEa4AcIIN0AY4QYII9wAYYQbIIxwA4QRboAwwg0QZih3lXRNTk629nd3d639/v5+a1/Vv1dhaWmpfca/6P379639u3fv2mesr6+39ouLi+0z/oTu3Sbduzdubm5a+0E/8686OTlp7Q8ODlr7jY2N1r6qanl5uf2ZYfDGDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEEa4AcIIN0CYkfv7+7/9PQDQ4I0bIIxwA4QRboAwwg0QRrgBwgg3QBjhBggj3ABhhBsgjHADhBFugDDCDRBGuAHCCDdAGOEGCCPcAGGEGyCMcAOEEW6AMMINEEa4AcIIN0AY4QYI8x8Ufpg2WPDUkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inference: C vs. D detector\n",
    "with torch.no_grad():\n",
    "    print('C' if model(generate_data(visualise=False)[0].unsqueeze_(0)) > 0 else 'D')\n",
    "    print(activation['act'])\n",
    "    \n",
    "    # visualize activations after convolution\n",
    "    for i, act in enumerate(activation['act'][0]):\n",
    "        print(act)\n",
    "        data = act.view(6,6)\n",
    "        subplot(1, 4, i+1)\n",
    "        imshow(data, cmap='gray', vmin=-1, vmax=1)\n",
    "        axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# A printout of sample data, activations, outputs to troubleshoot Teensy implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 1., 1., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 1., 1., 0., 0., 0.]]]), tensor(0.))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAAyVJREFUeJzt3cENAjEQBEEvuvxTNhEg8TkMTVUEI0utfXrWWnsBSY/TA4D7CBzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgEHadHvBL9t6nJyTMzOkJf8MFhzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIczfZF+s+ofXJ/94q77hu1xwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5h1+kBvLb3Pj3hFjNzesLfcMEhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQNmut5v84gAsOZQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hD0BJxAM/pvEV9UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dat = generate_data(visualise=True)\n",
    "print(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.1830, -0.0421,  0.0127],\n",
      "          [ 0.0772,  0.2068,  0.3201],\n",
      "          [-0.2569, -0.1222,  0.1310]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2762,  0.2901,  0.2941],\n",
      "          [ 0.0663, -0.2899,  0.0307],\n",
      "          [-0.2085, -0.3107,  0.2962]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2535, -0.3325,  0.0624],\n",
      "          [-0.0562, -0.0549, -0.1526],\n",
      "          [ 0.1282, -0.1974,  0.1222]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1686,  0.2386,  0.1246],\n",
      "          [-0.3299, -0.2162,  0.1664],\n",
      "          [ 0.0698, -0.2600, -0.1919]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3136,  0.2246, -0.1453, -0.0839], requires_grad=True)\n",
      "Linear(in_features=16, out_features=1, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2381, -0.0045, -0.1883, -0.1928, -0.0138,  0.0375, -0.1024,  0.1483,\n",
      "         -0.1521,  0.2268,  0.1713, -0.2108, -0.0622,  0.0113,  0.0365,  0.0593]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0981], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n",
      "tensor([[ 0.3224,  0.0656, -0.0654,  0.0567,  0.3136,  0.3136],\n",
      "        [ 0.7183,  0.6608,  0.7286,  0.2687,  0.0567,  0.3136],\n",
      "        [ 0.3689,  0.2876,  0.9056,  0.5812,  0.1339,  0.3136],\n",
      "        [ 0.3561,  0.3169,  0.7774,  0.3561,  0.3169,  0.3136],\n",
      "        [ 0.3561,  0.3169,  0.7774,  0.3561,  0.3169,  0.3136],\n",
      "        [ 0.4871,  0.3258,  0.2673,  0.2214,  0.5738,  0.3136]])\n",
      "tensor([[ 0.2101,  0.0016, -0.2946,  0.0161,  0.2246,  0.2246],\n",
      "        [-0.3452, -0.1768,  0.2972, -0.0197,  0.0161,  0.2246],\n",
      "        [ 0.2083,  0.9428,  1.1177, -0.0997,  0.0824,  0.2246],\n",
      "        [-0.0858,  0.3586,  0.8456, -0.0858,  0.3586,  0.2246],\n",
      "        [-0.0858,  0.3586,  0.8456, -0.0858,  0.3586,  0.2246],\n",
      "        [ 0.2103,  0.3441,  0.0302,  0.0163,  0.5671,  0.2246]])\n",
      "tensor([[-0.2206, -0.0924, -0.2146, -0.0172, -0.1453, -0.1453],\n",
      "        [-0.5502, -0.2807, -0.1342, -0.3989, -0.0172, -0.1453],\n",
      "        [-0.6677, -0.0900, -0.2548, -0.1442, -0.0733, -0.1453],\n",
      "        [-0.7301,  0.1801, -0.1133, -0.7301,  0.1801, -0.1453],\n",
      "        [-0.7301,  0.1801, -0.1133, -0.7301,  0.1801, -0.1453],\n",
      "        [-0.6079,  0.1049, -0.3048, -0.4045,  0.0520, -0.1453]])\n",
      "tensor([[-0.5359, -0.4661, -0.2742, -0.0141, -0.0839, -0.0839],\n",
      "        [-0.3937, -0.3938, -0.8220, -0.6738, -0.0141, -0.0839],\n",
      "        [-0.1969,  0.1878,  0.2978, -0.3916, -0.3440, -0.0839],\n",
      "        [-0.3215, -0.1755,  0.0152, -0.3215, -0.1755, -0.0839],\n",
      "        [-0.3215, -0.1755,  0.0152, -0.3215, -0.1755, -0.0839],\n",
      "        [-0.5135, -0.6274,  0.0169,  0.0083, -0.2452, -0.0839]])\n",
      "\n",
      "\n",
      "relu:\n",
      "tensor([[[[0.3224, 0.0656, 0.0000, 0.0567, 0.3136, 0.3136],\n",
      "          [0.7183, 0.6608, 0.7286, 0.2687, 0.0567, 0.3136],\n",
      "          [0.3689, 0.2876, 0.9056, 0.5812, 0.1339, 0.3136],\n",
      "          [0.3561, 0.3169, 0.7774, 0.3561, 0.3169, 0.3136],\n",
      "          [0.3561, 0.3169, 0.7774, 0.3561, 0.3169, 0.3136],\n",
      "          [0.4871, 0.3258, 0.2673, 0.2214, 0.5738, 0.3136]],\n",
      "\n",
      "         [[0.2101, 0.0016, 0.0000, 0.0161, 0.2246, 0.2246],\n",
      "          [0.0000, 0.0000, 0.2972, 0.0000, 0.0161, 0.2246],\n",
      "          [0.2083, 0.9428, 1.1177, 0.0000, 0.0824, 0.2246],\n",
      "          [0.0000, 0.3586, 0.8456, 0.0000, 0.3586, 0.2246],\n",
      "          [0.0000, 0.3586, 0.8456, 0.0000, 0.3586, 0.2246],\n",
      "          [0.2103, 0.3441, 0.0302, 0.0163, 0.5671, 0.2246]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1801, 0.0000, 0.0000, 0.1801, 0.0000],\n",
      "          [0.0000, 0.1801, 0.0000, 0.0000, 0.1801, 0.0000],\n",
      "          [0.0000, 0.1049, 0.0000, 0.0000, 0.0520, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1878, 0.2978, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0152, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0152, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0169, 0.0083, 0.0000, 0.0000]]]])\n",
      "\n",
      "\n",
      "pool:\n",
      "tensor([[[[0.9056, 0.5812],\n",
      "          [0.7774, 0.5738]],\n",
      "\n",
      "         [[1.1177, 0.2246],\n",
      "          [0.8456, 0.5671]],\n",
      "\n",
      "         [[0.0000, 0.0000],\n",
      "          [0.1801, 0.1801]],\n",
      "\n",
      "         [[0.2978, 0.0000],\n",
      "          [0.0169, 0.0083]]]])\n",
      "\n",
      "\n",
      "flatten:\n",
      "tensor([[0.9056, 0.5812, 0.7774, 0.5738, 1.1177, 0.2246, 0.8456, 0.5671, 0.0000,\n",
      "         0.0000, 0.1801, 0.1801, 0.2978, 0.0000, 0.0169, 0.0083]])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABrCAYAAABXGGiIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAABDxJREFUeJzt3D9LVn8cxvFPkYRioAWlOaUFZTTkHDg6BYKQuLTUQ6gn0djS0AMI2hoaamlqjqA/iIODUILDLRH9g7Ip+I1dN9z2+8DrNV/nHD3gu7P0PXJwcFAA9HH0X/8AAGSEG6AZ4QZoRrgBmhFugGaEG6AZ4QZoRrgBmhFugGaOjeKmjx8/jv475vb2dnT/wWAQ7aempqJ9VdW5c+fiaxLr6+tHhrnu4cOH0bv98OFDdP/Nzc1of+nSpWhfVXX27Nn4msStW7eGere3b9+O3u309HR0//39/Wg/Ozsb7Yd5Rur+/ftDvduqqmvXrkXvd3x8PLr/zMxMtJ+fn4/2VVVfv36Nr0ncu3fvr96vL26AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhmJGeVLC0tRfvFxcVoPzExEe1fvnwZ7avy81NGfbbJH8+ePYv2p0+fjvbXr1+P9u/fv4/2Vfn5KaM+2+SPt2/fRvvz589H+5MnT0b7V69eRfuqqqtXr0b7UZ9t8l/p7596/vx5tB/m57lx40a0H9XZJr64AZoRboBmhBugGeEGaEa4AZoRboBmhBugGeEGaEa4AZoRboBmhBugmZGcVfLmzZto//nz52i/uroa7S9evBjtq6oGg0F8zWFYWVmJ9jdv3oz2x48fj/Z37tyJ9lVVZ86cia85DJ8+fYr2MzMz0X5vby/aD3P+zffv3+NrDsvs7Gy0T8882tjYiPaPHj2K9lX5eTbz8/PxM/6GL26AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhmJGeV/Pr1K9qPjY1F+/39/Wi/s7MT7av+v+dpbG1tRfunT59G++Xl5Wh/9Gj+b//CwkK0P6xzY759+xbt09/j58+f0f7JkyfRvqrq7t270f7du3fxM4aV/t2+fv062qdnx4yPj0f7qqpTp07F14yCL26AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaOTaKm05PT0f7vb29aP/ixYto/+PHj2hfVXXlypVov729HT9jGBcuXIj2BwcH0f7BgwfR/sSJE9G+qmpubi7aDwaD+BnDmJqaivZfvnyJ9h8/foz2i4uL0b7q8N7VMHZ3d6P95uZmtF9bW4v2ly9fjvZV+d/55ORk/Iy/4YsboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaOZKeZQHAv+WLG6AZ4QZoRrgBmhFugGaEG6AZ4QZoRrgBmhFugGaEG6AZ4QZoRrgBmhFugGaEG6AZ4QZoRrgBmhFugGaEG6AZ4QZoRrgBmhFugGaEG6AZ4QZoRrgBmvkNpHKxnu+Az5gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    #dat = generate_data(visualise=False)\n",
    "    x = dat[0].unsqueeze_(0)\n",
    "    print('C' if model(x) > 0 else 'D')\n",
    "    \n",
    "    # visualize activations after convolution\n",
    "    for i, act in enumerate(activation['act'][0]):\n",
    "        print(act)\n",
    "        data = act.view(6,6)\n",
    "        subplot(1, 4, i+1)\n",
    "        imshow(data, cmap='gray', vmin=-1, vmax=1)\n",
    "        axis('off');\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"relu:\")\n",
    "    print(activation[\"relu\"])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"pool:\")\n",
    "    print(activation[\"pool\"])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"flatten:\")\n",
    "    print(activation[\"flatten\"])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5656)\n"
     ]
    }
   ],
   "source": [
    "# compare against our model cost function\n",
    "X, Y = generate_data(visualise=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = model(X.unsqueeze_(0))  # feed-forward\n",
    "    l = loss(y.squeeze(-2), Y.unsqueeze(0))\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    # e^x => math.e ** 2\n",
    "    return 1 / (1 + math.e ** -x)\n",
    "\n",
    "# def binary_cross_entropy(input, y): return - (pred.log()*y + (1-y)*(1-pred).log()) .mean()\n",
    "\n",
    "def binary_cross_entropy(x,y):\n",
    "    return - (math.log(x)*y + (1-y)*math.log(1-x))\n",
    "    # no mean value for now, since input is 1-dimensional -> need to extend for matrices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5656)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model(X)\n",
    "\n",
    "binary_cross_entropy(sigmoid(y),Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
